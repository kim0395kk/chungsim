# app.py â€” AI í–‰ì •ê´€ Pro (Stable / Dual-Model Router v6.2)
# Groq: qwen/qwen3-32b (FAST) + llama-3.3-70b-versatile (STRICT)
# LAWGO(DRF) + NAVER + Supabase + A4 HTML Preview + Anti-crash
#
# âœ… FAST(default): CaseNormalizer / Planner / Strategy
# âœ… STRICT: JSON ìƒì„±(Planner ë³´ì • ì‹¤íŒ¨/ê³µë¬¸ Draft), ë²•ë ¹ ë¶ˆí™•ì‹¤ ì‹œ Strategy ìŠ¹ê¸‰
# âœ… ë²•ë ¹: DRF JSON ìš°ì„  + "ì‚¬ëŒì´ ì½ëŠ” ì¡°ë¬¸"ìœ¼ë¡œ íŒŒì‹±(ì œëª©/ë³¸ë¬¸/í•­/í˜¸)
# âœ… í•œì ì œê±°(ê°€ë…ì„±): í•œì ë²”ìœ„ ì œê±° ì˜µì…˜ ê¸°ë³¸ ON
# âœ… UI: A4 ìš©ì§€ ìŠ¤íƒ€ì¼ HTML ë Œë”ë§(components.html)
# âœ… ì„±ëŠ¥: ìºì‹±(st.cache_data) + í”„ë¡¬í”„íŠ¸ ì¶•ì•½ + ê·œì¹™ ê¸°ë°˜ í›„ë³´ ìƒì„±
# âœ… Metrics: ëª¨ë¸ë³„ í˜¸ì¶œ + (ê°€ëŠ¥í•˜ë©´) tokens_total í•©ì‚°

import streamlit as st
import streamlit.components.v1 as components

import json
import re
import time
from datetime import datetime
from html import escape, unescape

# =========================
# 0) Optional Imports (Safety)
# =========================
try:
    from groq import Groq
except ImportError:
    Groq = None

try:
    import requests
except ImportError:
    requests = None

try:
    import xmltodict
except ImportError:
    xmltodict = None

try:
    from supabase import create_client
except ImportError:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (Dual v6.2)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }

/* ===== A4 Paper Preview ===== */
.paper-wrap { display:flex; justify-content:center; }
.paper-sheet {
  background:#fff;
  width: 210mm;
  min-height: 297mm;
  padding: 22mm 20mm;
  margin: 14px 0;
  box-shadow: 0 8px 24px rgba(0,0,0,0.10);
  border-radius: 10px;
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111;
  line-height: 1.68;
  position: relative;
}
.doc-header {
  text-align:center;
  font-size: 24pt;
  font-weight: 800;
  letter-spacing: 4px;
  margin: 0 0 20mm 0;
}
.doc-meta {
  display:flex;
  justify-content:space-between;
  gap: 10px;
  flex-wrap:wrap;
  font-size: 11pt;
  border-bottom: 2px solid #222;
  padding-bottom: 8mm;
  margin-bottom: 10mm;
}
.doc-meta span { white-space: nowrap; }
.doc-body { font-size: 12pt; text-align: justify; }
.doc-body p { margin: 0 0 12px 0; }
.doc-footer {
  text-align:center;
  font-size: 20pt;
  font-weight: 800;
  letter-spacing: 6px;
  margin-top: 22mm;
}
.stamp {
  position:absolute;
  right: 18mm;
  bottom: 26mm;
  border: 3px solid #d32f2f;
  color: #d32f2f;
  padding: 6px 12px;
  font-size: 13pt;
  font-weight: 900;
  transform: rotate(-12deg);
  opacity: 0.82;
  border-radius: 6px;
  font-family: 'Nanum Gothic', sans-serif;
}

/* ===== Logs ===== */
.agent-log {
  font-family: 'Pretendard', sans-serif;
  font-size: 0.92rem;
  padding: 8px 12px;
  border-radius: 8px;
  margin-bottom: 6px;
  background: white;
  border: 1px solid #e5e7eb;
}
.log-legal { border-left: 4px solid #2563eb; color: #1e3a8a; }
.log-search { border-left: 4px solid #f97316; color: #9a3412; }
.log-strat { border-left: 4px solid #8b5cf6; color: #5b21b6; }
.log-draft { border-left: 4px solid #ef4444; color: #7f1d1d; }
.log-sys   { border-left: 4px solid #9ca3af; color: #374151; }

.small-muted { color:#6b7280; font-size:12px; }
.kpi { background:#fff; border:1px solid #e5e7eb; border-radius: 10px; padding: 10px 12px; }
.kpi h4 { margin:0 0 6px 0; font-size: 0.95rem; }
.kpi p { margin:0; color:#374151; font-size: 0.9rem; }

</style>
""",
    unsafe_allow_html=True,
)

_TAG_RE = re.compile(r"<[^>]+>")
# ì œì–´ë¬¸ì + Private Use Area(ì˜¤ë¥˜ ìœ ë°œ) ì œê±°
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")
# í•œì(ì¤‘êµ­ì–´/í•œì) ë²”ìœ„ ì œê±°(ê°€ë…ì„± ìœ„í•´)
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]")


# =========================
# 2) Helpers
# =========================
def clean_text(value) -> str:
    """HTML íƒœê·¸ + ì œì–´ë¬¸ì + PUA ì œê±°"""
    if value is None:
        return ""
    s = str(value)
    s = unescape(s)
    s = _TAG_RE.sub("", s)
    s = _CTRL_RE.sub("", s)
    # PUA(Private Use Area) ì œê±°: U+E000â€“U+F8FF
    s = re.sub(r"[\uE000-\uF8FF]", "", s)
    return s.strip()


def remove_hanja(s: str) -> str:
    """í•œìë¥¼ í•œê¸€ë¡œ 'ë³€í™˜'ì€ ëª»í•˜ë‹ˆ(ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´), ê°€ë…ì„± ìœ„í•´ ì œê±°(ì˜µì…˜)."""
    if not s:
        return ""
    return _HANJA_RE.sub("", s)


def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")


def truncate_text(s: str, max_chars: int = 1800) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"


def safe_json_dump(obj):
    try:
        return json.dumps(obj, ensure_ascii=False, default=str)
    except Exception:
        return "{}"


def ensure_doc_shape(doc):
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    out = {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
    }
    return out


def extract_keywords_kor(text: str, max_k: int = 6) -> list:
    if not text:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", text)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,12}", t)
    stop = set([
        "ê·¸ë¦¬ê³ ","ê´€ë ¨","ë¬¸ì˜","ì‚¬í•­","ëŒ€í•˜ì—¬","ëŒ€í•œ","ì²˜ë¦¬","ìš”ì²­","ì‘ì„±","ì•ˆë‚´","ê²€í† ","ë¶ˆí¸","ë¯¼ì›",
        "ì‹ ì²­","ë°œê¸‰","ì œì¶œ","í†µì§€","ë‹µë³€","íšŒì‹ ","ë¶€íƒ","ì¡°ì¹˜","í™•ì¸","ë‚´ìš©","ì‚¬ìœ ","ì§„í–‰"
    ])
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Metrics
# =========================
def metrics_init():
    if "metrics" not in st.session_state:
        st.session_state["metrics"] = {"calls": {}, "tokens_total": 0}

def metrics_add(model_name: str, tokens_total=None):
    metrics_init()
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass

metrics_init()


# =========================
# 4) LLM Service (Dual Router)
# =========================
class LLMService:
    """
    secrets.toml
    [general]
    GROQ_API_KEY = "..."
    GROQ_MODEL_FAST = "qwen/qwen3-32b"
    GROQ_MODEL_STRICT = "llama-3.3-70b-versatile"
    """
    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")
        self.model_fast = g.get("GROQ_MODEL_FAST", "qwen/qwen3-32b")
        self.model_strict = g.get("GROQ_MODEL_STRICT", "llama-3.3-70b-versatile")

        self.client = None
        self.last_model = "N/A"
        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def _chat(self, model: str, messages, temp: float, json_mode: bool):
        if not self.client:
            raise RuntimeError("Groq client not ready")

        kwargs = {"model": model, "messages": messages, "temperature": temp}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        resp = self.client.chat.completions.create(**kwargs)
        self.last_model = model

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_add(model, tokens_total=tokens_total)
        return resp.choices[0].message.content or ""

    def _parse_json(self, text: str) -> dict:
        try:
            return json.loads(text)
        except Exception:
            cleaned = re.sub(r"```json|```", "", text).strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    return {}
            return {}

    def generate_text(self, prompt: str, prefer: str = "fast", temp: float = 0.1) -> str:
        if not self.client:
            return "Groq API Keyê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜"

        model_first = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "Korean public administration assistant. Practical, correct, concise."},
            {"role": "user", "content": prompt},
        ]
        # 1ì°¨
        try:
            return self._chat(model_first, messages, temp, json_mode=False)
        except Exception:
            pass
        # ìŠ¹ê¸‰
        try:
            return self._chat(self.model_strict, messages, temp, json_mode=False)
        except Exception as e:
            return f"LLM Error: {e}"

    def generate_json(self, prompt: str, prefer: str = "fast", temp: float = 0.1, max_retry: int = 2) -> dict:
        if not self.client:
            return {}

        sys_json = "Output JSON only. No markdown. No extra keys. Follow schema exactly."
        messages = [
            {"role": "system", "content": sys_json},
            {"role": "user", "content": prompt},
        ]
        model_first = self.model_fast if prefer == "fast" else self.model_strict

        # ê°™ì€ ëª¨ë¸ ì¬ì‹œë„
        for _ in range(max_retry):
            try:
                txt = self._chat(model_first, messages, temp, json_mode=True)
                js = self._parse_json(txt)
                if js:
                    return js
            except Exception:
                pass

        # strict ìŠ¹ê¸‰
        try:
            txt = self._chat(self.model_strict, messages, temp, json_mode=True)
            js = self._parse_json(txt)
            return js if js else {}
        except Exception:
            return {}

llm_service = LLMService()


# =========================
# 5) LAW API (DRF) â€” JSON ìš°ì„  + ì¡°ë¬¸ íŒŒì‹±
# =========================
class LawAPIService:
    """
    secrets.toml
    [law]
    LAW_API_ID = "OCê°’"
    """
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and self.oc)

    def search_law(self, query: str, display: int = 10) -> list:
        if not self.enabled or not query:
            return []
        # JSON ìš°ì„ 
        try:
            params = {
                "OC": self.oc,
                "target": "law",
                "type": "JSON",
                "query": query,
                "display": display,
                "page": 1,
            }
            r = requests.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = r.json()
            laws = data.get("LawSearch", {}).get("law", [])
            if isinstance(laws, dict):
                laws = [laws]
            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue
                out.append({
                    "law_name": clean_text(it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or ""),
                    "mst": clean_text(it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or ""),
                    "law_id": clean_text(it.get("ë²•ë ¹ID") or it.get("lawId") or ""),
                    "link": clean_text(it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or ""),
                })
            return [x for x in out if x["law_name"] and x["mst"]]
        except Exception:
            # XML ë°±ì—…
            if not xmltodict:
                return []
            try:
                params = {
                    "OC": self.oc,
                    "target": "law",
                    "type": "XML",
                    "query": query,
                    "display": display,
                    "page": 1,
                }
                r = requests.get(self.search_url, params=params, timeout=7)
                r.raise_for_status()
                data = xmltodict.parse(r.text)
                laws = data.get("LawSearch", {}).get("law", [])
                if isinstance(laws, dict):
                    laws = [laws]
                out = []
                for it in laws:
                    if not isinstance(it, dict):
                        continue
                    out.append({
                        "law_name": clean_text(it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or ""),
                        "mst": clean_text(it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or ""),
                        "law_id": clean_text(it.get("ë²•ë ¹ID") or it.get("lawId") or ""),
                        "link": clean_text(it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or ""),
                    })
                return [x for x in out if x["law_name"] and x["mst"]]
            except Exception:
                return []

    def get_article_pretty(self, mst: str, article_no: str | None = None) -> dict:
        """
        return {
          ok: bool,
          law_name: str,
          article_no: "33" or "",
          text: "ì œ33ì¡°(...)\\në³¸ë¬¸\\n1. ...\\n- ..."
        }
        """
        if not self.enabled or not mst:
            return {"ok": False, "law_name": "", "article_no": "", "text": ""}

        tgt = re.sub(r"[^0-9]", "", str(article_no or ""))

        # JSON ìš°ì„ 
        try:
            params = {"OC": self.oc, "target": "law", "type": "JSON", "MST": mst}
            r = requests.get(self.service_url, params=params, timeout=9)
            r.raise_for_status()
            data = r.json()

            law = data.get("Law", {}) or {}
            law_name = clean_text(law.get("lawNm") or law.get("ë²•ë ¹ëª…í•œê¸€") or "")

            articles = law.get("Article", []) or []
            if isinstance(articles, dict):
                articles = [articles]

            # ì¡°ë¬¸ë²ˆí˜¸ ì—†ìœ¼ë©´: ì²« ì¡°ë¬¸ 1ê°œë§Œ
            if not tgt:
                if articles and isinstance(articles[0], dict):
                    at = clean_text(articles[0].get("ArticleTitle") or "")
                    ac = clean_text(articles[0].get("ArticleContent") or "")
                    txt = "\n".join([x for x in [at, ac] if x]).strip()
                    return {"ok": bool(txt), "law_name": law_name, "article_no": "", "text": txt}
                return {"ok": False, "law_name": law_name, "article_no": "", "text": ""}

            for art in articles:
                if not isinstance(art, dict):
                    continue
                an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or art.get("joNo") or "")
                an_num = re.sub(r"[^0-9]", "", an)
                at = clean_text(art.get("ArticleTitle") or "")
                if tgt == an_num or (tgt and f"ì œ{tgt}ì¡°" in at):
                    content = clean_text(art.get("ArticleContent") or "")

                    paras = art.get("Paragraph", []) or []
                    if isinstance(paras, dict):
                        paras = [paras]

                    lines = []
                    for p in paras:
                        if not isinstance(p, dict):
                            continue
                        pc = clean_text(p.get("ParagraphContent") or "")
                        if pc:
                            lines.append(pc)
                        items = p.get("Item", []) or []
                        if isinstance(items, dict):
                            items = [items]
                        for it in items:
                            if not isinstance(it, dict):
                                continue
                            ic = clean_text(it.get("ItemContent") or "")
                            if ic:
                                lines.append(f"- {ic}")

                    full = "\n".join([x for x in [at, content] if x] + lines).strip()
                    return {"ok": bool(full), "law_name": law_name, "article_no": tgt, "text": full}

            return {"ok": False, "law_name": law_name, "article_no": tgt, "text": ""}

        except Exception:
            # XML ë°±ì—…(ìµœí›„ ìˆ˜ë‹¨)
            if not xmltodict:
                return {"ok": False, "law_name": "", "article_no": tgt, "text": ""}
            try:
                params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
                r = requests.get(self.service_url, params=params, timeout=9)
                r.raise_for_status()
                data = xmltodict.parse(r.text)
                law = data.get("Law") or {}
                law_name = clean_text(law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("lawNm") or "")
                articles = law.get("Article", []) or []
                if isinstance(articles, dict):
                    articles = [articles]

                if not tgt:
                    txt = clean_text(r.text)
                    return {"ok": bool(txt), "law_name": law_name, "article_no": "", "text": txt[:1200]}

                for art in articles:
                    if not isinstance(art, dict):
                        continue
                    an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                    an_num = re.sub(r"[^0-9]", "", an)
                    at = clean_text(art.get("ArticleTitle") or "")
                    if tgt == an_num or (tgt and f"ì œ{tgt}ì¡°" in at):
                        content = clean_text(art.get("ArticleContent") or "")
                        full = "\n".join([x for x in [at, content] if x]).strip()
                        return {"ok": bool(full), "law_name": law_name, "article_no": tgt, "text": full}

                return {"ok": False, "law_name": law_name, "article_no": tgt, "text": ""}
            except Exception:
                return {"ok": False, "law_name": "", "article_no": tgt, "text": ""}

law_api = LawAPIService()


# =========================
# 6) NAVER Search
# =========================
class NaverSearchService:
    """
    secrets.toml
    [naver]
    CLIENT_ID="..."
    CLIENT_SECRET="..."
    """
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    def search(self, query: str, cat: str = "news", display: int = 5):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = requests.get(url, headers=headers, params=params, timeout=6)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []

naver_search = NaverSearchService()


# =========================
# 7) Supabase
# =========================
class DatabaseService:
    """
    secrets.toml
    [supabase]
    SUPABASE_URL="..."
    SUPABASE_KEY="..."
    """
    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        url = s.get("SUPABASE_URL")
        key = s.get("SUPABASE_KEY")
        if create_client and url and key:
            try:
                self.client = create_client(url, key)
            except Exception:
                self.client = None

    def save_log(self, data: dict):
        if not self.client:
            return "DB ë¯¸ì—°ê²°"
        try:
            safe_data = json.loads(safe_json_dump(data))
            self.client.table("law_logs").insert(safe_data).execute()
            return "ì €ì¥ ì„±ê³µ"
        except Exception as e:
            return f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"

db_service = DatabaseService()


# =========================
# 8) Caching (ì„±ëŠ¥)
# =========================
@st.cache_data(show_spinner=False, ttl=60 * 30)
def cached_law_search(query: str, display: int = 10):
    return law_api.search_law(query, display=display)

@st.cache_data(show_spinner=False, ttl=60 * 60)
def cached_law_article(mst: str, article_no: str):
    return law_api.get_article_pretty(mst, article_no)

@st.cache_data(show_spinner=False, ttl=60 * 20)
def cached_naver_news(query: str, display: int = 5):
    return naver_search.search(query, cat="news", display=display)


# =========================
# 9) Workflow í•µì‹¬ ê°œì„  í¬ì¸íŠ¸
# =========================
def normalize_case_fast(user_input: str) -> dict:
    """
    'ë¯¼ì› ìƒí™©ì„ ë„£ìœ¼ë©´ ì´í•´ ëª»í•¨' í•´ê²°ìš©:
    1) ì…ë ¥ì„ ë¨¼ì € 'ì‚¬ì‹¤/ìš”êµ¬/ëŒ€ìƒ/ì¥ì†Œ/ì‹œê°„/ì¦ê±°/ìŸì 'ìœ¼ë¡œ êµ¬ì¡°í™”
    2) ì´í›„ Planner/LawSearchëŠ” ì´ êµ¬ì¡°í™” í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œë§Œ ì§„í–‰
    """
    kw = extract_keywords_kor(user_input, max_k=6)
    prompt = f"""
ì•„ë˜ ë¯¼ì›/ì—…ë¬´ ì§€ì‹œë¥¼ 'ì‚¬ì‹¤ ì¤‘ì‹¬'ìœ¼ë¡œ êµ¬ì¡°í™”í•´ JSONë§Œ ì¶œë ¥.

[ì›ë¬¸]
{user_input}

[ìŠ¤í‚¤ë§ˆ]
{{
  "summary_one_line": "í•œ ì¤„ ìš”ì•½(20~40ì)",
  "facts": ["ì‚¬ì‹¤1","ì‚¬ì‹¤2","ì‚¬ì‹¤3"],
  "request": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ê²ƒ(ë˜ëŠ” ì²˜ë¦¬ ëª©í‘œ)",
  "targets": ["ëŒ€ìƒ(ì°¨ëŸ‰/ì—…ì²´/ì‚¬ëŒ/ê¸°ê´€ ë“±)"],
  "place_time": "ì¥ì†Œ/ì‹œê°„(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)",
  "evidence": ["ì¦ê±°/ìë£Œ(ì‚¬ì§„/ë¬¸ì„œ/ë…¹ì·¨ ë“±)"],
  "risk_points": ["ìŸì /ì£¼ì˜ì (ë²•ì /ë¯¼ì›/ì ˆì°¨)"],
  "keywords": {kw}
}}
ì£¼ì˜:
- ì¶”ì¸¡ ê¸ˆì§€(ì—†ìœ¼ë©´ ë¹ˆê°’/ëª¨ë¦„)
- ë²•ë ¹ëª… ì¶”ì •ì€ ì—¬ê¸°ì„œ í•˜ì§€ ë§ ê²ƒ
"""
    js = llm_service.generate_json(prompt, prefer="fast", max_retry=2, temp=0.1)
    if not js:
        return {
            "summary_one_line": "",
            "facts": [user_input[:120]],
            "request": "",
            "targets": [],
            "place_time": "",
            "evidence": [],
            "risk_points": [],
            "keywords": kw[:4],
        }
    # ì•ˆì „ì •ë¦¬
    def _list(v):
        return v if isinstance(v, list) else []
    return {
        "summary_one_line": clean_text(js.get("summary_one_line") or ""),
        "facts": [clean_text(x) for x in _list(js.get("facts")) if clean_text(x)][:6],
        "request": clean_text(js.get("request") or ""),
        "targets": [clean_text(x) for x in _list(js.get("targets")) if clean_text(x)][:6],
        "place_time": clean_text(js.get("place_time") or ""),
        "evidence": [clean_text(x) for x in _list(js.get("evidence")) if clean_text(x)][:6],
        "risk_points": [clean_text(x) for x in _list(js.get("risk_points")) if clean_text(x)][:6],
        "keywords": [clean_text(x) for x in _list(js.get("keywords")) if clean_text(x)][:6] or kw[:4],
    }


def plan_law_and_keywords(case_pack: dict) -> dict:
    """
    Plannerê°€ ì—‰ëš±í•œ ë²•ë ¹ ì°ëŠ” ë¬¸ì œë¥¼ ì¤„ì´ë ¤ë©´:
    - 'ë²•ë ¹ëª… ë§ì¶”ê¸°'ë¥¼ 1shotìœ¼ë¡œ í•˜ì§€ ë§ê³ 
    - í›„ë³´ ë²•ë ¹ëª…ì„ ìµœëŒ€ 3ê°œë§Œ ì œì‹œí•˜ê²Œ í•˜ê³ (í™•ì‹  ì—†ìœ¼ë©´ ë¹ˆê°’),
    - ì´í›„ ì‹¤ì œ law.go.kr search ê²°ê³¼ë¡œ ê²€ì¦í•´ì„œ ì±„íƒ.
    """
    base_text = f"""
[ìš”ì•½] {case_pack.get('summary_one_line','')}
[ì‚¬ì‹¤] {" / ".join(case_pack.get('facts',[]))}
[ìš”êµ¬] {case_pack.get('request','')}
[ëŒ€ìƒ] {", ".join(case_pack.get('targets',[]))}
[ì¥ì†Œ/ì‹œê°„] {case_pack.get('place_time','')}
[ìŸì ] {" / ".join(case_pack.get('risk_points',[]))}
[í‚¤ì›Œë“œ] {", ".join(case_pack.get('keywords',[]))}
""".strip()

    prompt = f"""
ë‹¤ìŒ ì—…ë¬´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ 'ê°€ëŠ¥ì„± ë†’ì€ ë²•ë ¹ í›„ë³´'ì™€ 'ê²€ìƒ‰ í‚¤ì›Œë“œ'ë§Œ JSONìœ¼ë¡œ ì¶œë ¥.

[ì—…ë¬´ì •ë³´]
{base_text}

[ìŠ¤í‚¤ë§ˆ]
{{
  "task_type": "ì—…ë¬´ìœ í˜•(ì§§ê²Œ)",
  "law_candidates": ["ë²•ë ¹ëª… í›„ë³´1","ë²•ë ¹ëª… í›„ë³´2","ë²•ë ¹ëª… í›„ë³´3"],
  "article_no_hint": "ì¡°ë²ˆí˜¸ íŒíŠ¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
  "keywords": ["ê²€ìƒ‰ì–´1","ê²€ìƒ‰ì–´2","ê²€ìƒ‰ì–´3"]
}}

ì œì•½:
- í™•ì‹  ì—†ìœ¼ë©´ law_candidatesëŠ” ë¹ˆë¬¸ìì—´ë¡œ ì±„ìš°ì§€ ë§ê³  ê·¸ëƒ¥ ë¹„ì›Œë„ ë¨.
- ë²•ë ¹ëª…ì€ 'ê³µì‹ëª…' ìš°ì„ (ì˜ˆ: ìë™ì°¨ê´€ë¦¬ë²•, ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•, ë„ë¡œêµí†µë²• ë“±)
- ì¡°ë²ˆí˜¸ëŠ” ì •ë§ í™•ì‹¤í•  ë•Œë§Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)
"""
    js = llm_service.generate_json(prompt, prefer="fast", max_retry=2, temp=0.1)
    if not js:
        return {"task_type": "ì—…ë¬´", "law_candidates": [], "article_no_hint": "", "keywords": case_pack.get("keywords", [])[:3]}

    cands = js.get("law_candidates") if isinstance(js.get("law_candidates"), list) else []
    cands = [clean_text(x) for x in cands if clean_text(x)]
    kws = js.get("keywords") if isinstance(js.get("keywords"), list) else []
    kws = [clean_text(x) for x in kws if clean_text(x)]
    if not kws:
        kws = case_pack.get("keywords", [])[:3]
    return {
        "task_type": clean_text(js.get("task_type") or "ì—…ë¬´"),
        "law_candidates": cands[:3],
        "article_no_hint": clean_text(js.get("article_no_hint") or ""),
        "keywords": kws[:4],
        "base_text": base_text,
    }


def choose_best_law(law_queries: list, article_no_hint: str, add_log=None) -> dict:
    """
    ì‹¤ì œ DRF ê²€ìƒ‰ ê²°ê³¼ë¡œ 'ê²€ì¦'í•´ì„œ ì„ ì •:
    - í›„ë³´ ì¿¼ë¦¬ ìˆœì„œëŒ€ë¡œ search -> top ê²°ê³¼ ì±„íƒ
    - ì¡°ë¬¸ íŒŒì‹± ì„±ê³µí•˜ë©´ CONFIRMED
    """
    legal_status = "FAIL"
    legal_basis = "ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨"
    law_debug = {"queries": law_queries, "picked": None}
    chosen = None

    for q in law_queries[:5]:
        if add_log:
            add_log(f"ë²•ë ¹ê²€ìƒ‰ ì‹œë„: {q}", "legal")
        cands = cached_law_search(q, display=10)
        if cands:
            chosen = cands[0]
            break

    if not chosen:
        return {"legal_status": "FAIL", "legal_basis": legal_basis, "law_debug": law_debug}

    law_name = clean_text(chosen.get("law_name") or "")
    mst = clean_text(chosen.get("mst") or "")
    link = clean_text(chosen.get("link") or "")
    law_debug["picked"] = {"law_name": law_name, "mst": mst, "link": link}

    # ì¡°ë¬¸ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ì¡°ë¬¸ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ì¡°ë¬¸ 1ê°œë¼ë„ ì‚¬ëŒ ì½ê²Œ
    art_no = re.sub(r"[^0-9]", "", article_no_hint or "")
    art_pack = cached_law_article(mst, art_no) if art_no else law_api.get_article_pretty(mst, None)

    if art_pack.get("ok") and art_pack.get("text"):
        legal_status = "CONFIRMED" if art_pack.get("article_no") else "WEAK"
        legal_basis = f"{art_pack.get('law_name','')}\n{art_pack.get('text','')}".strip()
    else:
        legal_status = "WEAK"
        legal_basis = f"{law_name}\n(ì¡°ë¬¸ ì›ë¬¸ íŒŒì‹± ì‹¤íŒ¨ â€” ì¶”ê°€ í™•ì¸ í•„ìš”)"
    return {"legal_status": legal_status, "legal_basis": legal_basis, "law_debug": law_debug}


def build_strategy(case_pack: dict, plan_pack: dict, legal_basis: str, legal_status: str, ev_text: str) -> str:
    prefer = "strict" if legal_status != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {plan_pack.get('task_type','ì—…ë¬´')}
[ì—…ë¬´ìš”ì•½] {case_pack.get('summary_one_line','')}
[ì‚¬ì‹¤] {" / ".join(case_pack.get('facts',[]))}
[ìš”êµ¬] {case_pack.get('request','')}
[ìŸì ] {" / ".join(case_pack.get('risk_points',[]))}

[ë²•ì ê·¼ê±°]
{truncate_text(legal_basis, 1200)}

[ì°¸ê³ (ë„¤ì´ë²„)]
{truncate_text(ev_text, 700)}

ì•„ë˜ í˜•ì‹ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œë§Œ:
1) ì²˜ë¦¬ ë°©í–¥ (3~6ì¤„)
2) í•µì‹¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë¶ˆë¦¿ 6~12ê°œ)
3) ì˜ˆìƒ ë¯¼ì›/ë°˜ë°œ & ëŒ€ì‘ (3~6ì¤„)
4) 'ë‹´ë‹¹ë¶€ì„œ í•œê³„'ê°€ ìˆìœ¼ë©´ í•œ ì¤„ ëª…ì‹œ(ì˜ˆ: ì£¼ê¸°ìœ„ë°˜ë§Œ ê°€ëŠ¥ ë“±)

ì›ì¹™:
- ê³¼ì¥/ì¶”ì¸¡ ê¸ˆì§€, ë¶ˆí™•ì‹¤í•˜ë©´ 'ì¶”ê°€ í™•ì¸ í•„ìš”' ëª…ì‹œ
- ì‹¤ì œ í–‰ì • ì ˆì°¨ ê´€ì (í†µì§€/ê³„ê³ /ì²­ë¬¸/ì´ì˜ì‹ ì²­ ë“±)ìœ¼ë¡œ ì‘ì„±
"""
    return llm_service.generate_text(prompt, prefer=prefer, temp=0.1)


def build_official_doc_json(
    dept: str,
    officer: str,
    case_pack: dict,
    legal_basis: str,
    legal_status: str,
    strategy_md: str,
    doc_num: str,
    today_str: str,
) -> dict:
    # STRICT ê³ ì •
    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4","ë¬¸ë‹¨5"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ê±´ ìš”ì•½:
- í•œì¤„ìš”ì•½: {case_pack.get("summary_one_line","")}
- ì‚¬ì‹¤: {" / ".join(case_pack.get("facts",[]))}
- ìš”êµ¬: {case_pack.get("request","")}
- ëŒ€ìƒ: {", ".join(case_pack.get("targets",[]))}
- ì¥ì†Œ/ì‹œê°„: {case_pack.get("place_time","")}

ë²•ì  ê·¼ê±°(í™•ë³´ëœ ë²”ìœ„ / ìƒíƒœ={legal_status}):
{truncate_text(legal_basis, 1200)}

ì²˜ë¦¬ ì „ëµ(ìš”ì•½):
{truncate_text(strategy_md, 900)}

ì‘ì„± ì›ì¹™:
- ë¬¸ì²´: ê±´ì¡°/ì •ì¤‘/ëª…í™•
- êµ¬ì¡°: [ê°ì‚¬/ìš”ì§€] -> [ì‚¬ì‹¤ê´€ê³„] -> [ë²•ì ê·¼ê±°] -> [ì¡°ì¹˜/ì•ˆë‚´] -> [ë¬¸ì˜ì²˜]
- ë²•ë ¹ì´ ë¶ˆí™•ì‹¤í•˜ë©´ 'ì¶”ê°€ í™•ì¸ í•„ìš”' ë˜ëŠ” 'ê´€ë ¨ ê·œì • ê²€í†  í›„' ë¬¸êµ¬ í¬í•¨
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
"""
    doc_json = llm_service.generate_json(prompt, prefer="strict", max_retry=2, temp=0.1)
    return ensure_doc_shape(doc_json)


def run_workflow(user_input: str, dept: str, officer: str, remove_hanja_on: bool = True):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.04)

    # 0) Normalize
    add_log("ğŸ§© [Normalizer] ë¯¼ì›/ì—…ë¬´ ì…ë ¥ì„ 'ì‚¬ì‹¤ ì¤‘ì‹¬ êµ¬ì¡°'ë¡œ ì •ë¦¬...", "sys")
    case_pack = normalize_case_fast(user_input)

    # 1) Planner
    add_log("ğŸ§­ [Planner] ë²•ë ¹ í›„ë³´/í‚¤ì›Œë“œ ì‚°ì¶œ (FAST)...", "sys")
    plan_pack = plan_law_and_keywords(case_pack)

    # 2) Law Search (ê²€ì¦ ê¸°ë°˜)
    add_log("ğŸ“š [Law] ë²•ë ¹ ê²€ìƒ‰ ë° ì¡°ë¬¸ íŒŒì‹±(ì‚¬ëŒì´ ì½ëŠ” í˜•íƒœ)...", "legal")
    # law query ìš°ì„ ìˆœìœ„: í›„ë³´ë²•ë ¹ëª… -> í‚¤ì›Œë“œ
    law_queries = []
    for x in plan_pack.get("law_candidates", [])[:3]:
        if x and x not in law_queries:
            law_queries.append(x)
    for k in plan_pack.get("keywords", [])[:3]:
        if k and k not in law_queries:
            law_queries.append(k)

    law_pick = choose_best_law(law_queries, plan_pack.get("article_no_hint", ""), add_log=add_log)
    legal_status = law_pick["legal_status"]
    legal_basis = law_pick["legal_basis"]
    law_debug = law_pick["law_debug"]

    if remove_hanja_on:
        legal_basis = remove_hanja(legal_basis)

    # 3) Naver Evidence
    add_log("ğŸŒ [Search] ë„¤ì´ë²„ ë‰´ìŠ¤ë¡œ ì‚¬ì‹¤ê´€ê³„/ë¦¬ìŠ¤í¬ ì ê²€...", "search")
    ev_items = []
    ev_text = ""
    if plan_pack.get("keywords"):
        q = " ".join(plan_pack["keywords"][:2])
        raw = cached_naver_news(q, display=5)
        for it in raw:
            t = clean_text(it.get("title"))
            d = clean_text(it.get("description"))
            link = clean_text(it.get("link"))
            if remove_hanja_on:
                t, d = remove_hanja(t), remove_hanja(d)
            ev_items.append({"title": t, "link": link, "desc": d})
            ev_text += f"- {t}: {d}\n"

    # 4) Strategy
    add_log("ğŸ§  [Analyst] ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½(ë²•ë ¹ ë¶ˆí™•ì‹¤ ì‹œ STRICT ìŠ¹ê¸‰)...", "strat")
    strategy = build_strategy(case_pack, plan_pack, legal_basis, legal_status, ev_text)
    if remove_hanja_on:
        strategy = remove_hanja(strategy)

    # 5) Drafter (A4 ë¬¸ì„œìš© JSON)
    add_log("âœï¸ [Drafter] ê³µë¬¸ì„œ(JSON) ìƒì„± (STRICT)...", "draft")
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"
    doc_final = build_official_doc_json(
        dept, officer, case_pack, legal_basis, legal_status, strategy, doc_num, today_str
    )

    # 6) Save
    add_log("ğŸ’¾ [System] ê²°ê³¼ ì €ì¥...", "sys")
    payload = {
        "created_at": datetime.now().isoformat(),
        "dept": dept,
        "officer": officer,
        "input": user_input,
        "case_pack": safe_json_dump(case_pack),
        "task_type": plan_pack.get("task_type", ""),
        "keywords": safe_json_dump(plan_pack.get("keywords", [])),
        "legal_status": legal_status,
        "legal_basis": legal_basis,
        "final_doc": safe_json_dump(doc_final),
        "strategy": strategy,
        "provenance": safe_json_dump(ev_items),
        "model_last": llm_service.last_model,
        "metrics": safe_json_dump(st.session_state.get("metrics", {})),
        "law_debug": safe_json_dump(law_debug),
        "remove_hanja": remove_hanja_on,
    }
    db_msg = db_service.save_log(payload)
    add_log(f"âœ… ì™„ë£Œ ({db_msg})", "sys")

    time.sleep(0.25)
    log_area.empty()

    return {
        "doc": doc_final,
        "meta": {"doc_num": doc_num, "today": today_str, "dept": dept, "officer": officer},
        "case_pack": case_pack,
        "legal_basis": legal_basis,
        "legal_status": legal_status,
        "strategy": strategy,
        "ev_items": ev_items,
        "db_msg": db_msg,
        "law_debug": law_debug,
        "plan_pack": plan_pack,
    }


# =========================
# 10) UI
# =========================
def render_a4_html(doc: dict, meta: dict) -> str:
    body_html = "".join([f"<p>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])])
    html = f"""
<div class="paper-wrap">
  <div class="paper-sheet">
    <div class="stamp">ì§ì¸ìƒëµ</div>
    <div class="doc-header">{safe_html(doc.get('title',''))}</div>
    <div class="doc-meta">
      <span>ë¬¸ì„œë²ˆí˜¸: {safe_html(meta.get('doc_num',''))}</span>
      <span>ì‹œí–‰ì¼ì: {safe_html(meta.get('today',''))}</span>
      <span>ìˆ˜ì‹ : {safe_html(doc.get('receiver',''))}</span>
    </div>
    <div class="doc-body">
      {body_html}
    </div>
    <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
  </div>
</div>
"""
    return html


def main():
    st.session_state.setdefault("dept", "OOì‹œì²­ OOê³¼")
    st.session_state.setdefault("officer", "ê¹€ì£¼ë¬´ê´€")
    st.session_state.setdefault("remove_hanja_on", True)

    col_l, col_r = st.columns([1, 1.25], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("Dual Router v6.2 â€” FAST(qwen/qwen3-32b) + STRICT(llama-3.3-70b) / ë²•ë ¹ ì¡°ë¬¸ ê°€ë…ì„± íŒ¨ì¹˜ ì™„ë£Œ")
        st.markdown("---")

        with st.expander("ğŸ“ ì‚¬ìš©ì ì •ë³´ ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.checkbox("ë²•ë ¹/ì „ëµ í…ìŠ¤íŠ¸ì—ì„œ í•œì ì œê±°(ê°€ë…ì„±)", key="remove_hanja_on")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­(ë¯¼ì› ìƒí™© í¬í•¨ ê°€ëŠ¥)",
            height=220,
            placeholder="ì˜ˆ: ì°¨ê³ ì§€ ì™¸ ë¶ˆë²• ë°©ì¹˜ëœ ê±´ì„¤ê¸°ê³„ì— ëŒ€í•´ ì£¼ê¸°ìœ„ë°˜ ì—¬ë¶€ ê²€í†  í›„ ì•ˆë‚´ ë‹µë³€ë¬¸ ì‘ì„±.",
        )

        if st.button("ğŸš€ ë¬¸ì„œ ìƒì„± ì‹¤í–‰", type="primary", use_container_width=True):
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("AI ì—ì´ì „íŠ¸ í˜‘ì—… ì¤‘..."):
                    try:
                        res = run_workflow(
                            user_input.strip(),
                            st.session_state["dept"],
                            st.session_state["officer"],
                            remove_hanja_on=bool(st.session_state.get("remove_hanja_on", True)),
                        )
                        st.session_state["result"] = res
                    except Exception as e:
                        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown("---")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("<div class='kpi'><h4>ëª¨ë¸ í˜¸ì¶œ(ì„¸ì…˜)</h4>", unsafe_allow_html=True)
            if calls:
                for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                    st.write(f"- **{k}**: {v}íšŒ")
            else:
                st.write("- ëŒ€ê¸° ì¤‘")
            st.markdown("</div>", unsafe_allow_html=True)

        with c2:
            st.markdown("<div class='kpi'><h4>í† í° í•©ê³„(ê°€ëŠ¥í•œ ê²½ìš°)</h4>", unsafe_allow_html=True)
            st.write(f"- **{tokens_total}**")
            st.markdown("</div>", unsafe_allow_html=True)

        st.markdown(
            "<div class='small-muted'>TIP: ì…ë ¥ì´ ê¸¸ì–´ë„ ë¨¼ì € Normalizerê°€ ì‚¬ì‹¤ê´€ê³„ë¥¼ êµ¬ì¡°í™”í•´ì„œ Planner/ë²•ë ¹ê²€ìƒ‰ì˜ 'ì—‰ëš±í•¨'ì„ ì¤„ì…ë‹ˆë‹¤.</div>",
            unsafe_allow_html=True,
        )

    with col_r:
        res = st.session_state.get("result")

        if not res:
            st.markdown(
                """
<div style='text-align: center; padding: 120px 20px; color: #9ca3af; border: 2px dashed #e5e7eb; border-radius: 12px; background:#fff;'>
  <h3 style="margin:0 0 6px 0;">ğŸ“„ A4 ê³µë¬¸ ë¯¸ë¦¬ë³´ê¸°</h3>
  <p style="margin:0;">ì™¼ìª½ì—ì„œ ì—…ë¬´ë¥¼ ì…ë ¥í•˜ê³  ì‹¤í–‰ì„ ëˆ„ë¥´ë©´<br>ë²•ë ¹ ê²€ì¦ í›„ ê³µë¬¸ì„œ í˜•íƒœë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.</p>
</div>
""",
                unsafe_allow_html=True,
            )
        else:
            doc = res["doc"]
            meta = res["meta"]

            tab1, tab2 = st.tabs(["ğŸ“„ ê³µë¬¸ì„œ(A4)", "ğŸ” ê·¼ê±°/ë¶„ì„/ë””ë²„ê·¸"])

            with tab1:
                html = render_a4_html(doc, meta)
                components.html(html, height=920, scrolling=True)

            with tab2:
                st.success(f"DB: {res.get('db_msg','')}")
                st.markdown("### ğŸ§© ì‚¬ê±´ êµ¬ì¡°í™”(ì…ë ¥ ì´í•´ ê²°ê³¼)")
                st.code(safe_json_dump(res.get("case_pack", {})), language="json")

                st.markdown("### ğŸ“œ ë²•ì  ê·¼ê±°(ê°€ë…ì„± ì¡°ë¬¸)")
                st.info(f"ìƒíƒœ: {res.get('legal_status')}")
                st.code(res.get("legal_basis", ""), language="text")

                st.markdown("### ğŸ’¡ ì²˜ë¦¬ ì „ëµ")
                st.markdown(res.get("strategy", ""))

                st.markdown("### ğŸ“ ì°¸ê³  ìë£Œ (Naver)")
                for item in res.get("ev_items", []):
                    title = clean_text(item.get("title"))
                    link = clean_text(item.get("link"))
                    desc = clean_text(item.get("desc"))
                    if link:
                        st.markdown(f"- [{title}]({link}) â€” {desc}")
                    else:
                        st.markdown(f"- {title} â€” {desc}")

                with st.expander("ğŸ› ï¸ Planner/ë²•ë ¹ ë””ë²„ê·¸", expanded=False):
                    st.markdown("**Planner ê²°ê³¼**")
                    st.code(safe_json_dump(res.get("plan_pack", {})), language="json")
                    st.markdown("**Law Debug**")
                    st.code(safe_json_dump(res.get("law_debug", {})), language="json")


if __name__ == "__main__":
    main()
