# streamlit_app.py â€” AI í–‰ì •ê´€ Pro (v7.1)
# Dual-Model Router (FAST: qwen/qwen3-32b, STRICT: llama-3.3-70b-versatile)
# law.go.kr DRF + Naver Search + (Optional) Supabase
#
# í•µì‹¬ UX:
# - ë²•ë ¹ í›„ë³´ë¥¼ "í´ë¦­(ì„ íƒ)" -> ì¡°ë¬¸ ì›ë¬¸(ì •ë¦¬ë³¸) + law.go.kr ë§í¬ + ì‚¬ë¡€(ë„¤ì´ë²„) ì¹´ë“œ
# - ê³µë¬¸ ê²°ê³¼ A4 HTML ë¯¸ë¦¬ë³´ê¸° + HTML ë‹¤ìš´ë¡œë“œ
# - U+EA01 ë“± ë¹„í‘œì‹œë¬¸ì(Private Use) ì œê±°ë¡œ SyntaxError/ë Œë”ë§ í¬ë˜ì‹œ ë°©ì§€

import streamlit as st
import streamlit.components.v1 as components
import google.generativeai as genai
import json
import re
import time
from datetime import datetime
from html import escape, unescape
from typing import Any, Dict, List, Optional, Tuple

# -------------------------
# Optional imports
# -------------------------
try:
    from groq import Groq
except Exception:
    Groq = None

try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (v7.1)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }

/* A4 ë¬¸ì„œ ìŠ¤íƒ€ì¼ */
.paper-sheet {
  background: #fff; width: 100%; max-width: 210mm; min-height: 297mm;
  padding: 25mm; margin: auto; box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111; line-height:1.7; position:relative;
}
.doc-header {
  text-align:center; font-size:24pt; font-weight:900;
  border-bottom:2px solid #111; padding-bottom:10px; margin-bottom:18px;
  letter-spacing:1px;
}
.doc-info {
  font-size:11pt; border-bottom:1px solid #d1d5db;
  padding-bottom:10px; margin-bottom:22px;
}
.doc-info b { color:#111; }
.doc-body { font-size:12pt; text-align: justify; min-height: 430px; }
.doc-footer {
  text-align:center; font-size:20pt; font-weight:900;
  margin-top:90px; border-top:1px solid #111; padding-top:20px;
  letter-spacing:3px;
}
.stamp {
  position:absolute; bottom:90px; right:80px;
  border:3px solid #d32f2f; color:#d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:900;
  transform:rotate(-12deg); opacity:0.85; border-radius:4px;
  font-family: 'Nanum Gothic', sans-serif;
}

/* Agent logs */
.agent-log {
  font-family: 'Pretendard', sans-serif; font-size: 0.92rem;
  padding: 8px 12px; border-radius: 8px; margin-bottom: 6px;
  background: white; border: 1px solid #e5e7eb;
}
.log-legal { border-left: 5px solid #3b82f6; }
.log-search { border-left: 5px solid #f97316; }
.log-strat { border-left: 5px solid #8b5cf6; }
.log-draft { border-left: 5px solid #ef4444; }
.log-sys   { border-left: 5px solid #9ca3af; }

.small-muted { color:#6b7280; font-size:12px; }

/* Evidence cards */
.ev-card{
  background:#fff; border:1px solid #e5e7eb; border-radius:12px;
  padding:12px 14px; margin:10px 0;
}
.ev-title{ font-weight:800; font-size:0.98rem; }
.ev-desc{ color:#374151; margin-top:6px; font-size:0.92rem; }
.ev-meta{ color:#6b7280; margin-top:6px; font-size:0.82rem; }

.badge{
  display:inline-block; padding:2px 8px; border-radius:999px;
  border:1px solid #e5e7eb; background:#fff; font-size:12px;
}
.badge-ok{ border-color:#bbf7d0; background:#f0fdf4; color:#166534; }
.badge-warn{ border-color:#fed7aa; background:#fff7ed; color:#9a3412; }
.badge-bad{ border-color:#fecaca; background:#fff1f2; color:#9f1239; }

</style>
""",
    unsafe_allow_html=True,
)

# =========================
# 2) Sanitizers (U+EA01 & Non-printable)
# =========================
_TAG_RE = re.compile(r"<[^>]+>")
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")

# Private Use Area í¬í•¨ ì œê±°(ë¬¸ì œì˜ U+EA01 ê°™ì€ ì• ë“¤)
_PUA_RE = re.compile(r"[\uE000-\uF8FF]")

# í•œì(í‘œì‹œìš© ì œê±°)
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]+")

def strip_pua(s: str) -> str:
    if not s:
        return ""
    return _PUA_RE.sub("", s)

def clean_text(value) -> str:
    """HTML íƒœê·¸/ì œì–´ë¬¸ì/PUA ì œê±°"""
    if value is None:
        return ""
    s = str(value)
    s = strip_pua(s)
    s = unescape(s)
    s = _TAG_RE.sub("", s)
    s = _CTRL_RE.sub("", s)
    return s.strip()

def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")

def normalize_whitespace(s: str) -> str:
    if not s:
        return ""
    s = strip_pua(s)
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()

def strip_hanja_for_display(s: str) -> str:
    if not s:
        return ""
    s = strip_pua(s)
    s = _HANJA_RE.sub("", s)
    s = re.sub(r"\s{2,}", " ", s)
    return s.strip()

def truncate_text(s: str, max_chars: int = 2800) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"

def safe_json_dump(obj):
    try:
        return json.dumps(obj, ensure_ascii=False, default=str)
    except Exception:
        return "{}"

def ensure_doc_shape(doc):
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    out = {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
    }
    return out

def extract_keywords_kor(text: str, max_k: int = 10) -> List[str]:
    if not text:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", text)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,14}", t)
    stop = {
        "ê·¸ë¦¬ê³ ","ê´€ë ¨","ë¬¸ì˜","ì‚¬í•­","ëŒ€í•˜ì—¬","ëŒ€í•œ","ì²˜ë¦¬","ìš”ì²­","ì‘ì„±","ì•ˆë‚´","ê²€í† ",
        "ë¶ˆí¸","ë¯¼ì›","ì‹ ì²­","ë°œê¸‰","ì œì¶œ","ê°€ëŠ¥","ì—¬ë¶€","ì¡°ì¹˜","í™•ì¸","í†µë³´","íšŒì‹ ","ê²°ê³¼","ì‚¬ìœ "
    }
    out = []
    for w in words:
        if w in stop: 
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Session State Init
# =========================
def ss_init():
    defaults = {
        "dept": "OOì‹œì²­ OOê³¼",
        "officer": "ê¹€ì£¼ë¬´ê´€",
        "user_key": "local_user",

        "metrics": {"calls": {}, "tokens_total": 0},

        "result": None,

        # í´ë¦­ UXìš©
        "law_candidates": [],
        "selected_candidate_idx": 0,
        "selected_law_pack": None,

        "case_struct": None,
        "strategy_md": "",

        "evidence_items": [],
        "example_items": [],  # (í™•ì¥ìš©) í–¥í›„ íŒë¡€/ì‚¬ë¡€ ìŠ¤í¬ë© ë„£ì„ ìë¦¬
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

ss_init()


# =========================
# 4) Metrics
# =========================
def metrics_add(model_name: str, tokens_total: Optional[int] = None):
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


# =========================
# 5) LLM Service (Dual Router)
# =========================
class LLMService:
    """
    [Model Hierarchy]
    1. Gemini 2.5 Flash
    2. Gemini 2.5 Flash Lite
    3. Gemini 2.0 Flash
    4. Groq (Llama 3 Backup)
    """
    def __init__(self):
        self.gemini_key = st.secrets["general"].get("GEMINI_API_KEY")
        self.groq_key = st.secrets["general"].get("GROQ_API_KEY")
        
        # [ì„ ìƒë‹˜ ìš”ì²­ì‚¬í•­] ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì›ìƒë³µêµ¬ (2.5 í¬í•¨)
        self.gemini_models = [
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash"
        ]
        
        if self.gemini_key:
            genai.configure(api_key=self.gemini_key)
            
        self.groq_client = Groq(api_key=self.groq_key) if self.groq_key else None

    def _try_gemini(self, prompt, is_json=False, schema=None):
        for model_name in self.gemini_models:
            try:
                # ëª¨ë¸ í˜¸ì¶œ (ëŒ€ì†Œë¬¸ì ì´ìŠˆ ë°©ì§€ ìœ„í•´ lower ì²˜ë¦¬ ë“±ì€ ìƒí™©ì— ë§ê²Œ)
                model = genai.GenerativeModel(model_name)
                config = genai.GenerationConfig(
                    response_mime_type="application/json",
                    response_schema=schema
                ) if is_json else None
                
                res = model.generate_content(prompt, generation_config=config)
                return res.text, model_name
            except Exception:
                continue # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
        raise Exception("All Gemini models failed")

    def generate_text(self, prompt):
        try:
            text, model_used = self._try_gemini(prompt, is_json=False)
            return text
        except Exception:
            if self.groq_client:
                return self._generate_groq(prompt)
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜: AI ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨"

    def generate_json(self, prompt, schema=None):
        try:
            text, model_used = self._try_gemini(prompt, is_json=True, schema=schema)
            return json.loads(text)
        except Exception:
            # Fallback for Groq or Gemini without JSON mode
            text = self.generate_text(prompt + "\n\nOutput strictly in JSON.")
            try:
                match = re.search(r'\{.*\}', text, re.DOTALL)
                return json.loads(match.group(0)) if match else None
            except:
                return None

    def _generate_groq(self, prompt):
        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            return completion.choices[0].message.content
        except:
            return "System Error"


# =========================
# 6) LAW API (DRF)
# =========================
class LawAPIService:
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)

    def search_law(self, query: str, display: int = 10) -> List[Dict[str, str]]:
        if not self.enabled or not query:
            return []
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "query": query, "display": display, "page": 1}
            r = requests.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = xmltodict.parse(r.text)
            laws = data.get("LawSearch", {}).get("law", [])
            if isinstance(laws, dict):
                laws = [laws]

            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue
                out.append(
                    {
                        "lawNm": it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or "",
                        "MST": it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or "",
                        "link": it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or "",
                        "amend": it.get("ê°œì •ì¼ì") or "",
                    }
                )
            return [x for x in out if clean_text(x.get("lawNm")) and clean_text(x.get("MST"))]
        except Exception:
            return []

    def _extract_articles(self, law_obj: dict) -> List[dict]:
        articles = law_obj.get("Article", []) or []
        if isinstance(articles, dict):
            articles = [articles]
        return [a for a in articles if isinstance(a, dict)]

    def get_article_by_mst(self, mst: str, article_no: Optional[str] = None) -> Dict[str, Any]:
        if not self.enabled or not mst:
            return {}
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
            r = requests.get(self.service_url, params=params, timeout=10)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            law = data.get("Law") or data.get("law") or {}
            law_name = clean_text(law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("LawName") or law.get("ë²•ë ¹ëª…") or "")
            articles = self._extract_articles(law)

            index_titles = []
            for a in articles[:120]:
                at = clean_text(a.get("ArticleTitle") or "")
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                if at:
                    index_titles.append(at)
                elif an:
                    index_titles.append(f"ì œ{an}ì¡°")

            if not article_no:
                if articles:
                    return self._format_article(law_name, mst, articles[0], index_titles)
                return {"law_name": law_name, "mst": mst, "all_articles_index": index_titles}

            tgt = re.sub(r"[^0-9]", "", str(article_no))
            if not tgt:
                return {"law_name": law_name, "mst": mst, "all_articles_index": index_titles}

            for a in articles:
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                at = clean_text(a.get("ArticleTitle") or "")
                if tgt == re.sub(r"[^0-9]", "", an) or (tgt and f"ì œ{tgt}ì¡°" in at):
                    return self._format_article(law_name, mst, a, index_titles)

            return {"law_name": law_name, "mst": mst, "article_no": tgt, "all_articles_index": index_titles}
        except Exception:
            return {}

    def _format_article(self, law_name: str, mst: str, art: dict, idx: List[str]) -> Dict[str, Any]:
        at = clean_text(art.get("ArticleTitle") or "")
        an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
        content = clean_text(art.get("ArticleContent") or "")

        paras = art.get("Paragraph", [])
        if isinstance(paras, dict):
            paras = [paras]
        p_lines = []
        for p in paras:
            if not isinstance(p, dict):
                continue
            pc = clean_text(p.get("ParagraphContent") or "")
            if pc:
                p_lines.append(pc)

        text = "\n".join([x for x in [content] + p_lines if x]).strip()
        text = normalize_whitespace(text)

        # í‘œì‹œìš©: í•œì ì œê±°
        text_disp = strip_hanja_for_display(text)

        return {
            "law_name": law_name,
            "mst": mst,
            "article_no": re.sub(r"[^0-9]", "", an) or "",
            "article_title": at or (f"ì œ{an}ì¡°" if an else ""),
            "article_text": text_disp,
            "all_articles_index": idx,
        }

law_api = LawAPIService()


# =========================
# 7) NAVER Search
# =========================
class NaverSearchService:
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    def search(self, query: str, cat: str = "news", display: int = 8):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = requests.get(url, headers=headers, params=params, timeout=7)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []

naver = NaverSearchService()


# =========================
# 8) (Optional) Supabase
# =========================
class DatabaseService:
    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        url = s.get("SUPABASE_URL")
        key = s.get("SUPABASE_KEY")
        if create_client and url and key:
            try:
                self.client = create_client(url, key)
            except Exception:
                self.client = None

    def enabled(self) -> bool:
        return bool(self.client)

    def save_log(self, data: dict) -> str:
        if not self.client:
            return "DB ë¯¸ì—°ê²°"
        try:
            safe_data = json.loads(safe_json_dump(data))
            self.client.table("law_logs").insert(safe_data).execute()
            return "ì €ì¥ ì„±ê³µ"
        except Exception as e:
            return f"ì €ì¥ ì‹¤íŒ¨: {e}"

db = DatabaseService()


# =========================
# 9) Core Agents
# =========================
def intake_schema(user_input: str) -> Dict[str, Any]:
    kw_fallback = extract_keywords_kor(user_input, max_k=10)

    prompt = f"""
ë‹¤ìŒ ë¯¼ì›/ì—…ë¬´ ì§€ì‹œë¥¼ 'í–‰ì • ì‚¬ì‹¤ê´€ê³„' ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ë¼.
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€).

{{
  "task_type": "ì£¼ê¸°ìœ„ë°˜|ë¬´ë‹¨ë°©ì¹˜|ë¶ˆë²•ì£¼ì •ì°¨|í–‰ì •ì²˜ë¶„|ì •ë³´ê³µê°œ|ê¸°íƒ€",
  "facts": {{
    "who": "ëŒ€ìƒ(ì°¨ëŸ‰/ê±´ì„¤ê¸°ê³„/ì—…ì²´/ê°œì¸ ë“±)",
    "what": "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€(í•µì‹¬ 1~2ë¬¸ì¥)",
    "where": "ì¥ì†Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "when": "ê¸°ê°„/ì¼ì‹œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "evidence": ["ì‚¬ì§„","ì˜ìƒ","ì§„ìˆ ","ê¸°íƒ€(ì—†ìœ¼ë©´ ë¹ˆë°°ì—´)"]
  }},
  "request": {{
    "user_wants": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ì¡°ì¹˜",
    "constraints": "ê¸°í•œ/ì ˆì°¨/ì´ì˜ì œê¸° ë“±(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "issues": ["ìŸì 1","ìŸì 2"],
  "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4"]
}}

ì…ë ¥:
\"\"\"{user_input}\"\"\"

ì£¼ì˜:
- ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ì„ ë§Œë“¤ì§€ ë§ˆë¼. ì—†ìœ¼ë©´ 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¡œ í‘œí˜„.
- keywordsëŠ” ì‚¬ì‹¤ ê¸°ë°˜ í•µì‹¬ì–´.
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    if not js:
        return {
            "task_type": "ê¸°íƒ€",
            "facts": {"who": "", "what": user_input[:140], "where": "", "when": "", "evidence": []},
            "request": {"user_wants": "", "constraints": ""},
            "issues": [],
            "keywords": kw_fallback[:4],
            "_input_quality": {"score": 60, "missing_fields": ["where", "when"]},
        }

    if not isinstance(js.get("keywords"), list) or not js["keywords"]:
        js["keywords"] = kw_fallback[:4]
    js["keywords"] = [clean_text(x) for x in js["keywords"] if clean_text(x)]
    if not js["keywords"]:
        js["keywords"] = kw_fallback[:4]

    if not isinstance(js.get("issues"), list):
        js["issues"] = []
    js["issues"] = [clean_text(x) for x in js["issues"] if clean_text(x)]

    facts = js.get("facts") if isinstance(js.get("facts"), dict) else {}
    missing = []
    if not clean_text(facts.get("where")):
        missing.append("where")
    if not clean_text(facts.get("when")):
        missing.append("when")
    score = max(40, 100 - 20 * len(missing))
    js["_input_quality"] = {"score": score, "missing_fields": missing}
    return js


def generate_law_candidates(case: Dict[str, Any]) -> List[Dict[str, Any]]:
    task_type = clean_text(case.get("task_type"))
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}
    issues = case.get("issues", [])
    keywords = case.get("keywords", [])

    domain_hint = []
    if task_type == "ì£¼ê¸°ìœ„ë°˜":
        domain_hint += ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì‹œí–‰ë ¹", "ë„ë¡œêµí†µë²•"]
    elif task_type == "ë¬´ë‹¨ë°©ì¹˜":
        domain_hint += ["ìë™ì°¨ê´€ë¦¬ë²•", "ë„ë¡œêµí†µë²•"]
    elif task_type == "ë¶ˆë²•ì£¼ì •ì°¨":
        domain_hint += ["ë„ë¡œêµí†µë²•", "ì£¼ì°¨ì¥ë²•"]

    prompt = f"""
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ í–‰ì • ì‹¤ë¬´ ê¸°ì¤€ìœ¼ë¡œ 'ë²•ë ¹ í›„ë³´'ë¥¼ ìƒì„±í•œë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥.

{{
  "candidates": [
    {{"law_name":"ë²•ë ¹ëª…(ê³µì‹)","article_hint":"ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)","reason":"ì²˜ë¶„/ì˜ë¬´/ê·¼ê±° ê´€ì  1ì¤„","confidence":0.0}}
  ]
}}

ì…ë ¥(ìš”ì•½):
- task_type: {task_type}
- what: {facts.get("what","")}
- issues: {issues}
- keywords: {keywords}

ê·œì¹™:
- 3~6ê°œ í›„ë³´
- í™•ì‹  ì—†ìœ¼ë©´ confidence ë‚®ê²Œ
- article_hintëŠ” ì¶”ì • ê°€ëŠ¥í•˜ë©´ ë„£ë˜, ëª¨ë¥´ë©´ ë¹„ì›Œë¼
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    cands = js.get("candidates", []) if isinstance(js.get("candidates"), list) else []

    out = []
    for x in domain_hint:
        out.append({"law_name": x, "article_hint": "", "reason": "ë„ë©”ì¸ ê·œì¹™ í›„ë³´", "confidence": 0.35})

    for c in cands:
        if not isinstance(c, dict):
            continue
        ln = clean_text(c.get("law_name"))
        if not ln:
            continue
        out.append({
            "law_name": ln,
            "article_hint": clean_text(c.get("article_hint") or ""),
            "reason": clean_text(c.get("reason") or ""),
            "confidence": float(c.get("confidence") or 0.0),
        })

    seen = set()
    uniq = []
    for c in out:
        k = c["law_name"]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(c)
        if len(uniq) >= 8:
            break
    return uniq[:8]


def verifier_score(case: Dict[str, Any], article_title: str, article_text: str) -> Dict[str, Any]:
    keywords = case.get("keywords", []) or []
    issues = case.get("issues", []) or []
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}
    text = (article_title + "\n" + article_text).lower()

    pool = []
    for w in keywords[:8]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in issues[:6]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in extract_keywords_kor(clean_text(facts.get("what", "")), max_k=6):
        pool.append(w)
    pool = list(dict.fromkeys(pool))[:12]

    hits = sum(1 for w in pool if w and w.lower() in text)
    relevance = min(40, int((hits / max(1, len(pool))) * 40))

    # ê¶Œí•œ ë°– ë‹¨ì–´ ê°ì (ëŒ€ì¶© ë°©ì§€)
    out_of_scope = ["êµ¬ì†", "ìˆ˜ì‚¬", "ì••ìˆ˜", "ìˆ˜ìƒ‰", "ì²´í¬", "ê¸°ì†Œ", "í˜•ì‚¬", "êµ¬ê¸ˆ"]
    o_hits = sum(1 for w in out_of_scope if w in article_text)
    scope_fit = max(0, 25 - min(25, o_hits * 8))

    length_score = 0
    if len(article_text) >= 200:
        length_score = 20
    elif len(article_text) >= 120:
        length_score = 12
    elif len(article_text) >= 80:
        length_score = 6
    else:
        length_score = 0

    risk = 0
    if not article_text or len(article_text) < 80:
        risk += 10
    if "||" in article_text or ">>" in article_text:
        risk += 5
    risk = min(15, risk)

    total = relevance + scope_fit + length_score + (15 - risk)

    if total >= 75:
        verdict = "CONFIRMED"
    elif total >= 50:
        verdict = "WEAK"
    else:
        verdict = "FAIL"

    return {
        "score_total": int(total),
        "verdict": verdict,
        "breakdown": {
            "relevance": int(relevance),
            "scope_fit": int(scope_fit),
            "length_score": int(length_score),
            "risk": int(risk),
        },
        "notes": [f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}/{max(1, len(pool))}", f"ì›ë¬¸ ê¸¸ì´ {len(article_text)}ì"],
    }


def draft_strategy(case: Dict[str, Any], law_pack: Dict[str, Any], evidence_text: str) -> str:
    prefer = "strict" if law_pack.get("verdict") != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {case.get("task_type")}
[ì‚¬ì‹¤ ìš”ì•½]
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
[ìš”êµ¬] {case.get("request",{}).get("user_wants","")}
[ìŸì ] {case.get("issues",[])}

[ë²•ì ê·¼ê±°(ì„ íƒ)]
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸(ì •ë¦¬): {truncate_text(law_pack.get("article_text",""), 900)}

[ì‚¬ë¡€/ì°¸ê³ (ë„¤ì´ë²„)]
{truncate_text(evidence_text, 700)}

ì•„ë˜ í˜•ì‹(ë§ˆí¬ë‹¤ìš´)ë§Œ ì¶œë ¥:
1) ì²˜ë¦¬ ë°©í–¥(í˜„ì‹¤ í”„ë¡œì„¸ìŠ¤ ì¤‘ì‹¬, 6~10ì¤„)
2) ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¶ˆë¦¿ 10~14ê°œ)
3) ë¯¼ì›ì¸ ì„¤ëª… ë¬¸ì¥(ë°”ë¡œ ë³µë¶™ìš© 4~6ì¤„)
"""
    return llm.generate_text(prompt, prefer=prefer, temp=0.1)


def draft_document_json(dept: str, officer: str, case: Dict[str, Any], law_pack: Dict[str, Any], strategy_md: str) -> Dict[str, Any]:
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"

    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ì‹¤ê´€ê³„(í™•ì •ëœ ë²”ìœ„):
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
- ë¯¼ì›ìš”êµ¬: {case.get("request",{}).get("user_wants","")}
- ì œì•½/ê¸°í•œ: {case.get("request",{}).get("constraints","")}

ë²•ì  ê·¼ê±°(í™•ë³´ëœ ë²”ìœ„):
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸(ì •ë¦¬): {truncate_text(law_pack.get("article_text",""), 1200)}

ì‘ì„± ì›ì¹™:
- í†¤: ê±´ì¡°/ì •ì¤‘, ë‹¨ì •/ì¶”ì¸¡ ê¸ˆì§€
- êµ¬ì¡°: [ê²½ìœ„]â†’[ë²•ì  ê·¼ê±°]â†’[ì¡°ì¹˜/ì•ˆë‚´]â†’[ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ë²•ë ¹ ì›ë¬¸ì´ ì•½í•˜ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”" í¬í•¨
"""
    js = llm.generate_json(prompt, prefer="strict", max_retry=3)
    out = ensure_doc_shape(js)
    out["_meta"] = {"doc_num": doc_num, "today": today_str, "dept": dept, "officer": officer}
    return out


def build_a4_html(doc: Dict[str, Any], meta: Dict[str, str]) -> str:
    body_html = "".join(
        [f"<p style='margin:0 0 15px 0; text-indent: 10px;'>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])]
    )
    html = f"""
<div class="paper-sheet" id="printable-area">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc.get('title',''))}</div>
  <div class="doc-info">
    <div><b>ë¬¸ì„œë²ˆí˜¸:</b> {safe_html(meta.get('doc_num',''))}</div>
    <div><b>ì‹œí–‰ì¼ì:</b> {safe_html(meta.get('today',''))}</div>
    <div style="margin-top:6px;"><b>ìˆ˜ì‹ :</b> {safe_html(doc.get('receiver',''))}</div>
  </div>
  <div class="doc-body">
    {body_html}
  </div>
  <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
  <div style="font-size: 10pt; color: #666; margin-top: 18px;">
    ë‹´ë‹¹ì: {safe_html(meta.get('officer',''))} / ë¶€ì„œ: {safe_html(meta.get('dept',''))}
  </div>
</div>
"""
    return html


def naver_case_query(case: Dict[str, Any], law_name: str, article_title: str) -> str:
    # "ì‚¬ë¡€"ë¥¼ ë” ì˜ ì°¾ê¸° ìœ„í•œ ì¿¼ë¦¬ ì¡°í•©(ì‹¤ë¬´í˜•)
    kw = case.get("keywords", []) or []
    core = " ".join([k for k in kw[:3] if k])
    law = clean_text(law_name)
    art = clean_text(article_title)

    # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼
    base = " ".join([x for x in [core, law, art] if x]).strip()
    base = re.sub(r"\s{2,}", " ", base).strip()

    # í–‰ì • ì‹¤ë¬´ì—ì„œ ì‚¬ë¡€ ì°¾ê¸° ë‹¨ì–´
    return (base + " í–‰ì •ì²˜ë¶„ ì²˜ë¶„ì‚¬ë¡€ ê³¼íƒœë£Œ í†µì§€").strip()


# =========================
# 10) Click-driven Law Pack Loader
# =========================
def load_law_pack_from_candidate(case: Dict[str, Any], cand: Dict[str, Any]) -> Dict[str, Any]:
    """
    í›„ë³´ 1ê°œë¥¼ ì„ íƒí–ˆì„ ë•Œ:
    - DRF search -> MST -> article fetch -> verifier ì ìˆ˜
    """
    q = clean_text(cand.get("law_name"))
    art_hint = clean_text(cand.get("article_hint") or "")

    laws = law_api.search_law(q, display=10)
    if not laws:
        return {"law_name": q, "verdict": "FAIL", "score": 0, "article_title": "", "article_text": "", "link": ""}

    chosen = laws[0]
    mst = clean_text(chosen.get("MST"))
    law_name = clean_text(chosen.get("lawNm"))
    link = clean_text(chosen.get("link"))

    pack = law_api.get_article_by_mst(mst, article_no=art_hint if art_hint else None)
    article_title = clean_text(pack.get("article_title", ""))
    article_text = clean_text(pack.get("article_text", ""))  # ì´ë¯¸ í•œì ì œê±°ëœ í‘œì‹œìš©

    if not article_text:
        return {"law_name": law_name, "mst": mst, "link": link, "verdict": "FAIL", "score": 0, "article_title": article_title, "article_text": ""}

    v = verifier_score(case, article_title, article_text)
    return {
        "law_name": law_name,
        "mst": mst,
        "link": link,
        "article_title": article_title,
        "article_text": article_text,
        "verdict": v["verdict"],
        "score": v["score_total"],
        "verify": v,
        "cand": cand,
        "all_articles_index": pack.get("all_articles_index", []),
    }


# =========================
# 11) Main Workflow
# =========================
def run_workflow(user_input: str, dept: str, officer: str, user_key: str):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.02)

    started = datetime.now().isoformat()

    # 1) INTAKE
    add_log("ğŸ§¾ [INTAKE] ì‚¬ì‹¤ê´€ê³„ êµ¬ì¡°í™”(FAST)â€¦", "sys")
    case = intake_schema(user_input)
    st.session_state["case_struct"] = case
    add_log(f"âœ… [INTAKE] ì™„ë£Œ (quality={case.get('_input_quality',{}).get('score','?')})", "sys")

    # 2) ë²•ë ¹ í›„ë³´ ìƒì„±
    add_log("ğŸ§© [LAW-CAND] ë²•ë ¹ í›„ë³´ ìƒì„±(FAST)â€¦", "legal")
    candidates = generate_law_candidates(case)
    if not candidates:
        kws = case.get("keywords", []) or []
        candidates = [{"law_name": k, "article_hint": "", "reason": "fallback", "confidence": 0.2} for k in kws[:3]]
    st.session_state["law_candidates"] = candidates
    st.session_state["selected_candidate_idx"] = 0
    add_log("ğŸ“Œ í›„ë³´ ì¤€ë¹„ ì™„ë£Œ (ìš°ì¸¡ì—ì„œ í´ë¦­/ì„ íƒ ê°€ëŠ¥)", "legal")

    # 3) ê¸°ë³¸ í›„ë³´ 1ê°œ ë¡œë”©
    add_log("ğŸ“š [LAW] ê¸°ë³¸ í›„ë³´ ì›ë¬¸ ë¡œë”© + ê²€ì¦â€¦", "legal")
    first_pack = load_law_pack_from_candidate(case, candidates[0])
    st.session_state["selected_law_pack"] = first_pack
    add_log(f"âœ… [LAW] ê¸°ë³¸ ì„ íƒ: {first_pack.get('law_name','')} / {first_pack.get('article_title','')} ({first_pack.get('verdict')}, score={first_pack.get('score',0)})", "legal")

    # 4) ì‚¬ë¡€(ë„¤ì´ë²„) ê¸°ë³¸ ë¡œë”©
    add_log("ğŸŒ [CASE] ì‚¬ë¡€/ê¸°ì‚¬ ìˆ˜ì§‘(ë„¤ì´ë²„)â€¦", "search")
    ev_items = []
    evidence_text = ""
    q = naver_case_query(case, first_pack.get("law_name",""), first_pack.get("article_title",""))
    raw_news = naver.search(q, cat="news", display=8) if naver.enabled else []
    raw_web = naver.search(q, cat="webkr", display=8) if naver.enabled else []

    def _push(items, source: str):
        nonlocal evidence_text
        for it in items:
            title = clean_text(it.get("title"))
            desc = clean_text(it.get("description"))
            link = clean_text(it.get("link"))
            # naver ì‘ë‹µì— HTML b íƒœê·¸ ì„ì´ë¯€ë¡œ clean_textë¡œ ì œê±°ë¨
            ev_items.append({"title": title, "desc": desc, "link": link, "source": source})
            evidence_text += f"- [{source}] {title}: {desc}\n"

    _push(raw_news, "NEWS")
    _push(raw_web, "WEB")

    st.session_state["evidence_items"] = ev_items
    add_log(f"âœ… [CASE] {len(ev_items)}ê±´", "search")

    # 5) ì „ëµ ì‘ì„±
    add_log("ğŸ§  [STRATEGY] ì²˜ë¦¬ ì „ëµ ìƒì„±â€¦", "strat")
    strategy = draft_strategy(case, first_pack, evidence_text)
    st.session_state["strategy_md"] = strategy

    # 6) ê³µë¬¸ ì‘ì„±(STRICT)
    add_log("âœï¸ [DRAFT] ê³µë¬¸ JSON ìƒì„±(STRICT)â€¦", "draft")
    doc = draft_document_json(dept, officer, case, first_pack, strategy)
    doc_final = ensure_doc_shape(doc)
    meta = doc.get("_meta", {}) if isinstance(doc, dict) else {}
    doc_meta = {
        "doc_num": meta.get("doc_num", ""),
        "today": meta.get("today", ""),
        "dept": meta.get("dept", dept),
        "officer": meta.get("officer", officer),
    }

    # 7) DB ì €ì¥(ì˜µì…˜)
    add_log("ğŸ’¾ [SAVE] ë¡œê·¸ ì €ì¥â€¦", "sys")
    payload = {
        "created_at": started,
        "dept": dept,
        "officer": officer,
        "user_key": user_key,
        "input_text": clean_text(user_input),
        "case_json": safe_json_dump(case),
        "law_pack_json": safe_json_dump(first_pack),
        "strategy_md": strategy,
        "final_doc_json": safe_json_dump(doc_final),
        "evidence_json": safe_json_dump(ev_items),
        "metrics": safe_json_dump(st.session_state.get("metrics", {})),
        "model_last": llm.last_model,
    }
    db_msg = db.save_log(payload) if db.enabled() else "DB ë¯¸ì—°ê²°"
    add_log(f"âœ… ì™„ë£Œ ({db_msg})", "sys")

    time.sleep(0.25)
    log_area.empty()

    return {
        "case": case,
        "law_pack": first_pack,
        "strategy": strategy,
        "doc": doc_final,
        "doc_meta": doc_meta,
        "evidence_items": ev_items,
        "db_msg": db_msg,
    }


# =========================
# 12) UI Renderers
# =========================
def verdict_badge(verdict: str) -> str:
    v = (verdict or "").upper()
    if v == "CONFIRMED":
        return "<span class='badge badge-ok'>CONFIRMED</span>"
    if v == "WEAK":
        return "<span class='badge badge-warn'>WEAK</span>"
    return "<span class='badge badge-bad'>FAIL</span>"

def render_a4(doc: Dict[str, Any], meta: Dict[str, str]):
    html_content = build_a4_html(doc, meta)
    components.html(html_content, height=980, scrolling=True)

    st.download_button(
        label="ğŸ“¥ ê³µë¬¸ HTMLë¡œ ë‚´ë³´ë‚´ê¸°",
        data=html_content,
        file_name=f"ê³µë¬¸_{meta.get('doc_num','') or 'draft'}.html",
        mime="text/html",
        use_container_width=True
    )

def render_law_panel(case: Dict[str, Any]):
    """
    - í›„ë³´ ë¦¬ìŠ¤íŠ¸(ì„ íƒ) -> ì„ íƒ ì¦‰ì‹œ ì›ë¬¸/ê²€ì¦/ì‚¬ë¡€ ì¬ë¡œë”©
    """
    candidates = st.session_state.get("law_candidates", []) or []
    if not candidates:
        st.info("ë²•ë ¹ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì™¼ìª½ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # í›„ë³´ í‘œì‹œ ë¬¸ìì—´
    def fmt(i: int) -> str:
        c = candidates[i]
        ln = clean_text(c.get("law_name"))
        ah = clean_text(c.get("article_hint"))
        rs = clean_text(c.get("reason"))
        cf = c.get("confidence", 0.0)
        tail = f" / ì¡°íŒíŠ¸:{ah}" if ah else ""
        return f"{ln}{tail}  (conf={cf:.2f}) â€” {rs}"

    idx = st.selectbox(
        "ğŸ“Œ ë²•ë ¹ í›„ë³´ ì„ íƒ(í´ë¦­)",
        options=list(range(len(candidates))),
        index=int(st.session_state.get("selected_candidate_idx", 0)),
        format_func=fmt,
    )

    if idx != st.session_state.get("selected_candidate_idx", 0):
        st.session_state["selected_candidate_idx"] = idx

        # ì„ íƒí•œ í›„ë³´ ë¡œë”©
        with st.spinner("ì„ íƒí•œ í›„ë³´ì˜ ì›ë¬¸/ê²€ì¦/ì‚¬ë¡€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            pack = load_law_pack_from_candidate(case, candidates[idx])
            st.session_state["selected_law_pack"] = pack

            # ì‚¬ë¡€ë„ ë²•ë ¹+ì¡°ë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì¬ê²€ìƒ‰
            ev_items = []
            q = naver_case_query(case, pack.get("law_name",""), pack.get("article_title",""))
            raw_news = naver.search(q, cat="news", display=8) if naver.enabled else []
            raw_web = naver.search(q, cat="webkr", display=8) if naver.enabled else []

            def _push(items, source: str):
                for it in items:
                    ev_items.append({
                        "title": clean_text(it.get("title")),
                        "desc": clean_text(it.get("description")),
                        "link": clean_text(it.get("link")),
                        "source": source
                    })

            _push(raw_news, "NEWS")
            _push(raw_web, "WEB")
            st.session_state["evidence_items"] = ev_items

    # í˜„ì¬ ì„ íƒ pack í‘œì‹œ
    pack = st.session_state.get("selected_law_pack") or {}
    law_name = pack.get("law_name", "")
    article_title = pack.get("article_title", "")
    verdict = pack.get("verdict", "FAIL")
    score = pack.get("score", 0)
    link = pack.get("link", "")

    st.markdown(
        f"""
<div style="padding:10px 12px; background:#fff; border:1px solid #e5e7eb; border-radius:12px;">
  <div style="font-weight:900; font-size:1.02rem;">ì„ íƒ ë²•ë ¹: {escape(clean_text(law_name))}</div>
  <div style="margin-top:6px;">ì¡°ë¬¸: <b>{escape(clean_text(article_title))}</b></div>
  <div style="margin-top:6px;">ê²€ì¦: {verdict_badge(verdict)} &nbsp; <span class="badge">score={int(score)}</span></div>
</div>
""",
        unsafe_allow_html=True
    )

    cols = st.columns([1,1,1])
    with cols[0]:
        if link:
            st.link_button("ğŸ”— law.go.kr ì›ë¬¸ ì—´ê¸°", link, use_container_width=True)
        else:
            st.button("ğŸ”— law.go.kr ì›ë¬¸ ì—´ê¸°", disabled=True, use_container_width=True)
    with cols[1]:
        st.button("ğŸ“Œ ì´ ë²•ë ¹ìœ¼ë¡œ ì „ëµ/ê³µë¬¸ ì¬ìƒì„±", disabled=True, use_container_width=True)
        st.caption("â€» ë²„íŠ¼ì€ í™•ì¥ìš©(í˜„ì¬ëŠ” ì„ íƒ ì¦‰ì‹œ ì‚¬ë¡€ë§Œ ì¬ë¡œë”©).")
    with cols[2]:
        st.caption("íŒ: ì¡°ë¬¸ì´ í‹€ë¦¬ë©´ í›„ë³´ë¥¼ ë°”ê¾¸ì„¸ìš”.")

    # ì›ë¬¸ í‘œì‹œ(ì •ë¦¬ë³¸)
    st.markdown("### ğŸ“œ ì¡°ë¬¸ ì›ë¬¸(ì •ë¦¬ë³¸)")
    txt = normalize_whitespace(pack.get("article_text","") or "")
    txt = strip_hanja_for_display(txt)

    if not txt:
        st.warning("ì¡°ë¬¸ ì›ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í›„ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    else:
        st.code(txt, language="text")

    # verifier details
    v = pack.get("verify")
    if v:
        with st.expander("ğŸ§ª Verifier ì ìˆ˜(ì™œ ì´ ë²•ì„ ì„ íƒ/ë°°ì œí–ˆëŠ”ì§€)", expanded=False):
            st.json(v)

    # ì¡°ë¬¸ ì¸ë±ìŠ¤(ì„ íƒ í™•ì¥ìš©)
    idx_titles = pack.get("all_articles_index", []) or []
    if idx_titles:
        with st.expander("ğŸ“š ì´ ë²•ë ¹ì˜ ì¡°ë¬¸ ëª©ë¡(ì¼ë¶€)", expanded=False):
            st.write(idx_titles[:80])
            st.caption("â€» í–¥í›„ 'ì¡°ë¬¸ í´ë¦­'ìœ¼ë¡œ íŠ¹ì • ì¡°ë¬¸ ë¡œë”© ê¸°ëŠ¥ê¹Œì§€ í™•ì¥ ê°€ëŠ¥.")


def render_evidence():
    items = st.session_state.get("evidence_items", []) or []
    if not naver.enabled:
        st.warning("ë„¤ì´ë²„ API ë¯¸ì„¤ì •: secrets.tomlì˜ [naver] CLIENT_ID/SECRET í•„ìš”")
        return
    if not items:
        st.info("ì‚¬ë¡€/ê¸°ì‚¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤(í‚¤ì›Œë“œ ë˜ëŠ” ë„¤ì´ë²„ ì œí•œ ê°€ëŠ¥).")
        return

    st.markdown("### ğŸ§¾ ì‚¬ë¡€/ê¸°ì‚¬ (í´ë¦­í•´ì„œ ì›ë¬¸ í™•ì¸)")
    for it in items[:16]:
        title = clean_text(it.get("title"))
        desc = clean_text(it.get("desc"))
        link = clean_text(it.get("link"))
        src = clean_text(it.get("source"))
        meta = f"ì¶œì²˜: {src}" if src else ""
        if link:
            st.markdown(
                f"""
<div class="ev-card">
  <div class="ev-title"><a href="{escape(link)}" target="_blank">{escape(title)}</a></div>
  <div class="ev-desc">{escape(desc)}</div>
  <div class="ev-meta">{escape(meta)}</div>
</div>
""",
                unsafe_allow_html=True
            )
        else:
            st.markdown(
                f"""
<div class="ev-card">
  <div class="ev-title">{escape(title)}</div>
  <div class="ev-desc">{escape(desc)}</div>
  <div class="ev-meta">{escape(meta)}</div>
</div>
""",
                unsafe_allow_html=True
            )


# =========================
# 13) Main UI
# =========================
def main():
    col_l, col_r = st.columns([1, 1.25], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("v7.1 â€” í´ë¦­ UX(ë²•ë ¹ ì›ë¬¸/ì‚¬ë¡€) + A4 ê³µë¬¸ + U+EA01 ë°©ì–´")
        st.markdown("---")

        with st.expander("ğŸ§© ë¶€ì„œ/ë‹´ë‹¹ì ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.text_input("ì‚¬ìš©ìí‚¤(ë¡œê·¸ êµ¬ë¶„ìš©)", key="user_key")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­(ë¯¼ì› ìƒí™© í¬í•¨)",
            height=220,
            placeholder="ì˜ˆ: ê±´ì„¤ê¸°ê³„ ì°¨ê³ ì§€ ì™¸ ì¥ê¸°ê°„ ì£¼ì°¨(ì£¼ê¸°ìœ„ë°˜) ì‹ ê³ . í˜„ì¥ í™•ì¸ ì‹œ ì´ë™. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì† ìš”êµ¬. ë‹´ë‹¹ì ê¶Œí•œ ë‚´ ì¡°ì¹˜/ë‹µë³€ ê³µë¬¸ ì‘ì„±.",
        )

        run_btn = st.button("ğŸš€ ì‹¤í–‰(êµ¬ì¡°í™”â†’ë²•ë ¹í›„ë³´â†’ì›ë¬¸/ê²€ì¦â†’ì‚¬ë¡€â†’ê³µë¬¸)", type="primary", use_container_width=True)

        if run_btn:
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì‹¤í–‰ ì¤‘..."):
                    try:
                        res = run_workflow(
                            clean_text(user_input),
                            st.session_state["dept"],
                            st.session_state["officer"],
                            st.session_state["user_key"],
                        )
                        st.session_state["result"] = res
                    except Exception as e:
                        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

        # Metrics
        st.markdown("---")
        st.subheader("ğŸ“Š ì„¸ì…˜ ì‚¬ìš©ëŸ‰")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)
        if calls:
            for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                st.write(f"- **{k}**: {v}íšŒ")
            st.caption(f"ì´ í† í°(ê°€ëŠ¥í•œ ê²½ìš°): {tokens_total}")
        else:
            st.info("ëŒ€ê¸° ì¤‘...")

        st.markdown("<div class='small-muted'>TIP: ë‹´ë‹¹ìëŠ” ìš°ì¸¡ì—ì„œ ë²•ë ¹ í›„ë³´ë¥¼ ë°”ê¿”ê°€ë©° ì›ë¬¸/ì‚¬ë¡€ë¥¼ ë³´ê³  íŒë‹¨í•˜ì„¸ìš”.</div>", unsafe_allow_html=True)

    with col_r:
        tabs = st.tabs(["ğŸ“„ ê³µë¬¸(A4)", "âš–ï¸ ë²•ì  ê·¼ê±°(í´ë¦­)", "ğŸ§¾ ì‚¬ë¡€(í´ë¦­)", "ğŸ§  ì „ëµ/êµ¬ì¡°í™”"])
        res = st.session_state.get("result")

        with tabs[0]:
            if not res:
                st.markdown(
                    """
<div style='text-align:center; padding:120px 20px; color:#9ca3af; border:2px dashed #e5e7eb; border-radius:14px; background:#fff;'>
  <h3 style='margin-bottom:8px;'>ğŸ“„ A4 ë¯¸ë¦¬ë³´ê¸°</h3>
  <p>ì™¼ìª½ì—ì„œ ë¯¼ì› ìƒí™© ì…ë ¥ í›„ ì‹¤í–‰í•˜ì„¸ìš”.<br>ê³µë¬¸ì„ A4 í˜•íƒœë¡œ ë³´ì—¬ì£¼ê³  HTMLë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
</div>
""",
                    unsafe_allow_html=True,
                )
            else:
                render_a4(res["doc"], res["doc_meta"])

        with tabs[1]:
            if not res:
                st.info("ì‹¤í–‰ í›„ ë²•ë ¹ í›„ë³´ë¥¼ í´ë¦­í•´ì„œ ì›ë¬¸ì„ ë³´ì„¸ìš”.")
            else:
                render_law_panel(res.get("case", {}))

        with tabs[2]:
            if not res:
                st.info("ì‹¤í–‰ í›„ ì‚¬ë¡€(ê¸°ì‚¬/ì›¹ë¬¸ì„œ)ë¥¼ í´ë¦­í•´ì„œ í™•ì¸í•˜ì„¸ìš”.")
            else:
                render_evidence()

        with tabs[3]:
            if not res:
                st.info("ì‹¤í–‰ í›„ ì „ëµ/êµ¬ì¡°í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            else:
                st.success(f"DB: {res.get('db_msg','')}")
                st.markdown("### 1) êµ¬ì¡°í™”ëœ ì‚¬ì‹¤ê´€ê³„(ë‹´ë‹¹ì ê²€í† ìš©)")
                st.json(res.get("case", {}))

                st.markdown("### 2) ì²˜ë¦¬ ì „ëµ(ë³µë¶™ ê°€ëŠ¥)")
                st.markdown(res.get("strategy", ""))

if __name__ == "__main__":
    main()
