# app.py â€” AI í–‰ì •ê´€ Pro (Stable / Dual-Model Router v7)
# Groq: qwen/qwen3-32b (FAST) + llama-3.3-70b-versatile (STRICT)
# LAWGO(DRF) + NAVER + Supabase(ì˜µì…˜) + "íŒë‹¨ UI(í´ë¦­í˜• ì›ë¬¸/ì‚¬ë¡€)"
#
# âœ… í•µì‹¬ UX: ë‹´ë‹¹ì íŒë‹¨ìš© ë¸Œë¼ìš°ì €
# - ë²•ë ¹ í›„ë³´ ë¦¬ìŠ¤íŠ¸(3~8) -> [ì›ë¬¸ ë³´ê¸°] í´ë¦­ -> ì¡°ë¬¸ ì´ë™(select) -> ì›ë¬¸ ì „ë¬¸(expander)
# - [ìœ ì‚¬ì‚¬ë¡€] í´ë¦­ -> ì›¹ë¬¸ì„œ/ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë§í¬ë¡œ í™•ì¸
# - ê³µë¬¸ì€ A4 HTMLë¡œ ë Œë”ë§
#
# âœ… ì •í™•ë„ ê°œì„ :
# 1) Intake(ì‚¬ì‹¤/ìš”êµ¬/ëŒ€ìƒ/ì‹œê°„/ì¥ì†Œ/ì¦ê±°) êµ¬ì¡°í™”
# 2) ë²•ë ¹ í›„ë³´ ë‹¤ì¤‘ ìƒì„± + DRF ì›ë¬¸ í™•ë³´ + Verifier ì ìˆ˜(ì°¸ê³ ìš©)
# 3) ìµœì¢… "ìë™ ì„ íƒ"ì€ í•˜ë˜, UIì—ì„œ í›„ë³´ë¥¼ ë‹¤ ë³´ì—¬ì¤˜ ë‹´ë‹¹ìê°€ í´ë¦­ìœ¼ë¡œ í™•ì •
#
# âš ï¸ ë³µë¶™ ì£¼ì˜: Private Use Character(U+E000ëŒ€) ì„ì´ë©´ ì—ëŸ¬ë‚  ìˆ˜ ìˆìŒ.
# - ë©”ëª¨ì¥(plain text)ì—ì„œ ì €ì¥ ê¶Œì¥.

import streamlit as st
import streamlit.components.v1 as components

import json
import re
import time
from datetime import datetime
from html import escape, unescape
from typing import Any, Dict, List, Optional, Tuple

# =========================
# 0) Optional Imports (Safety)
# =========================
try:
    from groq import Groq
except Exception:
    Groq = None

try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (Dual v7.0)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }

.paper-sheet {
  background: #fff; width: 100%; max-width: 210mm; min-height: 297mm;
  padding: 25mm; margin: auto; box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111; line-height:1.65; position:relative;
}
.doc-header { text-align:center; font-size:24pt; font-weight:800; margin-bottom:30px; letter-spacing:1px; }
.doc-info {
  display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;
  font-size:11pt; border-bottom:2px solid #111; padding-bottom:12px; margin-bottom:20px;
}
.doc-body { font-size:12pt; text-align: justify; }
.doc-footer { text-align:center; font-size:20pt; font-weight:800; margin-top:80px; letter-spacing:3px; }
.stamp {
  position:absolute; bottom:85px; right:80px; border:3px solid #d32f2f; color: #d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:800; transform:rotate(-15deg);
  opacity:0.85; border-radius:4px; font-family: 'Nanum Gothic', sans-serif;
}

/* Agent logs */
.agent-log {
  font-family: 'Pretendard', sans-serif; font-size: 0.92rem; padding: 8px 12px;
  border-radius: 8px; margin-bottom: 6px; background: white; border: 1px solid #e5e7eb;
}
.log-legal { border-left: 5px solid #3b82f6; }
.log-search { border-left: 5px solid #f97316; }
.log-strat { border-left: 5px solid #8b5cf6; }
.log-draft { border-left: 5px solid #ef4444; }
.log-sys   { border-left: 5px solid #9ca3af; }

.small-muted { color:#6b7280; font-size:12px; }

/* Evidence card */
.ev-card{
  background:#fff; border:1px solid #e5e7eb; border-radius:10px;
  padding:10px 12px; margin:8px 0;
}
.ev-title{ font-weight:700; }
.ev-desc{ color:#374151; margin-top:4px; }

/* Candidate row */
.cand-row{
  background:#fff; border:1px solid #e5e7eb; border-radius:12px;
  padding:10px 12px; margin:10px 0;
}
.cand-sub{ color:#6b7280; font-size:12px; margin-top:4px; }
</style>
""",
    unsafe_allow_html=True,
)

_TAG_RE = re.compile(r"<[^>]+>")
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")
# í‘œì‹œìš© í•œì ì œê±°(ì›ë¬¸ í‘œì‹œ UX ê°œì„ ìš©)
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]+")


# =========================
# 2) Helpers
# =========================
def clean_text(value) -> str:
    if value is None:
        return ""
    s = str(value)
    s = unescape(s)
    s = _TAG_RE.sub("", s)
    s = _CTRL_RE.sub("", s)
    return s.strip()


def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")


def truncate_text(s: str, max_chars: int = 2800) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"


def strip_hanja_for_display(s: str) -> str:
    if not s:
        return ""
    s = _HANJA_RE.sub("", s)
    s = re.sub(r"\|\>+", "", s)
    s = re.sub(r"\s{2,}", " ", s)
    return s.strip()


def normalize_whitespace(s: str) -> str:
    if not s:
        return ""
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def ensure_doc_shape(doc):
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    return {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
    }


def safe_json_dump(obj):
    try:
        return json.dumps(obj, ensure_ascii=False, default=str)
    except Exception:
        return "{}"


def extract_keywords_kor(text: str, max_k: int = 8) -> List[str]:
    if not text:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", text)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,14}", t)
    stop = {
        "ê·¸ë¦¬ê³ ", "ê´€ë ¨", "ë¬¸ì˜", "ì‚¬í•­", "ëŒ€í•˜ì—¬", "ëŒ€í•œ", "ì²˜ë¦¬", "ìš”ì²­",
        "ì‘ì„±", "ì•ˆë‚´", "ê²€í† ", "ë¶ˆí¸", "ë¯¼ì›", "ì‹ ì²­", "ë°œê¸‰", "ì œì¶œ",
        "ê°€ëŠ¥", "ì—¬ë¶€", "ì¡°ì¹˜", "í™•ì¸", "í†µë³´", "íšŒì‹ ", "ê²°ê³¼", "ì‚¬ìœ "
    }
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Metrics
# =========================
def metrics_init():
    if "metrics" not in st.session_state:
        st.session_state["metrics"] = {"calls": {}, "tokens_total": 0}


def metrics_add(model_name: str, tokens_total: Optional[int] = None):
    metrics_init()
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


metrics_init()


# =========================
# 4) LLM Service (Dual Router)
# =========================
class LLMService:
    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")
        self.model_fast = g.get("GROQ_MODEL_FAST", "qwen/qwen3-32b")
        self.model_strict = g.get("GROQ_MODEL_STRICT", "llama-3.3-70b-versatile")
        self.client = None
        self.last_model = "N/A"

        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def _chat(self, model: str, messages, temp: float, json_mode: bool):
        if not self.client:
            raise RuntimeError("Groq client not ready (missing key/lib).")

        kwargs = {"model": model, "messages": messages, "temperature": temp}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        resp = self.client.chat.completions.create(**kwargs)
        self.last_model = model

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_add(model, tokens_total=tokens_total)
        return resp.choices[0].message.content or ""

    def _parse_json(self, text: str) -> Dict[str, Any]:
        try:
            return json.loads(text)
        except Exception:
            cleaned = re.sub(r"```json|```", "", text).strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    return {}
            return {}

    def generate_text(self, prompt: str, prefer: str = "fast", temp: float = 0.1) -> str:
        if not self.client:
            return "Groq API Keyê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜"

        model_first = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "You are a Korean public-administration assistant. Be factual, structured, and practical."},
            {"role": "user", "content": prompt},
        ]

        try:
            return self._chat(model_first, messages, temp, json_mode=False)
        except Exception:
            if prefer == "fast":
                try:
                    return self._chat(self.model_strict, messages, temp, json_mode=False)
                except Exception as e2:
                    return f"LLM Error: {e2}"
            return "LLM Error"

    def generate_json(self, prompt: str, prefer: str = "fast", temp: float = 0.1, max_retry: int = 2) -> Dict[str, Any]:
        if not self.client:
            return {}

        sys_json = "Output JSON only. No markdown. No explanation. Follow the schema exactly."
        messages = [
            {"role": "system", "content": sys_json},
            {"role": "user", "content": prompt},
        ]
        model_first = self.model_fast if prefer == "fast" else self.model_strict

        for _ in range(max_retry):
            try:
                txt = self._chat(model_first, messages, temp, json_mode=True)
                js = self._parse_json(txt)
                if js:
                    return js
            except Exception:
                pass

        try:
            txt = self._chat(self.model_strict, messages, temp, json_mode=True)
            js = self._parse_json(txt)
            return js if js else {}
        except Exception:
            return {}


llm = LLMService()


# =========================
# 5) LAW API (DRF) â€” Search + Service (XML)
# =========================
class LawAPIService:
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)

    def search_law(self, query: str, display: int = 10) -> List[Dict[str, str]]:
        if not self.enabled or not query:
            return []
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "query": query, "display": display, "page": 1}
            r = requests.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = xmltodict.parse(r.text)
            laws = data.get("LawSearch", {}).get("law", [])
            if isinstance(laws, dict):
                laws = [laws]

            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue
                out.append(
                    {
                        "lawNm": it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or "",
                        "MST": it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or "",
                        "link": it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or "",
                        "promulgation": it.get("ê³µí¬ì¼ì") or "",
                        "amend": it.get("ê°œì •ì¼ì") or "",
                    }
                )
            return [x for x in out if clean_text(x.get("lawNm")) and clean_text(x.get("MST"))]
        except Exception:
            return []

    def _extract_articles(self, law_obj: dict) -> List[dict]:
        articles = law_obj.get("Article", []) or []
        if isinstance(articles, dict):
            articles = [articles]
        return [a for a in articles if isinstance(a, dict)]

    def get_article_by_mst(self, mst: str, article_no: Optional[str] = None) -> Dict[str, Any]:
        if not self.enabled or not mst:
            return {}

        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
            r = requests.get(self.service_url, params=params, timeout=10)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            law = data.get("Law") or data.get("law") or {}
            law_name = clean_text(law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("LawName") or law.get("ë²•ë ¹ëª…") or "")
            articles = self._extract_articles(law)

            # ì¡°ë¬¸ ì¸ë±ìŠ¤(UIìš©)
            idx = []
            for a in articles[:120]:
                at = clean_text(a.get("ArticleTitle") or "")
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                if at:
                    idx.append(at)
                elif an:
                    idx.append(f"ì œ{an}ì¡°")

            # article_no ì—†ìœ¼ë©´ 1ì¡°ë¼ë„ ë°˜í™˜(ì¸ë±ìŠ¤+ìƒ˜í”Œ)
            if not article_no:
                if articles:
                    return self._format_article(law_name, mst, articles[0], idx)
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            tgt = re.sub(r"[^0-9]", "", str(article_no))
            if not tgt:
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            # ì¡°ë¬¸ ë§¤ì¹­
            for a in articles:
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                at = clean_text(a.get("ArticleTitle") or "")
                if tgt == re.sub(r"[^0-9]", "", an) or (tgt and f"ì œ{tgt}ì¡°" in at):
                    return self._format_article(law_name, mst, a, idx)

            return {"law_name": law_name, "mst": mst, "article_no": tgt, "all_articles_index": idx}

        except Exception:
            return {}

    def _format_article(self, law_name: str, mst: str, art: dict, idx: List[str]) -> Dict[str, Any]:
        at = clean_text(art.get("ArticleTitle") or "")
        an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
        content = clean_text(art.get("ArticleContent") or "")

        paras = art.get("Paragraph", [])
        if isinstance(paras, dict):
            paras = [paras]
        p_lines = []
        for p in paras:
            if not isinstance(p, dict):
                continue
            pc = clean_text(p.get("ParagraphContent") or "")
            if pc:
                p_lines.append(pc)

        text = "\n".join([x for x in [content] + p_lines if x]).strip()
        text = normalize_whitespace(text)
        text_disp = strip_hanja_for_display(text)

        return {
            "law_name": law_name,
            "mst": mst,
            "article_no": re.sub(r"[^0-9]", "", an) or "",
            "article_title": at or (f"ì œ{an}ì¡°" if an else ""),
            "article_text": text_disp,
            "all_articles_index": idx,
        }


law_api = LawAPIService()


# =========================
# 6) NAVER Search
# =========================
class NaverSearchService:
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    def search(self, query: str, cat: str = "webkr", display: int = 8):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = requests.get(url, headers=headers, params=params, timeout=7)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []


naver = NaverSearchService()


# =========================
# 7) Supabase (ì˜µì…˜)
# =========================
class DatabaseService:
    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        self.url = s.get("SUPABASE_URL")
        self.key = s.get("SUPABASE_KEY")
        if create_client and self.url and self.key:
            try:
                self.client = create_client(self.url, self.key)
            except Exception:
                self.client = None

    def enabled(self) -> bool:
        return bool(self.client)

    def insert_run(self, row: dict) -> Tuple[bool, str, Optional[str]]:
        if not self.client:
            return False, "DB ë¯¸ì—°ê²°", None
        try:
            safe_row = json.loads(safe_json_dump(row))
            resp = self.client.table("runs").insert(safe_row).execute()
            run_id = None
            try:
                data = getattr(resp, "data", None)
                if data and isinstance(data, list) and data:
                    run_id = data[0].get("run_id") or data[0].get("id")
            except Exception:
                run_id = None
            return True, "ì €ì¥ ì„±ê³µ", run_id
        except Exception as e:
            return False, f"ì €ì¥ ì‹¤íŒ¨: {e}", None


db = DatabaseService()


# =========================
# 8) Core Logic
# =========================
def intake_schema(user_input: str) -> Dict[str, Any]:
    kw_fallback = extract_keywords_kor(user_input, max_k=10)

    prompt = f"""
ë‹¤ìŒ ë¯¼ì›/ì—…ë¬´ ì§€ì‹œë¥¼ "í–‰ì • ì‚¬ì‹¤ê´€ê³„" ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ë¼.
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€).

{{
  "task_type": "ì£¼ê¸°ìœ„ë°˜|ë¬´ë‹¨ë°©ì¹˜|ë¶ˆë²•ì£¼ì •ì°¨|í–‰ì •ì²˜ë¶„|ì •ë³´ê³µê°œ|ê¸°íƒ€",
  "facts": {{
    "who": "ëŒ€ìƒ(ì°¨ëŸ‰/ê±´ì„¤ê¸°ê³„/ì—…ì²´/ê°œì¸ ë“±)",
    "what": "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€(í•µì‹¬ 1~2ë¬¸ì¥)",
    "where": "ì¥ì†Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "when": "ê¸°ê°„/ì¼ì‹œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "evidence": ["ì‚¬ì§„","ì˜ìƒ","ì§„ìˆ ","ê¸°íƒ€(ì—†ìœ¼ë©´ ë¹ˆë°°ì—´)"]
  }},
  "request": {{
    "user_wants": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ì¡°ì¹˜",
    "constraints": "ê¸°í•œ/ì ˆì°¨/ì´ì˜ì œê¸° ë“±(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "issues": ["ìŸì 1","ìŸì 2"],
  "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4"]
}}

ì…ë ¥:
\"\"\"{user_input}\"\"\"

ì£¼ì˜:
- ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ì€ "ì¶”ê°€ í™•ì¸ í•„ìš”"ë¡œ ì²˜ë¦¬.
- ì¥ì†Œ/ì‹œê°„ì´ ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´.
- keywordsëŠ” ì‚¬ì‹¤ ê¸°ë°˜ í•µì‹¬ì–´ë¡œ.
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}

    if not js:
        js = {
            "task_type": "ê¸°íƒ€",
            "facts": {"who": "", "what": user_input[:120], "where": "", "when": "", "evidence": []},
            "request": {"user_wants": "", "constraints": ""},
            "issues": [],
            "keywords": kw_fallback[:4],
        }

    if not isinstance(js.get("keywords"), list) or not js["keywords"]:
        js["keywords"] = kw_fallback[:4]
    js["keywords"] = [clean_text(x) for x in js["keywords"] if clean_text(x)]
    if not js["keywords"]:
        js["keywords"] = kw_fallback[:4]

    if not isinstance(js.get("issues"), list):
        js["issues"] = []
    js["issues"] = [clean_text(x) for x in js["issues"] if clean_text(x)]

    missing = []
    facts = js.get("facts") if isinstance(js.get("facts"), dict) else {}
    if not clean_text(facts.get("where")):
        missing.append("where")
    if not clean_text(facts.get("when")):
        missing.append("when")
    score = 100 - 20 * len(missing)
    js["_input_quality"] = {"score": max(score, 40), "missing_fields": missing}
    return js


def generate_law_candidates(case: Dict[str, Any]) -> List[Dict[str, Any]]:
    task_type = clean_text(case.get("task_type"))
    facts = case.get("facts") if isinstance(case.get("facts"), dict) else {}
    issues = case.get("issues", [])
    keywords = case.get("keywords", [])

    domain_hint = []
    if task_type == "ì£¼ê¸°ìœ„ë°˜":
        domain_hint += ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì‹œí–‰ë ¹", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¬´ë‹¨ë°©ì¹˜":
        domain_hint += ["ìë™ì°¨ê´€ë¦¬ë²•", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¶ˆë²•ì£¼ì •ì°¨":
        domain_hint += ["ë„ë¡œêµí†µë²•", "ì£¼ì°¨ì¥ë²•"]

    prompt = f"""
ë„ˆëŠ” 'ë²•ë ¹ í›„ë³´ ìƒì„±ê¸°'ë‹¤. ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥.

{{
  "candidates": [
    {{"law_name":"ë²•ë ¹ëª…","article_hint":"ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)","reason":"ì§§ê²Œ","confidence":0.0}}
  ]
}}

ì…ë ¥(ì‚¬ì‹¤ìš”ì•½):
- task_type: {task_type}
- who: {facts.get("who","")}
- what: {facts.get("what","")}
- where: {facts.get("where","")}
- when: {facts.get("when","")}
- issues: {issues}
- keywords: {keywords}

ê·œì¹™:
- candidatesëŠ” 3~6ê°œ
- law_nameì€ ê³µì‹ ë²•ë ¹ëª… ìš°ì„ 
- article_hintëŠ” ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´
- ë‹´ë‹¹ìê°€ "í´ë¦­ìœ¼ë¡œ ì›ë¬¸ í™•ì¸"í•  ìˆ˜ ìˆê²Œ ë„“ê²Œ ë½‘ë˜ ì—‰ëš±í•œ ë¶„ì•¼ëŠ” ì œì™¸
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    cands = js.get("candidates", []) if isinstance(js.get("candidates"), list) else []

    out = []
    for x in domain_hint:
        out.append({"law_name": x, "article_hint": "", "reason": "ë„ë©”ì¸ ê·œì¹™ í›„ë³´", "confidence": 0.35})

    for c in cands:
        if not isinstance(c, dict):
            continue
        ln = clean_text(c.get("law_name"))
        if not ln:
            continue
        out.append({
            "law_name": ln,
            "article_hint": clean_text(c.get("article_hint") or ""),
            "reason": clean_text(c.get("reason") or ""),
            "confidence": float(c.get("confidence") or 0.0),
        })

    # ì¤‘ë³µ ì œê±°
    seen = set()
    uniq = []
    for c in out:
        k = c["law_name"]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(c)
        if len(uniq) >= 8:
            break
    return uniq[:8]


def verifier_score(case: Dict[str, Any], law_name: str, article_title: str, article_text: str) -> Dict[str, Any]:
    keywords = case.get("keywords", [])
    issues = case.get("issues", [])
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}
    text = (article_title + "\n" + article_text).lower()

    hits = 0
    pool = []
    for w in keywords[:8]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in issues[:6]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in extract_keywords_kor(clean_text(facts.get("what", "")), max_k=6):
        pool.append(w)
    pool = list(dict.fromkeys(pool))[:12]

    for w in pool:
        if w and w.lower() in text:
            hits += 1
    relevance = min(35, int((hits / max(1, len(pool))) * 35))

    out_of_scope = ["êµ¬ì†", "ìˆ˜ì‚¬", "ì••ìˆ˜", "ìˆ˜ìƒ‰", "ì²´í¬", "ê¸°ì†Œ", "í˜•ì‚¬", "êµ¬ê¸ˆ"]
    o_hits = sum(1 for w in out_of_scope if w in article_text)
    scope_fit = 25 - min(25, o_hits * 8)
    scope_fit = max(0, scope_fit)

    match = 10
    if len(article_text) >= 200:
        match += 10
    if any(k.lower() in (article_title.lower() if article_title else "") for k in keywords[:4] if k):
        match += 5
    article_match = min(25, match)

    risk = 0
    if not article_text or len(article_text) < 80:
        risk += 10
    if "||" in article_text or ">>" in article_text:
        risk += 5
    risk = min(15, risk)

    total = relevance + scope_fit + article_match + (15 - risk)
    verdict = "CONFIRMED" if total >= 75 else ("WEAK" if total >= 50 else "FAIL")

    return {
        "score_total": int(total),
        "score_breakdown": {
            "relevance": int(relevance),
            "scope_fit": int(scope_fit),
            "article_match": int(article_match),
            "hallucination_risk": int(risk),
        },
        "verdict": verdict,
        "reasons": [
            f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}/{max(1,len(pool))}",
            f"ì›ë¬¸ ê¸¸ì´ {len(article_text)}ì",
        ],
    }


def draft_strategy(case: Dict[str, Any], law_pack: Dict[str, Any], evidence_text: str) -> str:
    prefer = "strict" if law_pack.get("verdict") != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {case.get("task_type")}
[ì‚¬ì‹¤(ìš”ì•½)]
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
[ë¯¼ì› ìš”êµ¬] {case.get("request",{}).get("user_wants","")}
[ìŸì ] {case.get("issues",[])}

[ë²•ì ê·¼ê±°(ì°¸ê³ )]
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸(ìš”ì•½): {truncate_text(law_pack.get("article_text",""), 900)}

[ì°¸ê³ (ë„¤ì´ë²„)]
{truncate_text(evidence_text, 700)}

ì•„ë˜ í˜•ì‹(ë§ˆí¬ë‹¤ìš´)ë§Œ ì¶œë ¥:
1) ì²˜ë¦¬ ë°©í–¥(í˜„ì‹¤ì ì¸ í–‰ì • í”„ë¡œì„¸ìŠ¤ ì¤‘ì‹¬, 5~8ì¤„)
2) ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¶ˆë¦¿ 8~12ê°œ, í™•ì¸/ê¸°ë¡/í†µì§€/ê¸°í•œ í¬í•¨)
3) ë¯¼ì›ì¸ ì„¤ëª… í¬ì¸íŠ¸(ì˜¤í•´ ì¤„ì´ëŠ” ë¬¸ì¥ 3~5ê°œ)
"""
    return llm.generate_text(prompt, prefer=prefer, temp=0.1)


def draft_document_json(dept: str, officer: str, case: Dict[str, Any], law_pack: Dict[str, Any], strategy_md: str) -> Dict[str, Any]:
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"

    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ì‹¤ê´€ê³„(í™•ì •ëœ ë²”ìœ„):
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
- ë¯¼ì›ìš”êµ¬: {case.get("request",{}).get("user_wants","")}
- ì œì•½/ê¸°í•œ: {case.get("request",{}).get("constraints","")}

ë²•ì  ê·¼ê±°(ì°¸ê³ /í™•ë³´ëœ ë²”ìœ„):
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸: {truncate_text(law_pack.get("article_text",""), 1200)}

ì²˜ë¦¬ ì „ëµ(ìš”ì•½):
{truncate_text(strategy_md, 900)}

ì‘ì„± ì›ì¹™:
- ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘, ì¶”ì¸¡ ê¸ˆì§€
- êµ¬ì¡°: [ê²½ìœ„]â†’[ë²•ì  ê·¼ê±°]â†’[ì¡°ì¹˜/ì•ˆë‚´]â†’[ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
- ë²•ë ¹ ì›ë¬¸ì´ ì•½í•˜ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”" ë¬¸êµ¬ í¬í•¨
"""
    js = llm.generate_json(prompt, prefer="strict", max_retry=3)
    out = ensure_doc_shape(js)
    out["_meta"] = {"doc_num": doc_num, "today": today_str}
    return out


# =========================
# 9) Workflow
# =========================
def run_workflow(user_input: str, dept: str, officer: str, user_key: str):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.03)

    started = datetime.now().isoformat()

    add_log("ğŸ§¾ [INTAKE] ì‚¬ì‹¤ê´€ê³„ ì¤‘ì‹¬ êµ¬ì¡°í™”â€¦ (FAST)", "sys")
    case = intake_schema(user_input)
    add_log(f"âœ… [INTAKE] ì™„ë£Œ (quality={case.get('_input_quality',{}).get('score','?')})", "sys")

    add_log("ğŸ§© [LAW-CAND] ë²•ë ¹ í›„ë³´ ìƒì„±â€¦ (FAST)", "legal")
    candidates = generate_law_candidates(case)
    if not candidates:
        candidates = [{"law_name": k, "article_hint": "", "reason": "fallback", "confidence": 0.2} for k in case.get("keywords", [])[:3]]
    add_log("ğŸ“Œ í›„ë³´: " + ", ".join([c['law_name'] for c in candidates[:6]]), "legal")

    add_log("ğŸ“š [LAW] DRF ì›ë¬¸ í™•ë³´ + Verifier(ì°¸ê³ ìš©) ì ìˆ˜í™”â€¦", "legal")
    best_pack = {
        "law_name": "",
        "mst": "",
        "link": "",
        "article_title": "",
        "article_text": "",
        "verdict": "FAIL",
        "score": 0,
        "verify": {},
    }
    loop_debug = []
    for i, cand in enumerate(candidates[:6], start=1):
        q = cand.get("law_name", "")
        art_hint = cand.get("article_hint", "")
        add_log(f"  - ({i}) {q} ê²€ìƒ‰ â†’ ì›ë¬¸ í™•ì¸", "legal")

        laws = law_api.search_law(q, display=10)
        if not laws:
            loop_debug.append({"cand": cand, "search": "no_result"})
            continue

        chosen = laws[0]
        mst = clean_text(chosen.get("MST"))
        law_name = clean_text(chosen.get("lawNm"))
        link = clean_text(chosen.get("link"))

        pack = law_api.get_article_by_mst(mst, article_no=art_hint if art_hint else None)
        article_title = clean_text(pack.get("article_title", ""))
        article_text = clean_text(pack.get("article_text", ""))
        if not article_text:
            loop_debug.append({"cand": cand, "mst": mst, "fetch": "empty"})
            continue

        v = verifier_score(case, law_name, article_title, article_text)
        score = v["score_total"]
        verdict = v["verdict"]

        loop_debug.append({
            "cand": cand,
            "selected": {"law_name": law_name, "mst": mst, "link": link, "article_title": article_title},
            "verify": v
        })

        if score > best_pack["score"]:
            best_pack = {
                "law_name": law_name,
                "mst": mst,
                "link": link,
                "article_title": article_title,
                "article_text": article_text,
                "verdict": verdict,
                "score": score,
                "verify": v,
            }

        if verdict == "CONFIRMED":
            break

    add_log(f"âœ… [LAW] ìë™ì„ íƒ(ì°¸ê³ ): {best_pack.get('law_name','(ì—†ìŒ)')} / {best_pack.get('article_title','')} (score={best_pack.get('score',0)}, {best_pack.get('verdict')})", "legal")

    add_log("ğŸŒ [EVIDENCE] ë„¤ì´ë²„ ìœ ì‚¬ì‚¬ë¡€(ì„ íƒ) ìˆ˜ì§‘â€¦", "search")
    ev_items = []
    ev_text = ""
    kw = case.get("keywords", [])
    if kw:
        q = " ".join(kw[:2]) + " í–‰ì •ì²˜ë¶„"
        raw = naver.search(q, cat="webkr", display=8)
        for item in raw:
            title = clean_text(item.get("title"))
            desc = clean_text(item.get("description"))
            link = clean_text(item.get("link"))
            ev_items.append({"title": title, "desc": desc, "link": link})
            ev_text += f"- {title}: {desc}\n"
    add_log(f"âœ… [EVIDENCE] {len(ev_items)}ê±´", "search")

    add_log("ğŸ§  [STRATEGY] ì²˜ë¦¬ ì „ëµâ€¦ (FAST/STRICT)", "strat")
    strategy = draft_strategy(case, best_pack, ev_text)

    add_log("âœï¸ [DRAFT] ê³µë¬¸ JSON ìƒì„±â€¦ (STRICT)", "draft")
    doc = draft_document_json(dept, officer, case, best_pack, strategy)

    meta = doc.get("_meta", {})
    doc_num = meta.get("doc_num", "")
    today = meta.get("today", "")

    add_log("ğŸ’¾ [SAVE] (ì˜µì…˜) DB ì €ì¥â€¦", "sys")
    db_msg = "DB ë¯¸ì—°ê²°"
    run_id = None
    if db.enabled():
        ok, msg, rid = db.insert_run({
            "user_id": user_key,
            "created_at": started,
            "task_type": clean_text(case.get("task_type","")),
            "input_text": user_input,
            "input_quality_score": int(case.get("_input_quality",{}).get("score", 0)),
            "final_verdict": best_pack.get("verdict"),
            "law_name": best_pack.get("law_name"),
            "law_mst": best_pack.get("mst"),
            "total_tokens": int(st.session_state.get("metrics",{}).get("tokens_total",0)),
            "status": "DONE",
            "result_json": safe_json_dump({
                "case": case, "best_law": best_pack, "strategy": strategy, "doc": ensure_doc_shape(doc), "candidates": candidates
            })
        })
        db_msg = msg
        run_id = rid

    add_log(f"âœ… ì™„ë£Œ ({db_msg})", "sys")
    time.sleep(0.25)
    log_area.empty()

    return {
        "case": case,
        "candidates": candidates,     # âœ… í›„ë³´ ë¦¬ìŠ¤íŠ¸(í´ë¦­í˜• UI í•µì‹¬)
        "best_law": best_pack,        # âœ… ìë™ì„ íƒ(ì°¸ê³ ìš©)
        "strategy": strategy,
        "doc": ensure_doc_shape(doc),
        "doc_meta": {"doc_num": doc_num, "today": today, "dept": dept, "officer": officer},
        "ev_items": ev_items,
        "loop_debug": loop_debug,
        "db_msg": db_msg,
        "run_id": run_id,
    }


# =========================
# 10) íŒë‹¨ UI(í´ë¦­í˜• ì›ë¬¸/ì‚¬ë¡€)
# =========================
def ss_init():
    st.session_state.setdefault("selected_mst", "")
    st.session_state.setdefault("selected_law_name", "")
    st.session_state.setdefault("selected_article_no", "")
    st.session_state.setdefault("selected_article_title", "")
    st.session_state.setdefault("selected_article_text", "")
    st.session_state.setdefault("selected_law_link", "")
    st.session_state.setdefault("case_examples", [])
ss_init()


def build_law_link_fallback(mst: str) -> str:
    # DRF linkê°€ ì—†ì„ ë•Œë„ ìµœì†Œí•œì˜ ì´ë™ ê²½ë¡œ ì œê³µ
    if not mst:
        return ""
    return f"https://www.law.go.kr/LSW/lsInfoP.do?lsiSeq={mst}"


def ui_law_browser(case: dict, candidates: list):
    st.markdown("## âš–ï¸ ë²•ë ¹ í›„ë³´ (ì›ë¬¸/ì‚¬ë¡€ í´ë¦­í•´ì„œ íŒë‹¨)")
    st.caption("ìë™ì„ íƒì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤. í›„ë³´ë¥¼ ëˆŒëŸ¬ ì›ë¬¸ê³¼ ì‚¬ë¡€ë¥¼ ì§ì ‘ ë³´ê³  í™•ì •í•˜ì„¸ìš”.")

    if not candidates:
        st.warning("ë²•ë ¹ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ë‚´ìš©ì„ ë” êµ¬ì²´í™”í•˜ì„¸ìš”(ëŒ€ìƒ/ì¥ì†Œ/ê¸°ê°„/ì¦ê±°).")
        return

    for idx, c in enumerate(candidates[:8], start=1):
        law_name = clean_text(c.get("law_name",""))
        article_hint = clean_text(c.get("article_hint",""))
        reason = clean_text(c.get("reason",""))
        conf = c.get("confidence", 0.0)

        st.markdown(
            f"<div class='cand-row'><div><b>{idx}. {escape(law_name)}</b></div>"
            f"<div class='cand-sub'>íŒíŠ¸ ì¡°ë¬¸: {escape(article_hint or '-')} Â· ì‹ ë¢°ë„: {conf}</div>"
            f"<div class='cand-sub'>ì‚¬ìœ : {escape(reason or '')}</div></div>",
            unsafe_allow_html=True
        )

        colA, colB = st.columns([1, 1])
        with colA:
            if st.button("ğŸ“œ ì›ë¬¸ ë³´ê¸°", key=f"btn_law_open_{idx}", use_container_width=True):
                laws = law_api.search_law(law_name, display=10)
                if not laws:
                    st.warning(f"'{law_name}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                else:
                    chosen = laws[0]
                    mst = clean_text(chosen.get("MST"))
                    ln = clean_text(chosen.get("lawNm")) or law_name
                    link = clean_text(chosen.get("link")) or build_law_link_fallback(mst)

                    pack = law_api.get_article_by_mst(mst, article_no=article_hint if article_hint else None)
                    st.session_state["selected_mst"] = mst
                    st.session_state["selected_law_name"] = ln
                    st.session_state["selected_article_no"] = clean_text(pack.get("article_no",""))
                    st.session_state["selected_article_title"] = clean_text(pack.get("article_title",""))
                    st.session_state["selected_article_text"] = clean_text(pack.get("article_text",""))
                    st.session_state["selected_law_link"] = link

        with colB:
            if st.button("ğŸ§© ìœ ì‚¬ì‚¬ë¡€", key=f"btn_case_{idx}", use_container_width=True):
                kw = case.get("keywords", [])
                base = " ".join([clean_text(x) for x in kw[:2] if clean_text(x)])
                q = f"{law_name} {article_hint} {base}".strip()
                items = naver.search(q, cat="webkr", display=10)
                ex = []
                for it in items:
                    ex.append({
                        "title": clean_text(it.get("title")),
                        "desc": clean_text(it.get("description")),
                        "link": clean_text(it.get("link")),
                    })
                st.session_state["case_examples"] = ex

        st.markdown("---")


def ui_law_viewer():
    st.markdown("## ğŸ“œ ì„ íƒí•œ ë²•ë ¹ ì›ë¬¸")
    mst = st.session_state.get("selected_mst","")
    if not mst:
        st.info("ìœ„ í›„ë³´ì—ì„œ **ì›ë¬¸ ë³´ê¸°**ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        return

    law_name = st.session_state.get("selected_law_name","")
    art_title = st.session_state.get("selected_article_title","")
    art_text = st.session_state.get("selected_article_text","")
    link = st.session_state.get("selected_law_link","")

    st.markdown(f"**ë²•ë ¹:** {law_name}")
    if link:
        st.markdown(f"**ìƒì„¸ ë§í¬:** [{link}]({link})")

    # ì¡°ë¬¸ ì¸ë±ìŠ¤ ì œê³µ
    pack_idx = law_api.get_article_by_mst(mst, article_no=None) or {}
    idx_list = pack_idx.get("all_articles_index", []) if isinstance(pack_idx.get("all_articles_index"), list) else []

    if idx_list:
        pick = st.selectbox("ì¡°ë¬¸ ì´ë™", ["(í˜„ì¬ ì¡°ë¬¸ ìœ ì§€)"] + idx_list)
        if pick != "(í˜„ì¬ ì¡°ë¬¸ ìœ ì§€)":
            m = re.search(r"ì œ(\d+)ì¡°", pick)
            if m:
                art_no = m.group(1)
                pack2 = law_api.get_article_by_mst(mst, article_no=art_no) or {}
                st.session_state["selected_article_title"] = clean_text(pack2.get("article_title",""))
                st.session_state["selected_article_text"] = clean_text(pack2.get("article_text",""))
                art_title = st.session_state["selected_article_title"]
                art_text = st.session_state["selected_article_text"]

    st.markdown(f"### {art_title or 'ì¡°ë¬¸'}")
    if not art_text:
        st.warning("ì¡°ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í›„ë³´ë¥¼ ëˆŒëŸ¬ë³´ì„¸ìš”.")
        return

    with st.expander("ì›ë¬¸ ì „ë¬¸ í¼ì¹˜ê¸°", expanded=True):
        st.code(normalize_whitespace(strip_hanja_for_display(art_text)), language="text")


def ui_case_examples():
    st.markdown("## ğŸ§© ìœ ì‚¬ì‚¬ë¡€(í´ë¦­í•´ì„œ í™•ì¸)")
    ex = st.session_state.get("case_examples", []) or []
    if not ex:
        st.info("ë²•ë ¹ í›„ë³´ì—ì„œ **ìœ ì‚¬ì‚¬ë¡€** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì—¬ê¸°ì— ëœ¹ë‹ˆë‹¤.")
        return

    for it in ex[:12]:
        title = clean_text(it.get("title",""))
        desc = clean_text(it.get("desc",""))
        link = clean_text(it.get("link",""))
        if link:
            st.markdown(f"- **[{title}]({link})**  \n  {desc}")
        else:
            st.markdown(f"- **{title}**  \n  {desc}")


# =========================
# 11) Renderers
# =========================
def render_a4(doc: Dict[str, Any], meta: Dict[str, str]):
    body_html = "".join([f"<p style='margin:0 0 14px 0;'>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])])
    html = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc.get('title',''))}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {safe_html(meta.get('doc_num',''))}</span>
    <span>ì‹œí–‰ì¼ì: {safe_html(meta.get('today',''))}</span>
    <span>ìˆ˜ì‹ : {safe_html(doc.get('receiver',''))}</span>
  </div>
  <div class="doc-body">
    {body_html}
  </div>
  <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
</div>
"""
    components.html(html, height=920, scrolling=True)


# =========================
# 12) Main UI
# =========================
def main():
    st.session_state.setdefault("user_key", "local_user")
    st.session_state.setdefault("dept", "OOì‹œì²­ OOê³¼")
    st.session_state.setdefault("officer", "ê¹€ì£¼ë¬´ê´€")

    col_l, col_r = st.columns([1, 1.25], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("Dual Router v7.0 â€” í´ë¦­í˜• ì›ë¬¸/ì‚¬ë¡€ ê¸°ë°˜ 'íŒë‹¨ UI' + A4 ê³µë¬¸ ë Œë”ë§")
        st.markdown("---")

        with st.expander("ğŸ§© ì‚¬ìš©ì/ë¶€ì„œ ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.text_input("ì‚¬ìš©ì í‚¤(íˆìŠ¤í† ë¦¬ êµ¬ë¶„ìš©, ì„ì˜)", key="user_key")
            st.caption("â€» Supabase ë¯¸ì„¤ì •ì´ì–´ë„ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­(ë¯¼ì› ìƒí™© í¬í•¨)",
            height=240,
            placeholder="ì˜ˆ: ê±´ì„¤ê¸°ê³„ê°€ ì°¨ê³ ì§€ ì™¸ ì¥ê¸°ê°„ ì£¼ì°¨(ì£¼ê¸°ìœ„ë°˜) ì‹ ê³ ê°€ ë“¤ì–´ì˜´. í˜„ì¥ í™•ì¸í–ˆë”ë‹ˆ ì´ë™í•œ ìƒíƒœ. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì†ì„ ìš”êµ¬. ë‹´ë‹¹ìê°€ í•  ìˆ˜ ìˆëŠ” ì¡°ì¹˜ì™€ ê³µë¬¸ ì´ˆì•ˆ ì‘ì„±.",
        )

        if st.button("ğŸš€ ì‹¤í–‰(êµ¬ì¡°í™”â†’ë²•ë ¹í›„ë³´â†’ì›ë¬¸í™•ë³´â†’ê³µë¬¸ì‘ì„±)", type="primary", use_container_width=True):
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì‹¤í–‰ ì¤‘..."):
                    try:
                        res = run_workflow(
                            user_input.strip(),
                            st.session_state["dept"],
                            st.session_state["officer"],
                            st.session_state["user_key"],
                        )
                        st.session_state["result"] = res

                        # ìë™ì„ íƒ ë²•ë ¹ì„ ìš°ì„  'ì„ íƒ ìƒíƒœ'ì— ë¡œë“œ(ë°”ë¡œ ì›ë¬¸íƒ­ì—ì„œ ë³´ì´ê²Œ)
                        best = res.get("best_law", {}) or {}
                        if best.get("mst"):
                            st.session_state["selected_mst"] = best.get("mst","")
                            st.session_state["selected_law_name"] = best.get("law_name","")
                            st.session_state["selected_article_title"] = best.get("article_title","")
                            st.session_state["selected_article_text"] = best.get("article_text","")
                            st.session_state["selected_law_link"] = best.get("link","") or build_law_link_fallback(best.get("mst",""))
                    except Exception as e:
                        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

        # Metrics
        st.markdown("---")
        st.subheader("ğŸ“Š ì„¸ì…˜ ì‚¬ìš©ëŸ‰")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)
        if calls:
            for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                st.write(f"- **{k}**: {v}íšŒ")
            st.caption(f"ì´ í† í°(ê°€ëŠ¥í•œ ê²½ìš°): {tokens_total}")
        else:
            st.info("ëŒ€ê¸° ì¤‘...")

        st.markdown(
            "<div class='small-muted'>í•µì‹¬: ìë™ì„ íƒì€ ì°¸ê³ ìš©. ë‹´ë‹¹ìëŠ” í›„ë³´ë¥¼ í´ë¦­í•´ ì›ë¬¸Â·ì‚¬ë¡€ë¥¼ ì§ì ‘ í™•ì¸í•˜ê³  íŒë‹¨í•©ë‹ˆë‹¤.</div>",
            unsafe_allow_html=True
        )

    with col_r:
        tab_doc, tab_law, tab_case, tab_debug = st.tabs(["ğŸ“„ ê³µë¬¸(A4)", "âš–ï¸ ë²•ë ¹ ì›ë¬¸", "ğŸ§© ìœ ì‚¬ì‚¬ë¡€", "ğŸ§ª ë””ë²„ê·¸"])
        res = st.session_state.get("result")

        with tab_doc:
            if not res:
                st.markdown(
                    """
<div style='text-align:center; padding:120px 20px; color:#9ca3af; border:2px dashed #e5e7eb; border-radius:14px; background:#fff;'>
  <h3 style='margin-bottom:8px;'>ğŸ“„ A4 ë¯¸ë¦¬ë³´ê¸°</h3>
  <p>ì™¼ìª½ì—ì„œ ë¯¼ì› ìƒí™©ì„ ì…ë ¥í•˜ê³  ì‹¤í–‰ì„ ëˆ„ë¥´ì„¸ìš”.<br>ê³µë¬¸ì´ A4 í˜•íƒœë¡œ ìë™ ë Œë”ë§ë©ë‹ˆë‹¤.</p>
</div>
""",
                    unsafe_allow_html=True,
                )
            else:
                render_a4(res["doc"], res["doc_meta"])

        with tab_law:
            if not res:
                st.info("ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ì™¼ìª½ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")
            else:
                ui_law_browser(res.get("case", {}), res.get("candidates", []))
                ui_law_viewer()

        with tab_case:
            ui_case_examples()

        with tab_debug:
            if not res:
                st.info("ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"DB ì €ì¥: {res.get('db_msg','')}")
                st.markdown("### 1) êµ¬ì¡°í™”ëœ ì¼€ì´ìŠ¤(case)")
                st.json(res.get("case", {}))

                st.markdown("### 2) ìë™ì„ íƒ(ì°¸ê³ ìš©) best_law")
                st.json(res.get("best_law", {}))

                st.markdown("### 3) ì „ëµ(strategy)")
                st.markdown(res.get("strategy",""))

                st.markdown("### 4) ë²•ë ¹ í›„ë³´ ë£¨í”„ ë””ë²„ê·¸(loop_debug)")
                st.json(res.get("loop_debug", []))


if __name__ == "__main__":
    main()
```î¨0î¨‚
