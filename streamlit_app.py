# streamlit_app.py
# âœ… ì™„ì„¸íŠ¸ (secrets ì¸ì‹ fix + 414 ë°©ì–´ + law_api_service ë¯¸ì •ì˜ í•´ê²° + google.genai ë§ˆì´ê·¸ë ˆì´ì…˜ + ì•ˆì „í•œ fallback)
#
# requirements.txt ì˜ˆì‹œ
# streamlit
# google-genai
# groq
# supabase
# requests
#
# âœ… secrets.toml ì˜ˆì‹œ (í”„ë¡œì íŠ¸/.streamlit/secrets.toml ë˜ëŠ” Streamlit Cloud Secretsì— ë¶™ì—¬ë„£ê¸°)
# [general]
# GEMINI_API_KEY = "..."
# LAW_API_ID = "..."
# GROQ_API_KEY = "..."
# NAVER_CLIENT_ID = "..."
# NAVER_CLIENT_SECRET = "..."
#
# [supabase]
# SUPABASE_URL = "..."
# SUPABASE_KEY = "..."

import streamlit as st

# google-genai (ì‹ í˜•)
from google import genai
from google.genai import types

from groq import Groq
from supabase import create_client

import json
import re
import time
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from html import escape as _escape


# ==========================================
# 0. Helpers
# ==========================================
def _get_secret(section: str, key: str, default=None):
    """
    âœ… Streamlit SecretsëŠ” dictê°€ ì•„ë‹ˆë¼ dict-like ê°ì²´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    isinstance(dict) ì²´í¬ ê¸ˆì§€. ê·¸ëƒ¥ dictì²˜ëŸ¼ ì ‘ê·¼.
    """
    try:
        if section not in st.secrets:
            return default
        return st.secrets[section].get(key, default)
    except Exception:
        return default


def _extract_json(text: str):
    """ëª¨ë¸ì´ JSONì„ ì¡°ê¸ˆ ê¹¨ë„ ìµœëŒ€í•œ ë³µêµ¬."""
    if not text:
        return None
    t = text.strip()

    # ```json ... ``` ì œê±°
    t = re.sub(r"^```(?:json)?\s*", "", t, flags=re.IGNORECASE)
    t = re.sub(r"\s*```$", "", t)

    # ë°°ì—´ ìš°ì„ 
    m = re.search(r"\[[\s\S]*\]", t)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            pass

    # ê°ì²´
    m = re.search(r"\{[\s\S]*\}", t)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            pass

    return None


# ==========================================
# 1. Configuration & Styles
# ==========================================
st.set_page_config(layout="wide", page_title="AI Bureau: The Legal Glass", page_icon="âš–ï¸")

st.markdown(
    """
<style>
    .stApp { background-color: #f3f4f6; }

    .paper-sheet {
        background-color: white;
        width: 100%;
        max-width: 210mm;
        min-height: 297mm;
        padding: 25mm;
        margin: auto;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        font-family: 'Batang', serif;
        color: #111;
        line-height: 1.6;
        position: relative;
    }

    .doc-header { text-align: center; font-size: 22pt; font-weight: 900; margin-bottom: 30px; letter-spacing: 2px; }
    .doc-info { display: flex; justify-content: space-between; gap: 12px; font-size: 11pt; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 20px; flex-wrap: wrap; }
    .doc-body { font-size: 12pt; text-align: justify; white-space: pre-line; }
    .doc-footer { text-align: center; font-size: 20pt; font-weight: bold; margin-top: 80px; letter-spacing: 5px; }
    .stamp { position: absolute; bottom: 85px; right: 80px; border: 3px solid #cc0000; color: #cc0000; padding: 5px 10px; font-size: 14pt; font-weight: bold; transform: rotate(-15deg); opacity: 0.8; border-radius: 5px; }

    .agent-log { font-family: 'Consolas', monospace; font-size: 0.85rem; padding: 6px 12px; border-radius: 6px; margin-bottom: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    .log-legal { background-color: #eff6ff; color: #1e40af; border-left: 4px solid #3b82f6; }
    .log-search { background-color: #fff7ed; color: #c2410c; border-left: 4px solid #f97316; }
    .log-strat { background-color: #f5f3ff; color: #6d28d9; border-left: 4px solid #8b5cf6; }
    .log-calc { background-color: #f0fdf4; color: #166534; border-left: 4px solid #22c55e; }
    .log-draft { background-color: #fef2f2; color: #991b1b; border-left: 4px solid #ef4444; }
    .log-sys { background-color: #f3f4f6; color: #4b5563; border-left: 4px solid #9ca3af; }
</style>
""",
    unsafe_allow_html=True,
)


# ==========================================
# 2. Infrastructure Layer (Services)
# ==========================================
class LLMService:
    """
    [Model Hierarchy]
    1. Gemini 2.5 Flash
    2. Gemini 2.5 Flash Lite
    3. Gemini 2.0 Flash
    4. Groq (Llama 3 Backup)
    """

    def __init__(self):
        self.gemini_key = _get_secret("general", "GEMINI_API_KEY")
        self.groq_key = _get_secret("general", "GROQ_API_KEY")

        self.gemini_models = [
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
        ]

        self.gemini_client = None
        if self.gemini_key:
            try:
                self.gemini_client = genai.Client(api_key=self.gemini_key)
            except Exception:
                self.gemini_client = None

        self.groq_client = Groq(api_key=self.groq_key) if self.groq_key else None

    def _try_gemini(self, prompt: str):
        if not self.gemini_client:
            raise Exception("Gemini client not configured")

        last_err = None
        for model_name in self.gemini_models:
            try:
                res = self.gemini_client.models.generate_content(
                    model=model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        temperature=0.1,
                        max_output_tokens=2048,
                    ),
                )
                text = (getattr(res, "text", None) or "").strip()
                if text:
                    return text, model_name
            except Exception as e:
                last_err = e
                continue
        raise Exception(f"All Gemini models failed: {last_err}")

    def _generate_groq(self, prompt: str) -> str:
        if not self.groq_client:
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜: AI ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨ (GROQ_API_KEY ì—†ìŒ)"
        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            return completion.choices[0].message.content
        except Exception:
            return "System Error"

    def generate_text(self, prompt: str) -> str:
        try:
            text, _ = self._try_gemini(prompt)
            return text
        except Exception:
            return self._generate_groq(prompt)

    def generate_json(self, prompt: str):
        strict = (
            prompt
            + "\n\n"
            + "ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…/ë¬¸ì¥/ë§ˆí¬ë‹¤ìš´/ì½”ë“œíœìŠ¤ ê¸ˆì§€.\n"
            + "ê°€ëŠ¥í•˜ë©´ ë°°ì—´/ê°ì²´ í˜•íƒœë¡œë§Œ ì¶œë ¥."
        )
        text = self.generate_text(strict)
        return _extract_json(text)


class SearchService:
    """
    âœ… Hybrid Search Engine
    - 414(URI Too Long) ë°©ì–´ í¬í•¨
    """

    def __init__(self):
        self.client_id = _get_secret("general", "NAVER_CLIENT_ID")
        self.client_secret = _get_secret("general", "NAVER_CLIENT_SECRET")

        self.web_url = "https://openapi.naver.com/v1/search/webkr.json"
        self.news_url = "https://openapi.naver.com/v1/search/news.json"

        self.whitelist_domains = [
            "law.go.kr",
            "scourt.go.kr",
            "acrc.go.kr",
            "korea.kr",
            "go.kr",
            "moj.go.kr",
            "police.go.kr",
            "easylaw.go.kr",
            "moleg.go.kr",
        ]
        self.blacklist_domains = [
            "blog.naver.com",
            "m.blog.naver.com",
            "cafe.naver.com",
            "m.cafe.naver.com",
            "post.naver.com",
            "tistory.com",
            "brunch.co.kr",
            "youtube.com",
            "youtu.be",
            "instagram.com",
            "facebook.com",
            "namu.wiki",
            "kin.naver.com",
        ]
        self.signal_keywords = [
            "í–‰ì •ì‹¬íŒ",
            "ì¬ê²°",
            "ì²˜ë¶„",
            "ê³¼íƒœë£Œ",
            "ì´í–‰ëª…ë ¹",
            "ì‚¬ì „í†µì§€",
            "ì˜ê²¬ì œì¶œ",
            "ì²­ë¬¸",
            "í–‰ì •ì ˆì°¨ë²•",
            "íŒê²°",
            "íŒë¡€",
            "ëŒ€ë²•ì›",
            "ì¡°ë¡€",
            "ì‹œí–‰ê·œì¹™",
            "ê³ ì‹œ",
            "í›ˆë ¹",
            "ì˜ˆê·œ",
            "ì§€ì¹¨",
            "ê³µê³ ",
        ]

    def _headers(self):
        return {
            "X-Naver-Client-Id": self.client_id or "",
            "X-Naver-Client-Secret": self.client_secret or "",
        }

    def _naver_search(self, url: str, query: str, display: int = 10):
        params = {"query": query, "display": display, "start": 1, "sort": "sim"}
        res = requests.get(url, headers=self._headers(), params=params, timeout=8)
        res.raise_for_status()
        return res.json()

    def _clean_html(self, s: str) -> str:
        if not s:
            return ""
        s = re.sub(r"</?b>", "", s)
        s = re.sub(r"<[^>]+>", "", s)
        return s.strip()

    def _get_domain(self, link: str) -> str:
        if not link:
            return ""
        m = re.search(r"https?://([^/]+)", link)
        return (m.group(1).lower() if m else "").strip()

    def _is_blacklisted(self, domain: str) -> bool:
        d = (domain or "").lower()
        return any(bad in d for bad in self.blacklist_domains)

    def _whitelist_score(self, domain: str) -> int:
        d = (domain or "").lower()
        score = 0
        for good in self.whitelist_domains:
            if good == "go.kr":
                if d.endswith(".go.kr") or d == "go.kr" or ".go.kr" in d:
                    score += 8
            else:
                if good in d:
                    score += 10
        return score

    def _keyword_score(self, text: str) -> int:
        t = (text or "").lower()
        score = 0
        for kw in self.signal_keywords:
            if kw.lower() in t:
                score += 2
        return score

    def _score_item(self, title: str, desc: str, link: str) -> int:
        domain = self._get_domain(link)
        if self._is_blacklisted(domain):
            return -999
        score = 0
        score += self._whitelist_score(domain)
        score += self._keyword_score(title) * 2
        score += self._keyword_score(desc)
        if len((desc or "").strip()) < 25:
            score -= 3
        if not (link or "").startswith("http"):
            score -= 5
        return score

    def _shrink_query(self, q: str, max_tokens: int = 10, max_chars: int = 80) -> str:
        q = re.sub(r"\s+", " ", (q or "")).strip()
        q = " ".join(q.split()[:max_tokens])
        if len(q) > max_chars:
            q = q[:max_chars].rstrip()
        return q

    def _optimize_query_llm(self, situation: str) -> str:
        # âœ… 414 ë°©ì–´ ì „ì œ(ì§§ê²Œ!)
        prompt = f"""
ë‹¹ì‹ ì€ í–‰ì • ë°ì´í„° ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ìƒí™©ì„ í•´ê²°í•˜ê¸° ìœ„í•œ 'ê²€ìƒ‰ í‚¤ì›Œë“œ'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

[ìƒí™©]: "{situation}"

[ê·œì¹™]
- ë¬¸ì¥ ê¸ˆì§€, í‚¤ì›Œë“œë§Œ
- ê³µë°± ê¸°ì¤€ 10í† í° ì´í•˜
- 60ì ì´í•˜
- í–‰ì • ì‹¤ë¬´ ìš©ì–´ í¬í•¨(ì²˜ë¶„/ë¶ˆë³µ/ì¬ê²°/ê³¼íƒœë£Œ/ì‚¬ì „í†µì§€/ì˜ê²¬ì œì¶œ ë“±)
"""
        try:
            q = (llm_service.generate_text(prompt) or "").strip()
            q = re.sub(r'["\']', "", q)
            return self._shrink_query(q, max_tokens=10, max_chars=80)
        except Exception:
            return self._shrink_query(situation, max_tokens=10, max_chars=80)

    def _rerank_results_llm(self, situation: str, candidate_items: list) -> list:
        if not candidate_items:
            return []
        ctx = ""
        for idx, item in enumerate(candidate_items[:7]):
            ctx += f"[{idx}] ì œëª©: {item['title']} / ë‚´ìš©: {item['desc']} / ì¶œì²˜: {item['domain']}\n"

        prompt = f"""
[ì—­í• ] ë² í…Œë‘ í–‰ì • ê³µë¬´ì›
[ìƒí™©] "{situation}"
[ì„ë¬´] ì•„ë˜ í›„ë³´ ì¤‘ ì‹ ë¢°/ì‹¤ë¬´ë„ì›€ ìˆœì„œë¡œ ì¸ë±ìŠ¤ë§Œ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥.

[í›„ë³´]
{ctx}

ì¶œë ¥ ì˜ˆ: [2,0,5]
"""
        try:
            ranking = llm_service.generate_json(prompt)
            if isinstance(ranking, list) and ranking:
                out = []
                for i in ranking:
                    if isinstance(i, int) and 0 <= i < len(candidate_items):
                        out.append(candidate_items[i])
                return out or candidate_items
            return candidate_items
        except Exception:
            return candidate_items

    def search_precedents(self, situation: str, top_k: int = 3) -> str:
        if not self.client_id or not self.client_secret:
            return "âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        optimized_query = self._optimize_query_llm(situation)

        # âœ… 414 ë°©ì§€: ì§§ê²Œ + site í•˜ë‚˜
        final_query = f"{optimized_query} site:go.kr"

        try:
            web_res = self._naver_search(self.web_url, final_query, display=10)
            news_res = self._naver_search(self.news_url, final_query, display=10)

        except requests.HTTPError as e:
            # âœ… 414ë©´ ë” ì¤„ì—¬ ì¬ì‹œë„
            if "414" in str(e):
                shorter = self._shrink_query(optimized_query, max_tokens=6, max_chars=50)
                final_query = f"{shorter} site:go.kr"
                web_res = self._naver_search(self.web_url, final_query, display=10)
                news_res = self._naver_search(self.news_url, final_query, display=10)
            else:
                return f"ë„¤ì´ë²„ API í˜¸ì¶œ ì˜¤ë¥˜: {e}"
        except Exception as e:
            return f"ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜: {e}"

        merged = []
        seen = set()
        for src_name, payload in [("ì›¹", web_res), ("ë‰´ìŠ¤", news_res)]:
            for it in (payload.get("items", []) or []):
                link = it.get("link", "#")
                if link in seen:
                    continue
                seen.add(link)
                title = self._clean_html(it.get("title", ""))
                desc = self._clean_html(it.get("description", ""))
                score = self._score_item(title, desc, link)
                if score > -100:
                    merged.append(
                        {
                            "src": src_name,
                            "title": title,
                            "desc": desc,
                            "link": link,
                            "domain": self._get_domain(link),
                            "score": score,
                        }
                    )

        if not merged:
            # site ì œí•œì´ ë„ˆë¬´ ì„¸ë©´ í•œ ë²ˆ ë” ì™„í™”
            try:
                fallback_query = self._shrink_query(optimized_query, max_tokens=6, max_chars=50)
                web_res = self._naver_search(self.web_url, fallback_query, display=10)
                for it in (web_res.get("items", []) or []):
                    link = it.get("link", "#")
                    title = self._clean_html(it.get("title", ""))
                    desc = self._clean_html(it.get("description", ""))
                    score = self._score_item(title, desc, link)
                    if score > -100:
                        merged.append(
                            {
                                "src": "ì›¹",
                                "title": title,
                                "desc": desc,
                                "link": link,
                                "domain": self._get_domain(link),
                                "score": score,
                            }
                        )
            except Exception:
                pass

        if not merged:
            return f"ê²€ìƒ‰ì–´ '{optimized_query}'ì— ëŒ€í•œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        merged.sort(key=lambda x: x["score"], reverse=True)
        candidates = merged[:7]
        final_items = self._rerank_results_llm(situation, candidates)[:top_k]

        lines = [
            f"ğŸ” **AI ìµœì í™” ê²€ìƒ‰ì–´:** `{optimized_query}`",
            f"ğŸ§  **AI ì„ ë³„ ê²°ê³¼ (Top {len(final_items)})**",
            "---",
        ]
        for it in final_items:
            lines.append(f"- ({it['src']}) **[{it['title']}]({it['link']})** `[{it['domain']}]`\n  : {it['desc']}")
        return "\n".join(lines)


class DatabaseService:
    """Supabase Persistence Layer"""

    def __init__(self):
        try:
            self.url = _get_secret("supabase", "SUPABASE_URL")
            self.key = _get_secret("supabase", "SUPABASE_KEY")
            if self.url and self.key:
                self.client = create_client(self.url, self.key)
                self.is_active = True
            else:
                self.client = None
                self.is_active = False
        except Exception:
            self.client = None
            self.is_active = False

    def save_log(self, user_input, legal_basis, strategy, doc_data):
        if not self.is_active:
            return "DB ë¯¸ì—°ê²° (ì €ì¥ ê±´ë„ˆëœ€)"
        try:
            final_summary_content = {"strategy": strategy, "document_content": doc_data}
            data = {
                "situation": user_input,
                "law_name": legal_basis,
                "summary": json.dumps(final_summary_content, ensure_ascii=False),
            }
            self.client.table("law_reports").insert(data).execute()
            return "DB ì €ì¥ ì„±ê³µ"
        except Exception as e:
            return f"DB ì €ì¥ ì‹¤íŒ¨: {e}"


class LawOfficialService:
    """
    êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°(law.go.kr) ê³µì‹ API ì—°ë™
    """

    def __init__(self):
        self.api_id = _get_secret("general", "LAW_API_ID")
        self.base_url = "http://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "http://www.law.go.kr/DRF/lawService.do"

    def get_law_text(self, law_name, article_num=None):
        if not self.api_id:
            return "âš ï¸ API ID(OC)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        law_name = (law_name or "").strip()
        if not law_name:
            return "âš ï¸ ë²•ë ¹ëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

        # 1) ê²€ìƒ‰ -> MST
        try:
            params = {"OC": self.api_id, "target": "law", "type": "XML", "query": law_name, "display": 1}
            res = requests.get(self.base_url, params=params, timeout=8)
            root = ET.fromstring(res.content)

            law_node = root.find(".//law")
            if law_node is None:
                return f"ğŸ” '{law_name}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

            mst_id_node = law_node.find("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸")
            link_node = law_node.find("ë²•ë ¹ìƒì„¸ë§í¬")
            mst_id = mst_id_node.text.strip() if mst_id_node is not None and mst_id_node.text else None
            full_link = link_node.text.strip() if link_node is not None and link_node.text else ""

            if not mst_id:
                return f"ğŸ” '{law_name}' ê²€ìƒ‰ì€ ëì§€ë§Œ MST ì¶”ì¶œ ì‹¤íŒ¨"
        except Exception as e:
            return f"API ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}"

        # 2) ìƒì„¸ -> ì¡°ë¬¸ íƒìƒ‰
        try:
            detail_params = {"OC": self.api_id, "target": "law", "type": "XML", "MST": mst_id}
            res_detail = requests.get(self.service_url, params=detail_params, timeout=12)
            root_detail = ET.fromstring(res_detail.content)

            # article_num ì—†ìœ¼ë©´ ë§í¬ë§Œ
            if not article_num:
                return f"âœ… '{law_name}'ì´(ê°€) í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\nğŸ”— ì›ë¬¸ ë³´ê¸°: {full_link}"

            for article in root_detail.findall(".//ì¡°ë¬¸ë‹¨ìœ„"):
                jo_num = article.find("ì¡°ë¬¸ë²ˆí˜¸")
                jo_cont = article.find("ì¡°ë¬¸ë‚´ìš©")
                if jo_num is None or jo_cont is None:
                    continue
                current_num = (jo_num.text or "").strip()
                if str(article_num) == current_num:
                    body = (jo_cont.text or "").strip()
                    out = f"[{law_name} ì œ{current_num}ì¡° ì „ë¬¸]\n{_escape(body)}"
                    # í•­ë‚´ìš©
                    for hang in article.findall(".//í•­"):
                        hang_cont = hang.find("í•­ë‚´ìš©")
                        if hang_cont is not None and hang_cont.text:
                            out += f"\n  - {hang_cont.text.strip()}"
                    return out

            return f"âœ… '{law_name}'ì´(ê°€) í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n(ìš”ì²­ ì¡°ë¬¸ ìë™ ì¶”ì¶œ ì‹¤íŒ¨: ì œ{article_num}ì¡°)\nğŸ”— ì›ë¬¸ ë³´ê¸°: {full_link}"

        except Exception as e:
            return f"ìƒì„¸ ë²•ë ¹ íŒŒì‹± ì‹¤íŒ¨: {e}"


# ==========================================
# 3. Agents
# ==========================================
class LegalAgents:
    @staticmethod
    def researcher(situation):
        """
        - ì‹¤ì²´ë²• + ì •ì˜/ë°˜ë°• + ì ˆì°¨ë²•ê¹Œì§€ ìµœëŒ€ 4ê°œ
        - categoryë¥¼ ë„£ì–´ strategistê°€ ì ˆì°¨ë²• ì¸ìš©ì„ ê°•ì œí•˜ê¸° ì‰¬ì›€
        """
        prompt_extract = f"""
ìƒí™©: "{situation}"

í•„ìš” ë²•ë ¹/ì¡°ë¬¸ì„ ì•„ë˜ ì¹´í…Œê³ ë¦¬ì— ë§ì¶° ìµœëŒ€ 4ê°œê¹Œì§€ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ.
ì¹´í…Œê³ ë¦¬:
- violation (ì‹¤ì²´ë²• ìœ„ë°˜ì¡°í•­)
- definition (ì •ì˜/ë°˜ë°• ì¡°í•­)
- procedure (ì ˆì°¨/ì£¼ì˜ ì¡°í•­: í–‰ì •ì ˆì°¨ë²•, ì§ˆì„œìœ„ë°˜í–‰ìœ„ê·œì œë²• ë“±)

í˜•ì‹:
[
  {{"category":"violation","law_name":"ë„ë¡œêµí†µë²•","article_num":32}},
  {{"category":"definition","law_name":"ë„ë¡œêµí†µë²•","article_num":2}},
  {{"category":"procedure","law_name":"í–‰ì •ì ˆì°¨ë²•","article_num":21}},
  {{"category":"procedure","law_name":"ì§ˆì„œìœ„ë°˜í–‰ìœ„ê·œì œë²•","article_num":16}}
]

ê·œì¹™:
- ë²•ë ¹ëª…ì€ ì •ì‹ ëª…ì¹­
- ì¡°ë¬¸ ë²ˆí˜¸ ë¶ˆëª…í™•í•˜ë©´ null
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥
"""
        try:
            extracted = llm_service.generate_json(prompt_extract)
            if isinstance(extracted, dict):
                extracted = [extracted]
            search_targets = extracted if isinstance(extracted, list) and extracted else []
        except Exception:
            search_targets = []

        if not search_targets:
            search_targets = [{"category": "violation", "law_name": "ë„ë¡œêµí†µë²•", "article_num": None}]

        report_lines = [f"ğŸ” **AIê°€ ì‹ë³„í•œ í•µì‹¬ ë²•ë ¹ (ì‹¤ì²´+ì ˆì°¨) {len(search_targets)}ê±´**", "---"]
        api_success_count = 0

        for idx, item in enumerate(search_targets):
            category = item.get("category", "etc")
            law_name = item.get("law_name", "ê´€ë ¨ë²•ë ¹")
            article_num = item.get("article_num")

            real_law_text = law_api_service.get_law_text(law_name, article_num)

            error_keywords = ["ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤", "ì˜¤ë¥˜", "API ID", "ì‹¤íŒ¨"]
            is_success = not any(k in real_law_text for k in error_keywords)

            if is_success:
                api_success_count += 1
                header = f"âœ… **{idx+1}. [{category}] {law_name} ì œ{article_num}ì¡° (í™•ì¸ë¨)**"
                content = real_law_text
            else:
                header = f"âš ï¸ **{idx+1}. [{category}] {law_name} ì œ{article_num}ì¡° (API ì¡°íšŒ ì‹¤íŒ¨)**"
                content = "(êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ í•´ë‹¹ ì¡°ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë²•ë ¹ëª…/ì¡°ë¬¸ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.)"

            report_lines.append(f"{header}\n{content}\n")

        if api_success_count == 0:
            ai_fallback = llm_service.generate_text(
                f"""[AI ì¶”ë¡  ê²°ê³¼]
ìƒí™©: "{situation}"
ë²•ë ¹ API ì—°ê²° ì‹¤íŒ¨ ìƒíƒœ. í•„ìš”í•œ ì‹¤ì²´ë²•/ì ˆì°¨ë²•ì„ ìµœëŒ€í•œ ì •í™•íˆ ì„¤ëª…í•˜ë˜,
ë°˜ë“œì‹œ 'ë²•ì œì²˜ í™•ì¸ í•„ìˆ˜' ê²½ê³ ë¥¼ í¬í•¨í•´ì„œ ì‘ì„±."""
            ).strip()
            return f"âš ï¸ **[ì‹œìŠ¤í…œ ê²½ê³ : API ì¡°íšŒ ì‹¤íŒ¨]**\n(ë²•ì œì²˜ í™•ì¸ í•„ìˆ˜)\n------------------\n{ai_fallback}"

        return "\n".join(report_lines)

    @staticmethod
    def strategist(situation, legal_basis, search_results):
        prompt = f"""
ë‹¹ì‹ ì€ í–‰ì • ì—…ë¬´ ë² í…Œë‘ 'ì£¼ë¬´ê´€'ì…ë‹ˆë‹¤.

[ë¯¼ì› ìƒí™©]
{situation}

[í™•ë³´ëœ ë²•ë ¹ ë°ì´í„°(ì‹¤ì²´/ì •ì˜/ì ˆì°¨)]
{legal_basis}

[ìœ ì‚¬ ì‚¬ë¡€(ê²€ìƒ‰)]
{search_results}

[ì¶œë ¥ ì–‘ì‹(ë§ˆí¬ë‹¤ìš´)]
1) **ì²˜ë¦¬ ë°©í–¥**
- ì ìš© ìœ„ë°˜ì¡°í•­(ì‹¤ì²´ë²•)ìœ¼ë¡œ ë¬´ì—‡ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í• ì§€
- ë¯¼ì›ì¸ì˜ ì£¼ì¥ ë°˜ë°•(ì •ì˜/íŒë‹¨ ê·¼ê±°)

2) **í•µì‹¬ ì£¼ì˜ì‚¬í•­(ì ˆì°¨ ë§¤í•‘ í•„ìˆ˜)**
- 3~4ê°œ í•­ëª©
- ê° í•­ëª© ëì— ê·¼ê±° ë²•ë ¹/ì¡°ë¬¸ì„ ë°˜ë“œì‹œ í‘œê¸° (í–‰ì •ì ˆì°¨ë²•/ì§ˆì„œìœ„ë°˜í–‰ìœ„ê·œì œë²• ë“±)

3) **ì˜ˆìƒ ë°˜ë°œ ë° ëŒ€ì‘**
- ì˜ˆìƒ ì£¼ì¥ 2~3ê°œì™€ ì‘ëŒ€ ë©˜íŠ¸
"""
        return llm_service.generate_text(prompt)

    @staticmethod
    def clerk(situation, legal_basis):
        today = datetime.now()
        prompt = f"""
ì˜¤ëŠ˜: {today.strftime('%Y-%m-%d')}
ìƒí™©: {situation}
ë²•ë ¹: {legal_basis}

ì‚¬ì „í†µì§€/ì´í–‰ëª…ë ¹/ì˜ê²¬ì œì¶œ ë“± í†µìƒ ë¶€ì—¬í•˜ëŠ” ê¸°ê°„(ì¼ìˆ˜)ì„ ìˆ«ìë§Œ ì¶œë ¥.
(ì˜ˆ: 10, 15, 20) ëª¨ë¥´ë©´ 15.
"""
        try:
            res = llm_service.generate_text(prompt)
            days = int(re.sub(r"[^0-9]", "", res))
            if days <= 0:
                days = 15
        except Exception:
            days = 15

        deadline = today + timedelta(days=days)
        return {
            "today_str": today.strftime("%Y. %m. %d."),
            "deadline_str": deadline.strftime("%Y. %m. %d."),
            "days_added": days,
            "doc_num": f"í–‰ì •-{today.strftime('%Y')}-{int(time.time())%1000:03d}í˜¸",
        }

    @staticmethod
    def drafter(situation, legal_basis, meta_info, strategy):
        prompt = f"""
ë„ˆëŠ” í–‰ì •ê¸°ê´€ ë² í…Œë‘ ì„œê¸°ë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³µë¬¸ì„œ JSONì„ ìƒì„±í•˜ë¼.
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.

[ì…ë ¥]
- ë¯¼ì› ìƒí™©: {situation}
- ë²•ì  ê·¼ê±°: {legal_basis}
- ì‹œí–‰ ì¼ì: {meta_info['today_str']}
- ê¸°í•œ: {meta_info['deadline_str']} ({meta_info['days_added']}ì¼)
- ì „ëµ:
{strategy}

[ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
{{
  "title": "ê³µë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ì¸",
  "body_paragraphs": ["ë¬¸ë‹¨1", "ë¬¸ë‹¨2", "ë¬¸ë‹¨3"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

[ì‘ì„± ì›ì¹™]
- ë³¸ë¬¸ì— ì‹¤ì²´ë²• + ì ˆì°¨ë²• ì¸ìš©(ê°€ëŠ¥í•˜ë©´ ì¡°ë¬¸ë²ˆí˜¸ í¬í•¨)
- êµ¬ì¡°: ê²½ìœ„ -> ë²•ì ê·¼ê±°(ìœ„ë°˜/ì •ì˜/ì ˆì°¨) -> ì²˜ë¶„/ì¡°ì¹˜ -> ê¶Œë¦¬êµ¬ì œ/ì´ì˜ì œê¸° ì•ˆë‚´
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
"""
        data = llm_service.generate_json(prompt)
        if not isinstance(data, dict):
            return {
                "title": "ê³µ ë¬¸ ì„œ",
                "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
                "body_paragraphs": ["(ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì…ë ¥/í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.)"],
                "department_head": "í–‰ì •ê¸°ê´€ì¥",
            }

        data.setdefault("title", "ê³µ ë¬¸ ì„œ")
        data.setdefault("receiver", "ìˆ˜ì‹ ì ì°¸ì¡°")

        bp = data.get("body_paragraphs", [])
        if isinstance(bp, str):
            bp = [bp]
        if not isinstance(bp, list) or not bp:
            bp = ["(ë³¸ë¬¸ ìƒì„± ì‹¤íŒ¨)"]
        data["body_paragraphs"] = [str(x) for x in bp]

        data.setdefault("department_head", "í–‰ì •ê¸°ê´€ì¥")
        return data


# ==========================================
# 2.5 Global service instances (â­ ë¯¸ì •ì˜ í•´ê²°)
# ==========================================
llm_service = LLMService()
search_service = SearchService()
db_service = DatabaseService()
law_api_service = LawOfficialService()


# ==========================================
# 4. Workflow (UI ë¡œì§)
# ==========================================
def run_workflow(user_input: str):
    log_placeholder = st.empty()
    logs = []

    def add_log(msg, style="sys"):
        logs.append(f"<div class='agent-log log-{style}'>{_escape(msg)}</div>")
        log_placeholder.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.25)

    add_log("ğŸ” Phase 1: ë²•ë ¹ ë° ìœ ì‚¬ ì‚¬ë¡€ ë¦¬ì„œì¹˜ ì¤‘...", "legal")
    legal_basis = LegalAgents.researcher(user_input)
    add_log("ğŸ“œ ë²•ì  ê·¼ê±° ìˆ˜ì§‘ ì™„ë£Œ", "legal")

    add_log("ğŸŸ© ë„¤ì´ë²„ ê²€ìƒ‰ ì—”ì§„ ê°€ë™...", "search")
    try:
        search_results = search_service.search_precedents(user_input)
    except Exception:
        search_results = "ê²€ìƒ‰ ëª¨ë“ˆ ì˜¤ë¥˜ (ê±´ë„ˆëœ€)"

    add_log("ğŸ§  Phase 2: AI ì£¼ë¬´ê´€ì´ ì—…ë¬´ ì²˜ë¦¬ ë°©í–¥ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤...", "strat")
    strategy = LegalAgents.strategist(user_input, legal_basis, search_results)

    add_log("ğŸ“… Phase 3: ê¸°í•œ ì‚°ì • ë° ê³µë¬¸ì„œ ì‘ì„± ì‹œì‘...", "calc")
    meta_info = LegalAgents.clerk(user_input, legal_basis)

    add_log("âœï¸ ìµœì¢… ê³µë¬¸ì„œ ì¡°íŒ ì¤‘...", "draft")
    doc_data = LegalAgents.drafter(user_input, legal_basis, meta_info, strategy)

    add_log("ğŸ’¾ ì—…ë¬´ ê¸°ë¡ì„ DB(Supabase)ì— ì €ì¥ ì¤‘...", "sys")
    save_result = db_service.save_log(user_input, legal_basis, strategy, doc_data)

    add_log(f"âœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ({save_result})", "sys")
    time.sleep(0.8)
    log_placeholder.empty()

    return {
        "doc": doc_data,
        "meta": meta_info,
        "law": legal_basis,
        "search": search_results,
        "strategy": strategy,
        "save_msg": save_result,
    }


# ==========================================
# 5. Presentation Layer (UI)
# ==========================================
def main():
    col_left, col_right = st.columns([1, 1.2])

    with col_left:
        st.title("ğŸ¢ AI í–‰ì •ê´€ Pro")
        st.caption("Gemini(google.genai) + êµ­ê°€ë²•ë ¹ì •ë³´ + Naver Search + Strategy + DB")
        st.markdown("---")

        # âœ… ìƒíƒœ ì ê²€(ì£½ì§€ ì•Šê³  ê²½ê³ ë§Œ)
        warn_lines = []
        if not llm_service.gemini_key and not llm_service.groq_key:
            warn_lines.append("- LLM í‚¤ ì—†ìŒ: `GEMINI_API_KEY` ë˜ëŠ” `GROQ_API_KEY`ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        if not law_api_service.api_id:
            warn_lines.append("- ë²•ë ¹ API í‚¤ ì—†ìŒ: `LAW_API_ID(OC)`ê°€ ì—†ìœ¼ë©´ ë²•ë ¹ ì „ë¬¸ ì¶”ì¶œì´ ì œí•œë©ë‹ˆë‹¤.")
        if not search_service.client_id or not search_service.client_secret:
            warn_lines.append("- ë„¤ì´ë²„ í‚¤ ì—†ìŒ: `NAVER_CLIENT_ID/SECRET` ì—†ìœ¼ë©´ ìœ ì‚¬ì‚¬ë¡€ ê²€ìƒ‰ì´ êº¼ì§‘ë‹ˆë‹¤.")
        if warn_lines:
            st.warning("í˜„ì¬ ì„¤ì • ìƒíƒœ:\n" + "\n".join(warn_lines))

        st.markdown("### ğŸ—£ï¸ ì—…ë¬´ ì§€ì‹œ")
        user_input = st.text_area(
            "ì—…ë¬´ ë‚´ìš©",
            height=150,
            placeholder="ì˜ˆì‹œ:\n- ì•„íŒŒíŠ¸ ë‹¨ì§€ ë‚´ ì†Œë°©ì°¨ ì „ìš©êµ¬ì—­ ë¶ˆë²• ì£¼ì°¨ ì°¨ëŸ‰ ê³¼íƒœë£Œ ë¶€ê³¼ ì˜ˆê³  í†µì§€ì„œ ì‘ì„±í•´ì¤˜.",
            label_visibility="collapsed",
        )

        if st.button("âš¡ ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
            if not user_input:
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    with st.spinner("AI ì—ì´ì „íŠ¸ íŒ€ì´ í˜‘ì—… ì¤‘ì…ë‹ˆë‹¤..."):
                        st.session_state["workflow_result"] = run_workflow(user_input)
                except Exception as e:
                    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        if "workflow_result" in st.session_state:
            res = st.session_state["workflow_result"]
            st.markdown("---")

            if "ì„±ê³µ" in (res.get("save_msg") or ""):
                st.success(f"âœ… {res['save_msg']}")
            else:
                st.info(f"â„¹ï¸ {res.get('save_msg')}")

            with st.expander("âœ… [ê²€í† ] ë²•ë ¹ ë° ìœ ì‚¬ ì‚¬ë¡€ í™•ì¸", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**ğŸ“œ ì ìš© ë²•ë ¹**")
                    st.code(res.get("law", ""), language="text")
                with col2:
                    st.markdown("**ğŸŸ© ë„¤ì´ë²„ ìœ ì‚¬ ì‚¬ë¡€**")
                    st.info(res.get("search", ""))

            with st.expander("ğŸ§­ [ë°©í–¥] ì—…ë¬´ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸", expanded=True):
                st.markdown(res.get("strategy", ""))

    with col_right:
        if "workflow_result" in st.session_state:
            res = st.session_state["workflow_result"]
            doc = res.get("doc") or {}
            meta = res.get("meta") or {}

            html_content = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{_escape(str(doc.get('title', 'ê³µ ë¬¸ ì„œ')))}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {_escape(str(meta.get('doc_num','-')))}</span>
    <span>ì‹œí–‰ì¼ì: {_escape(str(meta.get('today_str','-')))}</span>
    <span>ìˆ˜ì‹ : {_escape(str(doc.get('receiver','ìˆ˜ì‹ ì ì°¸ì¡°')))}</span>
  </div>
  <hr style="border: 1px solid black; margin-bottom: 30px;">
  <div class="doc-body">
"""
            paragraphs = doc.get("body_paragraphs", [])
            if isinstance(paragraphs, str):
                paragraphs = [paragraphs]
            if not isinstance(paragraphs, list):
                paragraphs = ["(ë³¸ë¬¸ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜)"]

            for p in paragraphs:
                html_content += f"<p style='margin-bottom: 15px;'>{_escape(str(p))}</p>"

            html_content += f"""
  </div>
  <div class="doc-footer">{_escape(str(doc.get('department_head', 'í–‰ì •ê¸°ê´€ì¥')))}</div>
</div>
"""
            st.markdown(html_content, unsafe_allow_html=True)

        else:
            st.markdown(
                """<div style='text-align: center; padding: 100px; color: #aaa; background: white; border-radius: 10px; border: 2px dashed #ddd;'>
<h3>ğŸ“„ Document Preview</h3><p>ì™¼ìª½ì—ì„œ ì—…ë¬´ë¥¼ ì§€ì‹œí•˜ë©´<br>ì™„ì„±ëœ ê³µë¬¸ì„œê°€ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.</p></div>""",
                unsafe_allow_html=True,
            )


if __name__ == "__main__":
    main()
