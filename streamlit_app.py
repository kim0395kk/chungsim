import streamlit as st
import google.generativeai as genai
from groq import Groq
from serpapi import GoogleSearch
from supabase import create_client
import json
import re
import time
from datetime import datetime, timedelta
from html import escape

# ==========================================
# 1. Configuration & Styles (ì„¤ì • ë° ë””ìì¸)
# ==========================================
st.set_page_config(layout="wide", page_title="AI Bureau: The Legal Glass", page_icon="âš–ï¸")

st.markdown(
    """
<style>
    /* ë°°ê²½: ì°¨ë¶„í•œ ì˜¤í”¼ìŠ¤ í†¤ */
    .stApp { background-color: #f3f4f6; }

    /* ê²°ê³¼ë¬¼: A4 ìš©ì§€ ìŠ¤íƒ€ì¼ */
    .paper-sheet {
        background-color: white;
        width: 100%;
        max-width: 210mm;
        min-height: 297mm;
        padding: 25mm;
        margin: auto;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        font-family: 'Noto Serif KR','Noto Sans KR','Nanum Gothic','Apple SD Gothic Neo','Malgun Gothic',serif;
        color: #111;
        line-height: 1.6;
        position: relative;
    }

    /* ê³µë¬¸ì„œ ë‚´ë¶€ ìŠ¤íƒ€ì¼ */
    .doc-header { text-align: center; font-size: 22pt; font-weight: 900; margin-bottom: 30px; letter-spacing: 2px; }
    .doc-info { display: flex; justify-content: space-between; font-size: 11pt; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 20px; }
    .doc-body { font-size: 12pt; text-align: justify; }
    .doc-footer { text-align: center; font-size: 20pt; font-weight: bold; margin-top: 80px; letter-spacing: 5px; }
    .stamp { position: absolute; bottom: 85px; right: 80px; border: 3px solid #cc0000; color: #cc0000; padding: 5px 10px; font-size: 14pt; font-weight: bold; transform: rotate(-15deg); opacity: 0.8; border-radius: 5px; }

    /* ë¡œê·¸ ìŠ¤íƒ€ì¼ */
    .agent-log { font-family: 'Consolas', monospace; font-size: 0.85rem; padding: 6px 12px; border-radius: 6px; margin-bottom: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    .log-legal { background-color: #eff6ff; color: #1e40af; border-left: 4px solid #3b82f6; } /* Blue */
    .log-search { background-color: #fff7ed; color: #c2410c; border-left: 4px solid #f97316; } /* Orange */
    .log-strat { background-color: #f5f3ff; color: #6d28d9; border-left: 4px solid #8b5cf6; } /* Purple */
    .log-calc  { background-color: #f0fdf4; color: #166534; border-left: 4px solid #22c55e; } /* Green */
    .log-draft { background-color: #fef2f2; color: #991b1b; border-left: 4px solid #ef4444; } /* Red */
    .log-sys   { background-color: #f3f4f6; color: #4b5563; border-left: 4px solid #9ca3af; } /* Gray */

    /* ì „ëµ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .strategy-box { background-color: #fffbeb; border: 1px solid #fcd34d; padding: 15px; border-radius: 8px; margin-bottom: 15px; }
</style>
""",
    unsafe_allow_html=True,
)

# ==========================================
# 2. Helpers (Robust JSON + Safe)
# ==========================================

def _safe_html_text(value):
    if value is None:
        return ""
    return escape(str(value), quote=False).replace("\n", "<br>")

def _strip_code_fences(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r"```(?:json)?\s*", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\s*```", "", text)
    return text.strip()

def _extract_first_json(text: str):
    """
    Tries to extract the first valid JSON object/array from messy LLM output.
    - Removes code fences
    - Scans for first '{' or '[' and then attempts incremental parsing
    """
    if not text:
        return None
    text = _strip_code_fences(text)

    # find first JSON start
    idx_obj = text.find("{")
    idx_arr = text.find("[")
    candidates = [i for i in [idx_obj, idx_arr] if i != -1]
    if not candidates:
        return None
    start = min(candidates)
    tail = text[start:]

    # fast path: whole tail is json
    try:
        return json.loads(tail)
    except Exception:
        pass

    # incremental: try to find an end position that parses
    # (works well for truncated explanations appended after JSON)
    for end in range(len(tail), max(len(tail) - 5000, 0), -1):
        chunk = tail[:end].strip()
        if not chunk:
            continue
        try:
            return json.loads(chunk)
        except Exception:
            continue
    return None

def _ensure_doc_shape(doc):
    """Guarantee the document dict has required keys and correct types."""
    fallback = {
        "title": "ê³µ ë¬¸ ì„œ",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["AI ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (JSON íŒŒì‹±/ìŠ¤í‚¤ë§ˆ/í† í° ë¬¸ì œ ê°€ëŠ¥)"],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    title = doc.get("title") or fallback["title"]
    receiver = doc.get("receiver") or fallback["receiver"]
    dept = doc.get("department_head") or fallback["department_head"]
    body = doc.get("body_paragraphs")

    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    # sanitize list items
    clean_body = []
    for p in body:
        if p is None:
            continue
        clean_body.append(str(p).strip())
    if not clean_body:
        clean_body = fallback["body_paragraphs"]

    return {
        "title": str(title),
        "receiver": str(receiver),
        "body_paragraphs": clean_body,
        "department_head": str(dept),
    }

# ==========================================
# 3. Infrastructure Layer (Services)
# ==========================================

class LLMService:
    """
    [Model Hierarchy]
    1. Gemini 2.5 Flash
    2. Gemini 2.5 Flash Lite
    3. Gemini 2.0 Flash
    4. Groq (Llama 3 Backup)
    """
    def __init__(self):
        self.gemini_key = st.secrets.get("general", {}).get("GEMINI_API_KEY")
        self.groq_key = st.secrets.get("general", {}).get("GROQ_API_KEY")

        self.gemini_models = [
            "gemini-2.5-flash",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
        ]

        if self.gemini_key:
            genai.configure(api_key=self.gemini_key)

        self.groq_client = Groq(api_key=self.groq_key) if self.groq_key else None

    def _try_gemini_text(self, prompt: str):
        last_err = None
        for model_name in self.gemini_models:
            try:
                model = genai.GenerativeModel(model_name)
                res = model.generate_content(prompt)
                return (res.text or "").strip(), model_name
            except Exception as e:
                last_err = e
                continue
        raise Exception(f"All Gemini models failed. last_err={last_err}")

    def _try_gemini_json(self, prompt: str, schema=None):
        """
        Uses JSON mime hint if possible, but still parses robustly because SDK/model may return non-pure JSON.
        """
        last_err = None
        for model_name in self.gemini_models:
            try:
                model = genai.GenerativeModel(model_name)
                # JSON íŒíŠ¸: ëª¨ë¸/SDK ì¡°í•©ì— ë”°ë¼ ì™„ì „ ë³´ì¥ X -> íŒŒì„œë¡œ ë§ˆë¬´ë¦¬
                config = genai.GenerationConfig(response_mime_type="application/json", response_schema=schema)
                res = model.generate_content(prompt, generation_config=config)
                raw = (res.text or "").strip()
                obj = _extract_first_json(raw)
                if obj is not None:
                    return obj, model_name, raw
                last_err = Exception("Gemini returned non-JSON or unparsable output")
            except Exception as e:
                last_err = e
                continue
        raise Exception(f"All Gemini JSON attempts failed. last_err={last_err}")

    def generate_text(self, prompt: str) -> str:
        try:
            text, _model = self._try_gemini_text(prompt)
            return text
        except Exception:
            if self.groq_client:
                return self._generate_groq(prompt)
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜: AI ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨"

    def generate_json(self, prompt: str, schema=None, retries: int = 2):
        """
        Robust JSON generation:
        - Gemini JSON hint -> parse
        - If fail: retry with stricter instruction
        - Finally: Groq fallback
        """
        # 1) Gemini JSON attempts
        try:
            obj, model_used, raw = self._try_gemini_json(prompt, schema=schema)
            return obj
        except Exception as first_err:
            # 2) Retry: add strict JSON constraints (shorter + explicit)
            for i in range(retries):
                tightened = (
                    prompt
                    + "\n\n[IMPORTANT]\n"
                      "- Output ONLY valid JSON. No markdown. No code fences. No commentary.\n"
                      "- Ensure all required keys exist.\n"
                )
                try:
                    obj, model_used, raw = self._try_gemini_json(tightened, schema=schema)
                    return obj
                except Exception:
                    continue

            # 3) Fallback: plain text then parse
            text = self.generate_text(
                prompt
                + "\n\n[IMPORTANT]\nOutput ONLY valid JSON object. No markdown. No commentary."
            )
            obj = _extract_first_json(text)
            if obj is not None:
                return obj

            # 4) Groq fallback (text then parse)
            if self.groq_client:
                text2 = self._generate_groq(
                    prompt
                    + "\n\n[IMPORTANT]\nOutput ONLY valid JSON object. No markdown. No commentary."
                )
                obj2 = _extract_first_json(text2)
                if obj2 is not None:
                    return obj2

            # fail hard
            raise first_err

    def _generate_groq(self, prompt: str) -> str:
        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
            )
            return completion.choices[0].message.content or ""
        except Exception:
            return "System Error"

class SearchService:
    """Google Search API (SerpApi) Wrapper"""
    def __init__(self):
        self.api_key = st.secrets.get("general", {}).get("SERPAPI_KEY")

    def search_precedents(self, query):
        if not self.api_key:
            return "âš ï¸ ê²€ìƒ‰ API í‚¤(SERPAPI_KEY)ê°€ ì—†ì–´ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            search_query = f"{query} í–‰ì •ì²˜ë¶„ íŒë¡€ ì‚¬ë¡€ ë¯¼ì› ë‹µë³€"
            params = {
                "engine": "google",
                "q": search_query,
                "api_key": self.api_key,
                "num": 3,
                "hl": "ko",
                "gl": "kr",
            }
            search = GoogleSearch(params)
            results = search.get_dict().get("organic_results", [])

            if not results:
                return "ê´€ë ¨ëœ ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

            summary = []
            for item in results:
                title = item.get("title", "ì œëª© ì—†ìŒ")
                snippet = item.get("snippet", "ë‚´ìš© ì—†ìŒ")
                link = item.get("link", "#")
                summary.append(f"- **[{title}]({link})**: {snippet}")

            return "\n".join(summary)
        except Exception as e:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

class DatabaseService:
    """Supabase Persistence Layer"""
    def __init__(self):
        try:
            self.url = st.secrets["supabase"]["SUPABASE_URL"]
            self.key = st.secrets["supabase"]["SUPABASE_KEY"]
            self.client = create_client(self.url, self.key)
            self.is_active = True
        except Exception:
            self.is_active = False

    def save_log(self, user_input, legal_basis, strategy, doc_data):
        if not self.is_active:
            return "DB ë¯¸ì—°ê²° (ì €ì¥ ê±´ë„ˆëœ€)"

        try:
            data = {
                "input_text": user_input,
                "legal_basis": legal_basis,
                "strategy": strategy,
                "final_doc": json.dumps(doc_data, ensure_ascii=False),
                "created_at": datetime.now().isoformat(),
            }
            self.client.table("law_logs").insert(data).execute()
            return "DB ì €ì¥ ì„±ê³µ"
        except Exception as e:
            return f"DB ì €ì¥ ì‹¤íŒ¨: {e}"

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm_service = LLMService()
search_service = SearchService()
db_service = DatabaseService()

# ==========================================
# 4. Domain Layer (Agents)
# ==========================================
class LegalAgents:
    @staticmethod
    def researcher(situation):
        """Step 1: ë²•ë ¹ íƒìƒ‰"""
        prompt = f"""
<role>ë‹¹ì‹ ì€ 30ë…„ ê²½ë ¥ì˜ ë²•ì œê´€ì…ë‹ˆë‹¤.</role>
<instruction>
ìƒí™©: "{situation}"
ìœ„ ìƒí™©ì— ì ìš©í•  ê°€ì¥ ì •í™•í•œ 'ë²•ë ¹ëª…'ê³¼ 'ê´€ë ¨ ì¡°í•­'ì„ í•˜ë‚˜ë§Œ ì°¾ìœ¼ì‹œì˜¤.
ë°˜ë“œì‹œ í˜„í–‰ ëŒ€í•œë¯¼êµ­ ë²•ë ¹ì´ì–´ì•¼ í•˜ë©°, ì¡°í•­ ë²ˆí˜¸ê¹Œì§€ ëª…ì‹œí•˜ì„¸ìš”.
(ì˜ˆ: ë„ë¡œêµí†µë²• ì œ32ì¡°(ì •ì°¨ ë° ì£¼ì°¨ì˜ ê¸ˆì§€))

*ì£¼ì˜: ì…ë ¥ì— ì‹¤ëª… ë“± ê°œì¸ì •ë³´ê°€ ìˆë‹¤ë©´ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì²˜ë¦¬í•˜ì„¸ìš”.
</instruction>
"""
        return llm_service.generate_text(prompt).strip()

    @staticmethod
    def strategist(situation, legal_basis, search_results):
        """Step 2: ì „ëµ ìˆ˜ë¦½"""
        prompt = f"""
ë‹¹ì‹ ì€ í–‰ì • ì—…ë¬´ ë² í…Œë‘ 'ì£¼ë¬´ê´€'ì…ë‹ˆë‹¤.

[ë¯¼ì› ìƒí™©]: {situation}
[ë²•ì  ê·¼ê±°]: {legal_basis}
[ìœ ì‚¬ ì‚¬ë¡€/íŒë¡€]: {search_results}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì´ ë¯¼ì›ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ **ëŒ€ëµì ì¸ ì—…ë¬´ ì²˜ë¦¬ ë°©í–¥(Strategy)**ì„ ìˆ˜ë¦½í•˜ì„¸ìš”.

ë‹¤ìŒ 3ê°€ì§€ í•­ëª©ì„ í¬í•¨í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
1. **ì²˜ë¦¬ ë°©í–¥**: (ì˜ˆ: ê°•ê²½ ëŒ€ì‘, ê³„ë„ ìœ„ì£¼, ë°˜ë ¤ ë“±)
2. **í•µì‹¬ ì£¼ì˜ì‚¬í•­**: (ì ˆì°¨ìƒ ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒ, ë²•ì  ìŸì )
3. **ì˜ˆìƒ ë°˜ë°œ ë° ëŒ€ì‘**: (ë¯¼ì›ì¸ì´ í•­ì˜í•  ê²½ìš° ëŒ€ì‘ ë…¼ë¦¬)

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""
        return llm_service.generate_text(prompt)

    @staticmethod
    def strategist_short(strategy_markdown: str):
        """
        LLM ì¶œë ¥ í† í° í­ë°œ ë°©ì§€: drafterì— ë„£ê¸° ì „ 5~7ì¤„ë¡œ ì••ì¶•
        """
        prompt = f"""
ì•„ë˜ 'ì—…ë¬´ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸'ì„ ê³µë¬¸ì„œ ì‘ì„±ì— í•„ìš”í•œ í•µì‹¬ë§Œ ë‚¨ê²¨ 5~7ì¤„ë¡œ ìš”ì•½í•´ì¤˜.
- ë¶ˆë¦¿ í˜•íƒœë¡œ
- ë²•ì  ë¦¬ìŠ¤í¬/ì ˆì°¨/ë°˜ë°œ ëŒ€ì‘ í¬í•¨
- êµ°ë”ë”ê¸° ì œê±°

[ì›ë¬¸]
{strategy_markdown}
"""
        return llm_service.generate_text(prompt).strip()

    @staticmethod
    def clerk(situation, legal_basis):
        """Step 3: ê¸°í•œ ì‚°ì •"""
        today = datetime.now()
        prompt = f"""
ì˜¤ëŠ˜: {today.strftime('%Y-%m-%d')}
ìƒí™©: {situation}
ë²•ë ¹: {legal_basis}
ìœ„ ìƒí™©ì—ì„œ í–‰ì •ì²˜ë¶„ ì‚¬ì „í†µì§€ë‚˜ ì´í–‰ ëª…ë ¹ ì‹œ, ë²•ì ìœ¼ë¡œ(ë˜ëŠ” í†µìƒì ìœ¼ë¡œ) ë¶€ì—¬í•´ì•¼ í•˜ëŠ” 'ì´í–‰/ì˜ê²¬ì œì¶œ ê¸°ê°„'ì€ ë©°ì¹ ì¸ê°€?
ì„¤ëª… ì—†ì´ ìˆ«ì(ì¼ìˆ˜)ë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: 10, 15, 20)
ëª¨ë¥´ê² ìœ¼ë©´ 15ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
"""
        try:
            res = llm_service.generate_text(prompt)
            days = int(re.sub(r"[^0-9]", "", res)) if res else 15
            if days <= 0:
                days = 15
        except Exception:
            days = 15

        deadline = today + timedelta(days=days)
        return {
            "today_str": today.strftime("%Y. %m. %d."),
            "deadline_str": deadline.strftime("%Y. %m. %d."),
            "days_added": days,
            "doc_num": f"í–‰ì •-{today.strftime('%Y')}-{int(time.time())%1000:03d}í˜¸",
        }

    @staticmethod
    def drafter(situation, legal_basis, meta_info, strategy_short):
        """Step 4: ê³µë¬¸ì„œ ì‘ì„±"""
        doc_schema = {
            "type": "OBJECT",
            "properties": {
                "title": {"type": "STRING", "description": "ê³µë¬¸ì„œ ì œëª©"},
                "receiver": {"type": "STRING", "description": "ìˆ˜ì‹ ì¸"},
                "body_paragraphs": {"type": "ARRAY", "items": {"type": "STRING"}},
                "department_head": {"type": "STRING", "description": "ë°œì‹  ëª…ì˜"},
            },
            "required": ["title", "receiver", "body_paragraphs", "department_head"],
        }

        prompt = f"""
ë‹¹ì‹ ì€ í–‰ì •ê¸°ê´€ì˜ ë² í…Œë‘ ì„œê¸°ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì™„ê²° ê³µë¬¸ì„œ'ë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

[ì…ë ¥ ì •ë³´]
- ë¯¼ì› ìƒí™©: {situation}
- ë²•ì  ê·¼ê±°: {legal_basis}
- ì‹œí–‰ ì¼ì: {meta_info['today_str']}
- ê¸°í•œ: {meta_info['deadline_str']} ({meta_info['days_added']}ì¼)

[ì—…ë¬´ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸ (ìš”ì•½)]
{strategy_short}

[ì‘ì„± ì›ì¹™]
1. ê°€ì´ë“œë¼ì¸ì˜ ê¸°ì¡°(í†¤/ì²˜ë¦¬ë°©í–¥)ë¥¼ ë°˜ì˜í•˜ì„¸ìš”.
2. ìˆ˜ì‹ ì¸ì´ ë¶ˆëª…í™•í•˜ë©´ ìƒí™©ì— ë§ì¶° í•©ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.
3. ë³¸ë¬¸ êµ¬ì¡°: [ê²½ìœ„] -> [ê·¼ê±°] -> [ì²˜ë¶„ ë‚´ìš©] -> [ê¶Œë¦¬êµ¬ì œ ì ˆì°¨]
4. ê°œì¸ì •ë³´(ì´ë¦„, ë²ˆí˜¸)ëŠ” ë°˜ë“œì‹œ ë§ˆìŠ¤í‚¹('OOO') ì²˜ë¦¬í•˜ì„¸ìš”.
5. body_paragraphsëŠ” ë¬¸ë‹¨ ë°°ì—´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""
        obj = llm_service.generate_json(prompt, schema=doc_schema, retries=2)
        return _ensure_doc_shape(obj)

# ==========================================
# 5. Application Layer (Workflow)
# ==========================================
def run_workflow(user_input):
    log_placeholder = st.empty()
    logs = []

    def add_log(msg, style="sys"):
        logs.append(f"<div class='agent-log log-{style}'>{escape(msg)}</div>")
        log_placeholder.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.25)

    def fail_doc(reason: str):
        return _ensure_doc_shape({
            "title": "ê³µ ë¬¸ ì„œ",
            "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
            "body_paragraphs": [f"AI ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {reason}"],
            "department_head": "í–‰ì •ê¸°ê´€ì¥",
        })

    # ----------------------------------------
    # Phase 1: Fact Check & Research
    # ----------------------------------------
    add_log("ğŸ” Phase 1: ë²•ë ¹ ë° ìœ ì‚¬ ì‚¬ë¡€ ë¦¬ì„œì¹˜ ì¤‘...", "legal")
    legal_basis = LegalAgents.researcher(user_input)
    add_log(f"ğŸ“œ ë²•ì  ê·¼ê±° ë°œê²¬: {legal_basis}", "legal")

    add_log("ğŸŒ êµ¬ê¸€ ê²€ìƒ‰ ì—”ì§„ ê°€ë™: ìœ ì‚¬ ì‚¬ë¡€ íŒë¡€ ìˆ˜ì§‘ ì¤‘...", "search")
    search_results = search_service.search_precedents(user_input)

    with st.expander("âœ… [ê²€í† ] ë²•ë ¹ ë° ìœ ì‚¬ ì‚¬ë¡€ í™•ì¸", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"**ì ìš© ë²•ë ¹**\n\n{legal_basis}")
        with col2:
            st.warning(f"**ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼**\n\n{search_results}")

    # ----------------------------------------
    # Phase 2: Strategy Setup
    # ----------------------------------------
    add_log("ğŸ§  Phase 2: AI ì£¼ë¬´ê´€ì´ ì—…ë¬´ ì²˜ë¦¬ ë°©í–¥ì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤...", "strat")
    strategy = LegalAgents.strategist(user_input, legal_basis, search_results)
    strategy_short = LegalAgents.strategist_short(strategy)

    with st.expander("ğŸ§­ [ë°©í–¥] ì—…ë¬´ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸", expanded=True):
        st.markdown(strategy)

    with st.expander("ğŸ§¾ [ìš”ì•½] Draft ì…ë ¥ìš© Strategy (í† í° ì ˆê°)", expanded=False):
        st.markdown(strategy_short)

    # ----------------------------------------
    # Phase 3: Execution (Drafting)
    # ----------------------------------------
    add_log("ğŸ“… Phase 3: ê¸°í•œ ì‚°ì • ë° ê³µë¬¸ì„œ ì‘ì„± ì‹œì‘...", "calc")
    meta_info = LegalAgents.clerk(user_input, legal_basis)
    add_log(f"â³ ê¸°í•œ ì„¤ì •: {meta_info['days_added']}ì¼ í›„ ({meta_info['deadline_str']})", "calc")

    add_log("âœï¸ ìµœì¢… ê³µë¬¸ì„œ ì¡°íŒ ì¤‘ (Formatting)...", "draft")
    try:
        doc_data = LegalAgents.drafter(user_input, legal_basis, meta_info, strategy_short)
    except Exception as e:
        doc_data = fail_doc(f"drafter ì˜ˆì™¸: {e}")

    # ----------------------------------------
    # Phase 4: Persistence (Saving)
    # ----------------------------------------
    add_log("ğŸ’¾ ì—…ë¬´ ê¸°ë¡ì„ ë°ì´í„°ë² ì´ìŠ¤(Supabase)ì— ì €ì¥ ì¤‘...", "sys")
    save_result = db_service.save_log(user_input, legal_basis, strategy, doc_data)

    add_log(f"âœ… ëª¨ë“  í–‰ì • ì ˆì°¨ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ({save_result})", "sys")
    time.sleep(0.8)
    log_placeholder.empty()

    return doc_data, meta_info

# ==========================================
# 6. Presentation Layer (UI)
# ==========================================
def main():
    col_left, col_right = st.columns([1, 1.2])

    with col_left:
        st.title("ğŸ¢ AI í–‰ì •ê´€ Pro")
        st.caption("Gemini 2.5 + Search + Strategy + DB (Robust JSON + Fallback)")
        st.markdown("---")

        st.markdown("### ğŸ—£ï¸ ì—…ë¬´ ì§€ì‹œ")
        user_input = st.text_area(
            "ì—…ë¬´ ë‚´ìš©",
            height=150,
            placeholder="ì˜ˆì‹œ:\n- ì•„íŒŒíŠ¸ ë‹¨ì§€ ë‚´ ì†Œë°©ì°¨ ì „ìš©êµ¬ì—­ ë¶ˆë²• ì£¼ì°¨ ì°¨ëŸ‰ ê³¼íƒœë£Œ ë¶€ê³¼ ì˜ˆê³  í†µì§€ì„œ ì‘ì„±í•´ì¤˜.\n- ì‹í’ˆìœ„ìƒë²• ìœ„ë°˜ ì‹ë‹¹ ì˜ì—…ì •ì§€ ì‚¬ì „ í†µì§€ì„œ ì¨ì¤˜.",
            label_visibility="collapsed",
        )

        col_btn1, col_btn2 = st.columns([1, 1])
        with col_btn1:
            run_btn = st.button("âš¡ ìŠ¤ë§ˆíŠ¸ í–‰ì • ì²˜ë¶„ ì‹œì‘", type="primary", use_container_width=True)
        with col_btn2:
            clear_btn = st.button("ğŸ§¹ ê²°ê³¼ ì´ˆê¸°í™”", use_container_width=True)

        if clear_btn:
            st.session_state.pop("final_doc", None)
            st.session_state.pop("debug_last_raw_json", None)
            st.rerun()

        if run_btn:
            if not user_input:
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                try:
                    with st.spinner("AI ì—ì´ì „íŠ¸ íŒ€ì´ í˜‘ì—… ì¤‘ì…ë‹ˆë‹¤..."):
                        doc, meta = run_workflow(user_input)
                        st.session_state["final_doc"] = (doc, meta)
                except Exception as e:
                    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown("---")
        st.info("ğŸ’¡ **Tip:** ë²•ë ¹/íŒë¡€ ê²€ìƒ‰ -> ì „ëµ ìˆ˜ë¦½ -> ë¬¸ì„œ ì‘ì„± -> DB ì €ì¥ê¹Œì§€ ì¼ê´„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    with col_right:
        if "final_doc" in st.session_state:
            doc, meta = st.session_state["final_doc"]
            doc = _ensure_doc_shape(doc)

            html_content = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{_safe_html_text(doc.get('title', 'ê³µ ë¬¸ ì„œ'))}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {_safe_html_text(meta.get('doc_num'))}</span>
    <span>ì‹œí–‰ì¼ì: {_safe_html_text(meta.get('today_str'))}</span>
    <span>ìˆ˜ì‹ : {_safe_html_text(doc.get('receiver', 'ìˆ˜ì‹ ì ì°¸ì¡°'))}</span>
  </div>
  <hr style="border: 1px solid black; margin-bottom: 30px;">
  <div class="doc-body">
"""
            paragraphs = doc.get("body_paragraphs", [])
            if isinstance(paragraphs, str):
                paragraphs = [paragraphs]
            for p in paragraphs:
                html_content += f"<p style='margin-bottom: 15px;'>{_safe_html_text(p)}</p>"

            html_content += f"""
  </div>
  <div class="doc-footer">{_safe_html_text(doc.get('department_head', 'í–‰ì •ê¸°ê´€ì¥'))}</div>
</div>
"""

            st.markdown(html_content, unsafe_allow_html=True)
            st.download_button(
                label="ğŸ–¨ï¸ ë‹¤ìš´ë¡œë“œ (HTML)",
                data=html_content,
                file_name="ê³µë¬¸ì„œ.html",
                mime="text/html",
                use_container_width=True,
            )

        else:
            st.markdown(
                """
<div style='text-align: center; padding: 100px; color: #aaa; background: white; border-radius: 10px; border: 2px dashed #ddd;'>
  <h3>ğŸ“„ Document Preview</h3>
  <p>ì™¼ìª½ì—ì„œ ì—…ë¬´ë¥¼ ì§€ì‹œí•˜ë©´<br>ì™„ì„±ëœ ê³µë¬¸ì„œê°€ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.</p>
</div>
""",
                unsafe_allow_html=True,
            )

if __name__ == "__main__":
    main()
