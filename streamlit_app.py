# app.py â€” AI í–‰ì •ê´€ Pro (Stable / Dual-Model Router)
# Groq: qwen/qwen3-32b (FAST) + llama-3.3-70b-versatile (STRICT)
# LAWGO(DRF) + NAVER + Supabase + Anti-crash patches
#
# FAST(default): Planner/Strategy
# STRICT(fallback/critical): Drafter(JSON), Planner JSON fail, Strategy when law not confirmed
# JSON ì•ˆì •í™”: ì¬ì‹œë„ + STRICT ìŠ¹ê¸‰
# UI íŠ ë°©ì§€: HTML sanitize + components.html ì•ˆì •í™”
# Metrics: ëª¨ë¸ë³„ í˜¸ì¶œ + tokens_total í•©ì‚°(ê°€ëŠ¥í•œ ê²½ìš°)

import json
import re
import time
from datetime import datetime
from html import escape, unescape

import streamlit as st
import streamlit.components.v1 as components

# =========================
# 0) Optional Imports (Safety)
# =========================
try:
    from groq import Groq
except Exception:
    Groq = None

try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (Dual v5.1)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }
/* ë¬¸ì„œ ìŠ¤íƒ€ì¼ */
.paper-sheet {
  background: #fff; width: 100%; max-width: 210mm; min-height: 297mm;
  padding: 25mm; margin: auto; box-shadow: 0 4px 15px rgba(0,0,0,0.08);
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111; line-height:1.6; position:relative;
}
.doc-header { text-align:center; font-size:24pt; font-weight:800; margin-bottom:35px; letter-spacing:2px; }
.doc-info {
  display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;
  font-size:11pt; border-bottom:2px solid #333; padding-bottom:12px; margin-bottom:25px;
}
.doc-body { font-size:12pt; text-align: justify; }
.doc-footer { text-align:center; font-size:22pt; font-weight:bold; margin-top:80px; letter-spacing:4px; }
.stamp {
  position:absolute; bottom:85px; right:80px; border:3px solid #d32f2f; color: #d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:bold; transform:rotate(-15deg);
  opacity:0.8; border-radius:4px; font-family: 'Nanum Gothic', sans-serif;
}
/* ë¡œê·¸ ìŠ¤íƒ€ì¼ */
.agent-log {
  font-family: 'Pretendard', sans-serif; font-size: 0.9rem; padding: 8px 12px;
  border-radius: 6px; margin-bottom: 6px; background: white; border: 1px solid #e5e7eb;
}
.log-legal { border-left: 4px solid #3b82f6; color: #1e40af; }
.log-search { border-left: 4px solid #f97316; color: #c2410c; }
.log-strat { border-left: 4px solid #8b5cf6; color: #6d28d9; }
.log-draft { border-left: 4px solid #ef4444; color: #991b1b; }
.log-sys   { border-left: 4px solid #9ca3af; color: #4b5563; }
.small-muted { color:#6b7280; font-size:12px; }
</style>
""",
    unsafe_allow_html=True,
)

_TAG_RE = re.compile(r"<[^>]+>")
# í•œì(ì¤‘êµ­/ì¼ë³¸ í•œì í¬í•¨) ë²”ìœ„ ì œê±°ìš©: CJK Unified + Extension A + Compatibility Ideographs
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF\uF900-\uFAFF]")


# =========================
# 2) Helpers
# =========================
def strip_bad_invisibles(s: str) -> str:
    """
    JSON/HTML/í…ìŠ¤íŠ¸ì— ì„ì´ëŠ” ë¹„ê°€ì‹œë¬¸ì(ì œë¡œí­, BOM, PUA ë“±) ì œê±°/ì¹˜í™˜
    - U+EA01 ê°™ì€ Private Use Area(U+E000~U+F8FF)ë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
    """
    if s is None:
        return ""
    s = str(s)

    # BOM / zero-width / NBSP / word-joiner
    s = s.replace("\ufeff", "")
    s = s.replace("\u200b", "").replace("\u200c", "").replace("\u200d", "")
    s = s.replace("\u2060", "")
    s = s.replace("\u00a0", " ")

    # Private Use Area
    out = []
    for ch in s:
        o = ord(ch)
        if 0xE000 <= o <= 0xF8FF:
            out.append(" ")
        else:
            out.append(ch)
    return "".join(out)


def clean_text(value) -> str:
    """HTML íƒœê·¸, ì œì–´ë¬¸ì, ë¹„ê°€ì‹œë¬¸ì ì œê±°"""
    if value is None:
        return ""
    s = strip_bad_invisibles(unescape(str(value)))
    s = _TAG_RE.sub("", s)
    s = re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]", "", s)  # control chars
    return s.strip()


def remove_hanja(value: str) -> str:
    """í•œì ì œê±°(â€˜í•œê¸€ë¡œ ë²ˆì—­â€™ì€ ë¶ˆê°€ â†’ ì•ˆì „í•˜ê²Œ ì œê±°/ì •ë¦¬)"""
    s = clean_text(value)
    if not s:
        return ""
    s = _HANJA_RE.sub("", s)
    s = re.sub(r"\s{2,}", " ", s).strip()
    return s


def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")


def truncate_text(s: str, max_chars: int = 2500) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"


def ensure_doc_shape(doc):
    """LLM ì‘ë‹µì´ ê¹¨ì¡Œì„ ë•Œ ê¸°ë³¸ê°’ ë³´ì¥ + í•œì ì œê±°"""
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    body_clean = []
    for x in body:
        cx = remove_hanja(x)
        if cx:
            body_clean.append(cx)
    if not body_clean:
        body_clean = fallback["body_paragraphs"]

    return {
        "title": remove_hanja(doc.get("title") or fallback["title"]),
        "receiver": remove_hanja(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": body_clean,
        "department_head": remove_hanja(doc.get("department_head") or fallback["department_head"]),
    }


def safe_json_dump(obj):
    """Supabase ì €ì¥ ì‹œ í„°ì§€ì§€ ì•Šê²Œ ì§ë ¬í™” + ë¹„ê°€ì‹œë¬¸ì ë°©ì–´"""
    try:
        return json.dumps(obj, ensure_ascii=False, default=lambda x: strip_bad_invisibles(str(x)))
    except Exception:
        return "{}"


def extract_keywords_kor(text: str, max_k: int = 6):
    if not text:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", clean_text(text))
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,12}", t)
    stop = set(
        [
            "ê·¸ë¦¬ê³ ",
            "ê´€ë ¨",
            "ë¬¸ì˜",
            "ì‚¬í•­",
            "ëŒ€í•˜ì—¬",
            "ëŒ€í•œ",
            "ì²˜ë¦¬",
            "ìš”ì²­",
            "ì‘ì„±",
            "ì•ˆë‚´",
            "ê²€í† ",
            "ë¶ˆí¸",
            "ë¯¼ì›",
            "ì‹ ì²­",
            "ë°œê¸‰",
            "ì œì¶œ",
        ]
    )
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Metrics
# =========================
def metrics_init():
    if "metrics" not in st.session_state:
        st.session_state["metrics"] = {"calls": {}, "tokens_total": 0}


def metrics_add(model_name: str, tokens_total=None):
    metrics_init()
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


metrics_init()


# =========================
# 4) LLM Service (Dual Router)
# =========================
class LLMService:
    """
    secrets.toml
    [general]
    GROQ_API_KEY = "..."
    GROQ_MODEL_FAST = "qwen/qwen3-32b"
    GROQ_MODEL_STRICT = "llama-3.3-70b-versatile"
    """

    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")

        self.model_fast = g.get("GROQ_MODEL_FAST", "qwen/qwen3-32b")
        self.model_strict = g.get("GROQ_MODEL_STRICT", "llama-3.3-70b-versatile")

        self.client = None
        self.last_model = "N/A"

        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def _chat(self, model: str, messages, temp: float, json_mode: bool):
        if not self.client:
            raise RuntimeError("Groq client not ready")

        kwargs = {"model": model, "messages": messages, "temperature": temp}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        resp = self.client.chat.completions.create(**kwargs)
        self.last_model = model

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_add(model, tokens_total=tokens_total)

        txt = resp.choices[0].message.content or ""
        return strip_bad_invisibles(txt)

    def _parse_json(self, text: str):
        text = strip_bad_invisibles(text).strip()
        try:
            return json.loads(text)
        except Exception:
            cleaned = re.sub(r"```json|```", "", text).strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    return {}
            return {}

    def generate_text(self, prompt: str, prefer: str = "fast", temp: float = 0.1) -> str:
        if not self.client:
            return "Groq API Keyê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜"

        model_first = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {
                "role": "system",
                "content": "Korean public administration assistant. Be practical, concise, and correct.",
            },
            {"role": "user", "content": strip_bad_invisibles(prompt)},
        ]

        # 1ì°¨
        try:
            return self._chat(model_first, messages, temp, json_mode=False)
        except Exception:
            pass

        # fast ì‹¤íŒ¨ë©´ strict ìŠ¹ê¸‰
        if prefer == "fast":
            try:
                return self._chat(self.model_strict, messages, temp, json_mode=False)
            except Exception as e2:
                return f"LLM Error: {e2}"

        return "LLM Error"

    def generate_json(self, prompt: str, prefer: str = "fast", temp: float = 0.1, max_retry: int = 2):
        if not self.client:
            return {}

        sys_json = "Output JSON only. No markdown. No explanation. Follow the schema exactly."
        messages = [
            {"role": "system", "content": sys_json},
            {"role": "user", "content": strip_bad_invisibles(prompt)},
        ]

        model_first = self.model_fast if prefer == "fast" else self.model_strict

        # ê°™ì€ ëª¨ë¸ ì¬ì‹œë„
        for _ in range(max_retry):
            try:
                txt = self._chat(model_first, messages, temp, json_mode=True)
                js = self._parse_json(txt)
                if isinstance(js, dict) and js:
                    return js
            except Exception:
                pass

        # strict ìŠ¹ê¸‰
        try:
            txt = self._chat(self.model_strict, messages, temp, json_mode=True)
            js = self._parse_json(txt)
            return js if isinstance(js, dict) else {}
        except Exception:
            return {}


llm_service = LLMService()


# =========================
# 5) LAW API (DRF) â€” Search + Service (XML)
# =========================
class LawAPIService:
    """
    secrets.toml
    [law]
    LAW_API_ID = "OCê°’"
    """

    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)

    def _pick(self, d: dict, keys: list[str], default=""):
        for k in keys:
            if k in d and d.get(k) not in (None, ""):
                return d.get(k)
        return default

    def search_law(self, query: str, display: int = 10):
        if not self.enabled or not query:
            return []
        try:
            params = {
                "OC": self.oc,
                "target": "law",
                "type": "XML",
                "query": query,
                "display": display,
                "page": 1,
            }
            r = requests.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            laws = (data.get("LawSearch", {}) or {}).get("law", []) or []
            if isinstance(laws, dict):
                laws = [laws]

            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue

                lawNm = self._pick(it, ["ë²•ë ¹ëª…í•œê¸€", "lawNm", "ë²•ë ¹ëª…", "ë²•ë ¹ëª…_í•œê¸€"], "")
                MST = self._pick(it, ["ë²•ë ¹ì¼ë ¨ë²ˆí˜¸", "MST", "mst"], "")
                lawId = self._pick(it, ["ë²•ë ¹ID", "lawId", "id"], "")
                link = self._pick(it, ["ë²•ë ¹ìƒì„¸ë§í¬", "link"], "")

                lawNm = remove_hanja(lawNm)  # í•œì ì œê±°
                out.append({"lawNm": lawNm, "MST": clean_text(MST), "lawId": clean_text(lawId), "link": clean_text(link)})

            out = [x for x in out if clean_text(x.get("lawNm"))]
            return out
        except Exception:
            return []

    def get_article_text_by_mst(self, mst: str, article_no: str | None = None) -> str:
        """
        DRF lawServiceëŠ” MSTë¡œ ê°€ì ¸ì˜¤ëŠ” ê²Œ ì•ˆì •ì .
        article_noëŠ” "ìˆ«ì"ë¡œ ë„£ìœ¼ë©´ ìµœëŒ€í•œ ë§¤ì¹­ ì‹œë„.
        """
        if not self.enabled or not mst:
            return ""
        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
            r = requests.get(self.service_url, params=params, timeout=9)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            law = data.get("Law") or data.get("law") or {}
            articles = law.get("Article", []) or []
            if isinstance(articles, dict):
                articles = [articles]

            # ì¡°ë¬¸ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ë„ˆë¬´ ê¸¸ê²Œ ë½‘ì§€ ë§ê³  ìš”ì•½ìš©ìœ¼ë¡œ ì¼ë¶€ë§Œ
            if not article_no:
                raw = remove_hanja(r.text)
                return raw[:4000]

            tgt = re.sub(r"[^0-9]", "", str(article_no))
            if not tgt:
                return ""

            for art in articles:
                if not isinstance(art, dict):
                    continue

                an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                at = remove_hanja(art.get("ArticleTitle") or "")
                content = remove_hanja(art.get("ArticleContent") or "")

                # ë§¤ì¹­
                if tgt == re.sub(r"[^0-9]", "", an) or (tgt and f"ì œ{tgt}ì¡°" in at):
                    paras = art.get("Paragraph", [])
                    if isinstance(paras, dict):
                        paras = [paras]
                    p_text = "\n".join(
                        [remove_hanja(p.get("ParagraphContent")) for p in paras if isinstance(p, dict)]
                    )
                    joined = "\n".join([x for x in [at, content, p_text] if x]).strip()
                    return joined

            return ""
        except Exception:
            return ""


law_api = LawAPIService()


# =========================
# 6) NAVER Search
# =========================
class NaverSearchService:
    """
    secrets.toml
    [naver]
    CLIENT_ID="..."
    CLIENT_SECRET="..."
    """

    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    def search(self, query: str, cat: str = "news", display: int = 5):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = requests.get(url, headers=headers, params=params, timeout=6)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []


naver_search = NaverSearchService()


# =========================
# 7) Supabase
# =========================
class DatabaseService:
    """
    secrets.toml
    [supabase]
    SUPABASE_URL="..."
    SUPABASE_KEY="..."
    """

    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        url = s.get("SUPABASE_URL")
        key = s.get("SUPABASE_KEY")
        if create_client and url and key:
            try:
                self.client = create_client(url, key)
            except Exception:
                self.client = None

    def save_log(self, data: dict):
        if not self.client:
            return "DB ë¯¸ì—°ê²°"
        try:
            safe_data = json.loads(safe_json_dump(data))
            self.client.table("law_logs").insert(safe_data).execute()
            return "ì €ì¥ ì„±ê³µ"
        except Exception as e:
            return f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"


db_service = DatabaseService()


# =========================
# 8) Workflow
# =========================
def run_workflow(user_input: str, dept: str, officer: str):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.04)

    user_input = remove_hanja(user_input)  # ì…ë ¥ì—ë„ í˜¹ì‹œ ì„ì´ë©´ ì •ë¦¬

    # ---- Phase 0: cheap keyword extraction (no LLM)
    kw_fallback = extract_keywords_kor(user_input, max_k=6)

    # 1) Planner (FAST/Qwen)
    add_log("ğŸ§­ [Planner] ì—…ë¬´ ë¶„ì„ ë° ë²•ë ¹/ê²€ìƒ‰ì–´ ì¶”ì¶œ (FAST: qwen/qwen3-32b)...", "sys")
    prompt_plan = f"""
ì…ë ¥: "{user_input}"

ì•„ë˜ ìŠ¤í‚¤ë§ˆë¥¼ ì •í™•íˆ ì§€ì¼œ JSONë§Œ ì¶œë ¥:
{{
  "task_type": "ì—…ë¬´ìœ í˜•(ì§§ê²Œ)",
  "law_hint": {{
    "law_name": "ë²•ë ¹ëª…(ê°€ëŠ¥í•˜ë©´ ê³µì‹ëª…)",
    "article_no": "ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "keywords": ["ê²€ìƒ‰ì–´1","ê²€ìƒ‰ì–´2","ê²€ìƒ‰ì–´3"]
}}

ì£¼ì˜:
- law_nameì´ í™•ì‹  ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ.
- keywordsëŠ” ìƒí™©í•µì‹¬ ìœ„ì£¼.
"""
    plan = llm_service.generate_json(prompt_plan, prefer="fast", max_retry=2)
    if not plan:
        plan = {"task_type": "ì—…ë¬´", "law_hint": {"law_name": "", "article_no": ""}, "keywords": kw_fallback[:3]}

    # Plan ë³´ì • + í•œì ì œê±°
    task_type = remove_hanja(plan.get("task_type") or "ì—…ë¬´")
    law_hint = plan.get("law_hint") if isinstance(plan.get("law_hint"), dict) else {}
    law_name = remove_hanja(law_hint.get("law_name") or "")
    art_no = clean_text(law_hint.get("article_no") or "")
    keywords = plan.get("keywords") if isinstance(plan.get("keywords"), list) else []
    keywords = [remove_hanja(x) for x in keywords if remove_hanja(x)]
    if not keywords:
        keywords = kw_fallback[:3]

    # 2) Law Search
    add_log("ğŸ“š [Law] ë²•ë ¹ ê²€ìƒ‰ ë° ì¡°ë¬¸ í™•ì¸...", "legal")
    legal_basis = "ë²•ë ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    legal_status = "PENDING"
    law_debug = {}

    # í›„ë³´ ì¿¼ë¦¬ êµ¬ì„±
    law_queries = []
    if law_name:
        law_queries.append(law_name)
    for k in keywords[:3]:
        if k and k not in law_queries:
            law_queries.append(k)

    chosen = None
    chosen_q = None
    for q in law_queries[:4]:
        candidates = law_api.search_law(q, display=10)
        if candidates:
            chosen = candidates[0]
            chosen_q = q
            break

    if chosen:
        nm = remove_hanja(chosen.get("lawNm") or "")
        mst = clean_text(chosen.get("MST") or "")
        link = clean_text(chosen.get("link") or "")

        # ì¡°ë¬¸ í…ìŠ¤íŠ¸
        full_text = law_api.get_article_text_by_mst(mst, art_no if art_no else None)
        full_text = remove_hanja(full_text)

        if full_text and len(full_text) >= 20:
            if art_no:
                legal_basis = f"{nm} ì œ{re.sub(r'[^0-9]', '', art_no)}ì¡°\n{truncate_text(full_text, 2500)}"
            else:
                legal_basis = f"{nm}\n{truncate_text(full_text, 2500)}"
            legal_status = "CONFIRMED"
        else:
            legal_basis = f"ë²•ë ¹({nm})ì€ ì°¾ì•˜ìœ¼ë‚˜ ì¡°ë¬¸ ì›ë¬¸ í™•ë³´ ì‹¤íŒ¨."
            legal_status = "WEAK"

        law_debug = {"mst": mst, "name": nm, "link": link, "query_used": chosen_q or ""}
    else:
        legal_basis = "ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨(í›„ë³´ ì—†ìŒ)."
        legal_status = "FAIL"
        law_debug = {"query_used": law_queries[:4]}

    # 3) Naver Evidence
    add_log("ğŸŒ [Search] ì‚¬ì‹¤ê´€ê³„ ë° ë¦¬ìŠ¤í¬ ì ê²€ (Naver)...", "search")
    ev_text = ""
    ev_items = []

    if keywords:
        q = " ".join(keywords[:2]) + " í–‰ì •ì²˜ë¶„"
        raw_items = naver_search.search(q, cat="news", display=5)
        for item in raw_items:
            clean_t = remove_hanja(item.get("title"))
            clean_d = remove_hanja(item.get("description"))
            link = clean_text(item.get("link"))
            ev_items.append({"title": clean_t, "link": link, "desc": clean_d})
            ev_text += f"- {clean_t}: {clean_d}\n"

    # 4) Strategy
    prefer_strat = "strict" if legal_status != "CONFIRMED" else "fast"
    add_log(
        f"ğŸ§  [Analyst] ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½ ({'STRICT: llama-3.3-70b' if prefer_strat=='strict' else 'FAST: qwen/qwen3-32b'})...",
        "strat",
    )
    prompt_strat = f"""
[ì—…ë¬´ìœ í˜•] {task_type}
[ìƒí™©] {user_input}

[ë²•ì ê·¼ê±°]
{legal_basis}

[ì°¸ê³ (ë„¤ì´ë²„)]
{truncate_text(ev_text, 900)}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±(ë§ˆí¬ë‹¤ìš´):
1) ì²˜ë¦¬ ë°©í–¥ (3~6ì¤„)
2) í•µì‹¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë¶ˆë¦¿ 5~10ê°œ)
3) ì˜ˆìƒ ë¯¼ì›/ë°˜ë°œ & ëŒ€ì‘ (3~6ì¤„)

ì£¼ì˜:
- ê³¼ë„í•œ ì¼ë°˜ë¡  ê¸ˆì§€
- ëª¨ë¥´ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”"ë¥¼ ëª…ì‹œ
"""
    strategy = llm_service.generate_text(prompt_strat, prefer=prefer_strat, temp=0.1)
    strategy = remove_hanja(strategy)

    # 5) Drafter (STRICT always)
    add_log("âœï¸ [Drafter] ê³µë¬¸ì„œ ì´ˆì•ˆ ì‘ì„± (STRICT: llama-3.3-70b-versatile)...", "draft")
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"

    prompt_draft = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ë¯¼ì›/ì—…ë¬´ ìƒí™©:
{user_input}

ë²•ì  ê·¼ê±°(í™•ë³´ëœ ë²”ìœ„):
{legal_basis}

ì²˜ë¦¬ ì „ëµ(ìš”ì•½):
{truncate_text(strategy, 900)}

ì‘ì„± ì›ì¹™:
- ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘, ë¶ˆí•„ìš”í•œ ìˆ˜ì‚¬ ê¸ˆì§€
- ë³¸ë¬¸ êµ¬ì¡°: [ê²½ìœ„] -> [ê·¼ê±°] -> [ì¡°ì¹˜/ì•ˆë‚´] -> [ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹(ìˆìœ¼ë©´)
- ë²•ë ¹ ì›ë¬¸ì´ ë¶ˆí™•ì‹¤í•˜ë©´ 'ì¶”ê°€ í™•ì¸ í•„ìš”' ë¬¸êµ¬ë¥¼ í¬í•¨
"""
    doc_json = llm_service.generate_json(prompt_draft, prefer="strict", max_retry=2)
    doc_final = ensure_doc_shape(doc_json)

    # 6) Save to DB
    add_log("ğŸ’¾ [System] ê²°ê³¼ ì €ì¥ ì¤‘...", "sys")
    payload = {
        "created_at": datetime.now().isoformat(),
        "dept": clean_text(dept),
        "officer": clean_text(officer),
        "task_type": task_type,
        "keywords": safe_json_dump(keywords),
        "input": user_input,
        "legal_status": legal_status,
        "legal_basis": legal_basis,
        "final_doc": safe_json_dump(doc_final),
        "strategy": strategy,
        "provenance": safe_json_dump(ev_items),
        "model_last": llm_service.last_model,
        "metrics": safe_json_dump(st.session_state.get("metrics", {})),
        "law_debug": safe_json_dump(law_debug),
    }
    db_msg = db_service.save_log(payload)
    add_log(f"âœ… ì™„ë£Œ ({db_msg})", "sys")

    time.sleep(0.25)
    log_area.empty()

    return {
        "doc": doc_final,
        "meta": {"doc_num": doc_num, "today": today_str, "dept": dept, "officer": officer},
        "legal_basis": legal_basis,
        "legal_status": legal_status,
        "strategy": strategy,
        "ev_items": ev_items,
        "task_type": task_type,
        "keywords": keywords,
        "db_msg": db_msg,
        "law_debug": law_debug,
    }


# =========================
# 9) UI
# =========================
def main():
    st.session_state.setdefault("dept", "OOì‹œì²­ OOê³¼")
    st.session_state.setdefault("officer", "ê¹€ì£¼ë¬´ê´€")

    col_l, col_r = st.columns([1, 1.2], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("Dual Router v5.1 â€” FAST(qwen/qwen3-32b) + STRICT(llama-3.3-70b)")
        st.markdown("---")

        with st.expander("ğŸ“ ì‚¬ìš©ì ì •ë³´ ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­",
            height=200,
            placeholder="ì˜ˆ: ë¶ˆë²•ì£¼ì •ì°¨ ê³¼íƒœë£Œ ë¶€ê³¼ì— ëŒ€í•œ ì´ì˜ì‹ ì²­ ê¸°ê° í†µì§€ì„œ ì‘ì„±í•´ì¤˜.",
        )

        if st.button("ğŸš€ ë¬¸ì„œ ìƒì„± ì‹¤í–‰", type="primary", use_container_width=True):
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("AI ì—ì´ì „íŠ¸ í˜‘ì—… ì¤‘..."):
                    try:
                        res = run_workflow(user_input.strip(), st.session_state["dept"], st.session_state["officer"])
                        st.session_state["result"] = res
                    except Exception as e:
                        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")

        # Metrics Dashboard
        st.markdown("---")
        st.subheader("ğŸ“Š ì‚¬ìš©ëŸ‰(ì„¸ì…˜ ê¸°ì¤€)")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)

        if calls:
            for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                st.write(f"- **{k}**: {v}íšŒ")
            st.caption(f"ì´ í† í°(ê°€ëŠ¥í•œ ê²½ìš°): {tokens_total}")
        else:
            st.info("ëŒ€ê¸° ì¤‘...")

        st.markdown(
            "<div class='small-muted'>TIP: Planner/StrategyëŠ” FAST, ê³µë¬¸(JSON)ì€ STRICTë¡œ ê³ ì •ë˜ì–´ í’ˆì§ˆ-ì†ë„ ê· í˜•ì„ ë§ì¶¥ë‹ˆë‹¤.</div>",
            unsafe_allow_html=True,
        )

    with col_r:
        res = st.session_state.get("result")

        if not res:
            st.markdown(
                """
<div style='text-align: center; padding: 120px 20px; color: #aaa; border: 2px dashed #ddd; border-radius: 12px; background:#fff;'>
  <h3>ğŸ“„ Document Preview</h3>
  <p>ì™¼ìª½ì—ì„œ ì—…ë¬´ë¥¼ ì…ë ¥í•˜ê³  ì‹¤í–‰ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.<br>ìë™ìœ¼ë¡œ ë²•ë ¹ì„ ê²€í† í•˜ê³  ê³µë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.</p>
</div>
""",
                unsafe_allow_html=True,
            )
        else:
            doc = res["doc"]
            meta = res["meta"]

            tab1, tab2 = st.tabs(["ğŸ“„ ê³µë¬¸ì„œ ê²°ê³¼", "ğŸ” ê·¼ê±° ë° ë¶„ì„"])

            with tab1:
                body_html = "".join(
                    [f"<p style='margin:0 0 14px 0;'>{safe_html(p)}</p>" for p in doc["body_paragraphs"]]
                )
                html = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc['title'])}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {safe_html(meta['doc_num'])}</span>
    <span>ì‹œí–‰ì¼ì: {safe_html(meta['today'])}</span>
    <span>ìˆ˜ì‹ : {safe_html(doc['receiver'])}</span>
  </div>
  <div class="doc-body">
    {body_html}
  </div>
  <div class="doc-footer">{safe_html(doc['department_head'])}</div>
</div>
"""
                # components.html ì•ˆì • ë Œë” (head/css ì–µì§€ ì‚½ì… X)
                components.html(html, height=880, scrolling=True)

            with tab2:
                st.success(f"DB: {res.get('db_msg', '')}")
                st.info(f"ğŸ“œ ë²•ì  ê·¼ê±° ìƒíƒœ: {res.get('legal_status')}")
                st.info(f"ğŸ“œ ë²•ì  ê·¼ê±°:\n{res['legal_basis']}")

                st.markdown("### ğŸ’¡ ì²˜ë¦¬ ì „ëµ")
                st.markdown(res["strategy"])

                st.markdown("### ğŸ” í‚¤ì›Œë“œ")
                st.write(res.get("keywords", []))

                st.markdown("### ğŸ“ ì°¸ê³  ìë£Œ (Naver)")
                for item in res["ev_items"]:
                    title = clean_text(item.get("title"))
                    link = clean_text(item.get("link"))
                    desc = clean_text(item.get("desc"))
                    if link:
                        st.markdown(f"- [{title}]({link}) â€” {desc}")
                    else:
                        st.markdown(f"- {title} â€” {desc}")

                with st.expander("ğŸ› ï¸ ë””ë²„ê·¸(ë²•ë ¹)", expanded=False):
                    st.code(safe_json_dump(res.get("law_debug", {})), language="json")


if __name__ == "__main__":
    main()
