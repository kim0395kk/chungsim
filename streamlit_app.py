# app.py â€” AI í–‰ì •ê´€ Pro (Stable / Dual-Model Router v6)
# Groq: qwen/qwen3-32b (FAST) + llama-3.3-70b-versatile (STRICT)
# LAWGO(DRF) + NAVER + Supabase (ì˜µì…˜: ë¡œê·¸ì¸/ì´ë ¥)
#
# âœ… ì •í™•ë„ ê°œì„  í¬ì¸íŠ¸(í•µì‹¬)
# 1) Intake(ì‚¬ì‹¤/ìš”êµ¬/ëŒ€ìƒ/ì‹œê°„/ì¥ì†Œ/ì¦ê±°) ê°•ì œ êµ¬ì¡°í™”
# 2) ë²•ë ¹ í›„ë³´ 3~6ê°œ ìƒì„± -> DRFë¡œ ì›ë¬¸ í™•ë³´ -> Verifier ì ìˆ˜ë¡œ ì„ íƒ(ë£¨í”„)
# 3) "ë²•ì ê·¼ê±°"ëŠ” 'ì›ë¬¸ í…ìŠ¤íŠ¸'ë§Œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì¤Œ(XML/ì¡ë¬¸/í•œì ì œê±°)
# 4) ê³µë¬¸(JSON)ì€ STRICT ëª¨ë¸ ê³ ì • + JSON ì¬ì‹œë„ + í’ˆì§ˆì²´í¬(QA)
#
# âš ï¸ U+EA01(ë¹„í‘œì‹œ ë¬¸ì) ì—ëŸ¬ ë°©ì§€:
# - ì´ íŒŒì¼ì€ "ë©”ëª¨ì¥(plain text)"ë¡œ ë¶™ì—¬ë„£ê³  ì €ì¥í•˜ì„¸ìš”.
# - í•œê¸€ ì›Œë“œ/ì›¹ì—ì„œ ë³µë¶™í•˜ë©´ ì¢…ì¢… Private Use Characterê°€ ì„ì…ë‹ˆë‹¤.
#
# -------------------------------
# secrets.toml ì˜ˆì‹œ (Streamlit Cloud)
# -------------------------------
# [general]
# GROQ_API_KEY = "..."
# GROQ_MODEL_FAST = "qwen/qwen3-32b"
# GROQ_MODEL_STRICT = "llama-3.3-70b-versatile"
#
# [law]
# LAW_API_ID = "..."  # law.go.kr DRF OC ê°’
#
# [naver]
# CLIENT_ID = "..."
# CLIENT_SECRET = "..."
#
# [supabase]  # ì˜µì…˜(ë¡œê·¸/íˆìŠ¤í† ë¦¬)
# SUPABASE_URL = "https://xxxx.supabase.co"
# SUPABASE_KEY = "service_role_or_anon_key"
#
# -------------------------------
# requirements.txt (ê¶Œì¥)
# -------------------------------
# streamlit
# groq
# requests
# xmltodict
# supabase
# python-dateutil

import streamlit as st
import streamlit.components.v1 as components

import json
import re
import time
from datetime import datetime
from html import escape, unescape
from typing import Any, Dict, List, Optional, Tuple

# =========================
# 0) Optional Imports (Safety)
# =========================
try:
    from groq import Groq
except Exception:
    Groq = None

try:
    import requests
except Exception:
    requests = None

try:
    import xmltodict
except Exception:
    xmltodict = None

try:
    from supabase import create_client
except Exception:
    create_client = None


# =========================
# 1) Page & Style
# =========================
st.set_page_config(
    layout="wide",
    page_title="AI í–‰ì •ê´€ Pro (Dual v6.0)",
    page_icon="âš–ï¸",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
<style>
.stApp { background-color: #f8f9fa; }

.paper-sheet {
  background: #fff; width: 100%; max-width: 210mm; min-height: 297mm;
  padding: 25mm; margin: auto; box-shadow: 0 6px 18px rgba(0,0,0,0.08);
  font-family: 'Noto Serif KR','Nanum Myeongjo',serif;
  color:#111; line-height:1.65; position:relative;
}
.doc-header { text-align:center; font-size:24pt; font-weight:800; margin-bottom:30px; letter-spacing:1px; }
.doc-info {
  display:flex; justify-content:space-between; gap:10px; flex-wrap:wrap;
  font-size:11pt; border-bottom:2px solid #111; padding-bottom:12px; margin-bottom:20px;
}
.doc-body { font-size:12pt; text-align: justify; }
.doc-footer { text-align:center; font-size:20pt; font-weight:800; margin-top:80px; letter-spacing:3px; }
.stamp {
  position:absolute; bottom:85px; right:80px; border:3px solid #d32f2f; color: #d32f2f;
  padding:6px 12px; font-size:14pt; font-weight:800; transform:rotate(-15deg);
  opacity:0.85; border-radius:4px; font-family: 'Nanum Gothic', sans-serif;
}

/* Agent logs */
.agent-log {
  font-family: 'Pretendard', sans-serif; font-size: 0.92rem; padding: 8px 12px;
  border-radius: 8px; margin-bottom: 6px; background: white; border: 1px solid #e5e7eb;
}
.log-legal { border-left: 5px solid #3b82f6; }
.log-search { border-left: 5px solid #f97316; }
.log-strat { border-left: 5px solid #8b5cf6; }
.log-draft { border-left: 5px solid #ef4444; }
.log-sys   { border-left: 5px solid #9ca3af; }

.small-muted { color:#6b7280; font-size:12px; }

/* Evidence card */
.ev-card{
  background:#fff; border:1px solid #e5e7eb; border-radius:10px;
  padding:10px 12px; margin:8px 0;
}
.ev-title{ font-weight:700; }
.ev-desc{ color:#374151; margin-top:4px; }
</style>
""",
    unsafe_allow_html=True,
)

_TAG_RE = re.compile(r"<[^>]+>")
_CTRL_RE = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]")
# í•œì(CJK Unified Ideographs) ì œê±° (ì›ë¬¸ì— ì„ì—¬ ë‚˜ì˜¤ë©´ ë³´ê¸° í˜ë“¤ì–´ì„œ "í‘œì‹œìš©"ì—ì„œ ì œê±°)
_HANJA_RE = re.compile(r"[\u3400-\u4DBF\u4E00-\u9FFF]+")


# =========================
# 2) Helpers
# =========================
def clean_text(value) -> str:
    """HTML íƒœê·¸ ë° ì œì–´ë¬¸ì ì œê±°"""
    if value is None:
        return ""
    s = str(value)
    s = unescape(s)
    s = _TAG_RE.sub("", s)
    s = _CTRL_RE.sub("", s)
    return s.strip()


def safe_html(value) -> str:
    return escape(clean_text(value), quote=False).replace("\n", "<br>")


def truncate_text(s: str, max_chars: int = 2800) -> str:
    s = s or ""
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "\n...(ë‚´ìš© ì¶•ì†Œë¨)"


def strip_hanja_for_display(s: str) -> str:
    """í‘œì‹œìš©: í•œì ì œê±° + ì´ìƒí•œ êµ¬ë¶„ì(ìŠ¤í¬ë¦°ìƒ· ê°™ì€ ||> ë“±) ì •ë¦¬"""
    if not s:
        return ""
    s = _HANJA_RE.sub("", s)
    # DRF/ê°€ê³µ ê³¼ì •ì—ì„œ ì„ì´ëŠ” ì¡ë¬¸ íŒ¨í„´ ì •ë¦¬
    s = re.sub(r"\|\>+", "", s)
    s = re.sub(r"\s{2,}", " ", s)
    s = s.replace("  ", " ")
    return s.strip()


def normalize_whitespace(s: str) -> str:
    if not s:
        return ""
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def ensure_doc_shape(doc):
    fallback = {
        "title": "ë¬¸ ì„œ (ìƒì„± ì‹¤íŒ¨)",
        "receiver": "ìˆ˜ì‹ ì ì°¸ì¡°",
        "body_paragraphs": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¬¸ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."],
        "department_head": "í–‰ì •ê¸°ê´€ì¥",
    }
    if not isinstance(doc, dict):
        return fallback

    body = doc.get("body_paragraphs")
    if isinstance(body, str):
        body = [body]
    if not isinstance(body, list) or not body:
        body = fallback["body_paragraphs"]

    return {
        "title": clean_text(doc.get("title") or fallback["title"]),
        "receiver": clean_text(doc.get("receiver") or fallback["receiver"]),
        "body_paragraphs": [clean_text(x) for x in body if clean_text(x)] or fallback["body_paragraphs"],
        "department_head": clean_text(doc.get("department_head") or fallback["department_head"]),
    }


def safe_json_dump(obj):
    try:
        return json.dumps(obj, ensure_ascii=False, default=str)
    except Exception:
        return "{}"


def extract_keywords_kor(text: str, max_k: int = 8) -> List[str]:
    """ê°„ì´ í‚¤ì›Œë“œ: LLM ì‹¤íŒ¨ì‹œ fallback"""
    if not text:
        return []
    t = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", text)
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,14}", t)
    stop = {
        "ê·¸ë¦¬ê³ ", "ê´€ë ¨", "ë¬¸ì˜", "ì‚¬í•­", "ëŒ€í•˜ì—¬", "ëŒ€í•œ", "ì²˜ë¦¬", "ìš”ì²­",
        "ì‘ì„±", "ì•ˆë‚´", "ê²€í† ", "ë¶ˆí¸", "ë¯¼ì›", "ì‹ ì²­", "ë°œê¸‰", "ì œì¶œ",
        "ê°€ëŠ¥", "ì—¬ë¶€", "ì¡°ì¹˜", "í™•ì¸", "í†µë³´", "íšŒì‹ ", "ê²°ê³¼", "ì‚¬ìœ "
    }
    out = []
    for w in words:
        if w in stop:
            continue
        if w.isdigit():
            continue
        if w not in out:
            out.append(w)
        if len(out) >= max_k:
            break
    return out


# =========================
# 3) Metrics
# =========================
def metrics_init():
    if "metrics" not in st.session_state:
        st.session_state["metrics"] = {"calls": {}, "tokens_total": 0}


def metrics_add(model_name: str, tokens_total: Optional[int] = None):
    metrics_init()
    m = st.session_state["metrics"]
    m["calls"][model_name] = m["calls"].get(model_name, 0) + 1
    if tokens_total is not None:
        try:
            m["tokens_total"] += int(tokens_total)
        except Exception:
            pass


metrics_init()


# =========================
# 4) LLM Service (Dual Router)
# =========================
class LLMService:
    """
    - FAST: qwen/qwen3-32b
    - STRICT: llama-3.3-70b-versatile
    """
    def __init__(self):
        g = st.secrets.get("general", {})
        self.groq_key = g.get("GROQ_API_KEY")
        self.model_fast = g.get("GROQ_MODEL_FAST", "qwen/qwen3-32b")
        self.model_strict = g.get("GROQ_MODEL_STRICT", "llama-3.3-70b-versatile")
        self.client = None
        self.last_model = "N/A"

        if Groq and self.groq_key:
            try:
                self.client = Groq(api_key=self.groq_key)
            except Exception:
                self.client = None

    def _chat(self, model: str, messages, temp: float, json_mode: bool):
        if not self.client:
            raise RuntimeError("Groq client not ready (missing key/lib).")

        kwargs = {"model": model, "messages": messages, "temperature": temp}
        if json_mode:
            kwargs["response_format"] = {"type": "json_object"}

        resp = self.client.chat.completions.create(**kwargs)
        self.last_model = model

        tokens_total = None
        try:
            usage = getattr(resp, "usage", None)
            if usage:
                tokens_total = getattr(usage, "total_tokens", None)
        except Exception:
            tokens_total = None

        metrics_add(model, tokens_total=tokens_total)
        return resp.choices[0].message.content or ""

    def _parse_json(self, text: str) -> Dict[str, Any]:
        try:
            return json.loads(text)
        except Exception:
            cleaned = re.sub(r"```json|```", "", text).strip()
            m = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(0))
                except Exception:
                    return {}
            return {}

    def generate_text(self, prompt: str, prefer: str = "fast", temp: float = 0.1) -> str:
        if not self.client:
            return "Groq API Keyê°€ ì—†ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜"

        model_first = self.model_fast if prefer == "fast" else self.model_strict
        messages = [
            {"role": "system", "content": "You are a Korean public-administration assistant. Be factual, structured, and practical."},
            {"role": "user", "content": prompt},
        ]

        try:
            return self._chat(model_first, messages, temp, json_mode=False)
        except Exception:
            if prefer == "fast":
                try:
                    return self._chat(self.model_strict, messages, temp, json_mode=False)
                except Exception as e2:
                    return f"LLM Error: {e2}"
            return "LLM Error"

    def generate_json(self, prompt: str, prefer: str = "fast", temp: float = 0.1, max_retry: int = 2) -> Dict[str, Any]:
        if not self.client:
            return {}

        sys_json = "Output JSON only. No markdown. No explanation. Follow the schema exactly."
        messages = [
            {"role": "system", "content": sys_json},
            {"role": "user", "content": prompt},
        ]
        model_first = self.model_fast if prefer == "fast" else self.model_strict

        # 1) same model retries
        for _ in range(max_retry):
            try:
                txt = self._chat(model_first, messages, temp, json_mode=True)
                js = self._parse_json(txt)
                if js:
                    return js
            except Exception:
                pass

        # 2) strict escalate
        try:
            txt = self._chat(self.model_strict, messages, temp, json_mode=True)
            js = self._parse_json(txt)
            return js if js else {}
        except Exception:
            return {}


llm = LLMService()


# =========================
# 5) LAW API (DRF) â€” Search + Service (XML)
# =========================
class LawAPIService:
    def __init__(self):
        self.oc = st.secrets.get("law", {}).get("LAW_API_ID")
        self.search_url = "https://www.law.go.kr/DRF/lawSearch.do"
        self.service_url = "https://www.law.go.kr/DRF/lawService.do"
        self.enabled = bool(requests and xmltodict and self.oc)

    def search_law(self, query: str, display: int = 10) -> List[Dict[str, str]]:
        if not self.enabled or not query:
            return []
        try:
            params = {
                "OC": self.oc,
                "target": "law",
                "type": "XML",
                "query": query,
                "display": display,
                "page": 1,
            }
            r = requests.get(self.search_url, params=params, timeout=7)
            r.raise_for_status()
            data = xmltodict.parse(r.text)
            laws = data.get("LawSearch", {}).get("law", [])
            if isinstance(laws, dict):
                laws = [laws]

            out = []
            for it in laws:
                if not isinstance(it, dict):
                    continue
                out.append(
                    {
                        "lawNm": it.get("ë²•ë ¹ëª…í•œê¸€") or it.get("lawNm") or it.get("ë²•ë ¹ëª…") or "",
                        "MST": it.get("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸") or it.get("MST") or it.get("mst") or "",
                        "link": it.get("ë²•ë ¹ìƒì„¸ë§í¬") or it.get("link") or "",
                        "promulgation": it.get("ê³µí¬ì¼ì") or "",
                        "amend": it.get("ê°œì •ì¼ì") or "",
                    }
                )
            return [x for x in out if clean_text(x.get("lawNm")) and clean_text(x.get("MST"))]
        except Exception:
            return []

    def _extract_articles(self, law_obj: dict) -> List[dict]:
        articles = law_obj.get("Article", []) or []
        if isinstance(articles, dict):
            articles = [articles]
        out = []
        for a in articles:
            if isinstance(a, dict):
                out.append(a)
        return out

    def get_article_by_mst(self, mst: str, article_no: Optional[str] = None) -> Dict[str, Any]:
        """
        ë°˜í™˜:
        {
          "law_name": "...",
          "mst": "...",
          "article_no": "33",
          "article_title": "...",
          "article_text": "ì •ë¦¬ëœ ë³¸ë¬¸",
          "all_articles_index": ["ì œ1ì¡°", "ì œ2ì¡°", ...] (ìµœëŒ€ 80ê°œ)
        }
        """
        if not self.enabled or not mst:
            return {}

        try:
            params = {"OC": self.oc, "target": "law", "type": "XML", "MST": mst}
            r = requests.get(self.service_url, params=params, timeout=10)
            r.raise_for_status()
            data = xmltodict.parse(r.text)

            law = data.get("Law") or data.get("law") or {}
            law_name = clean_text(law.get("ë²•ë ¹ëª…í•œê¸€") or law.get("LawName") or law.get("ë²•ë ¹ëª…") or "")
            articles = self._extract_articles(law)

            # ì¸ë±ìŠ¤ (UIìš©)
            idx = []
            for a in articles[:80]:
                at = clean_text(a.get("ArticleTitle") or "")
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                if at:
                    idx.append(at)
                elif an:
                    idx.append(f"ì œ{an}ì¡°")
            # article_no ì—†ìœ¼ë©´, ì¼ë¶€ë¼ë„ ë³´ì—¬ì¤„ ìˆ˜ ìˆê²Œ 1ì¡° ë°˜í™˜
            if not article_no:
                # ì²« ì¡°ë¬¸ êµ¬ì„±
                if articles:
                    a0 = articles[0]
                    return self._format_article(law_name, mst, a0, idx)
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            tgt = re.sub(r"[^0-9]", "", str(article_no))
            if not tgt:
                return {"law_name": law_name, "mst": mst, "all_articles_index": idx}

            # ì¡°ë¬¸ ë§¤ì¹­: ì¡°ë¬¸ë²ˆí˜¸ ë˜ëŠ” ì œëª© "ì œNNì¡°"
            for a in articles:
                an = clean_text(a.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
                at = clean_text(a.get("ArticleTitle") or "")
                if tgt == re.sub(r"[^0-9]", "", an) or (tgt and f"ì œ{tgt}ì¡°" in at):
                    return self._format_article(law_name, mst, a, idx)

            # ëª» ì°¾ìœ¼ë©´ ë¹ˆê°’
            return {"law_name": law_name, "mst": mst, "article_no": tgt, "all_articles_index": idx}

        except Exception:
            return {}

    def _format_article(self, law_name: str, mst: str, art: dict, idx: List[str]) -> Dict[str, Any]:
        at = clean_text(art.get("ArticleTitle") or "")
        an = clean_text(art.get("@ì¡°ë¬¸ë²ˆí˜¸") or "")
        content = clean_text(art.get("ArticleContent") or "")

        # í•­/í˜¸ ë¬¸ë‹¨ í•©ì¹˜ê¸°
        paras = art.get("Paragraph", [])
        if isinstance(paras, dict):
            paras = [paras]
        p_lines = []
        for p in paras:
            if not isinstance(p, dict):
                continue
            pc = clean_text(p.get("ParagraphContent") or "")
            if pc:
                p_lines.append(pc)

        text = "\n".join([x for x in [content] + p_lines if x]).strip()
        text = normalize_whitespace(text)
        text_disp = strip_hanja_for_display(text)  # ë³´ê¸° ì¢‹ê²Œ í•œì ì œê±°

        return {
            "law_name": law_name,
            "mst": mst,
            "article_no": re.sub(r"[^0-9]", "", an) or "",
            "article_title": at or (f"ì œ{an}ì¡°" if an else ""),
            "article_text": text_disp,
            "all_articles_index": idx,
        }


law_api = LawAPIService()


# =========================
# 6) NAVER Search
# =========================
class NaverSearchService:
    def __init__(self):
        n = st.secrets.get("naver", {})
        self.cid = n.get("CLIENT_ID")
        self.csec = n.get("CLIENT_SECRET")
        self.enabled = bool(requests and self.cid and self.csec)

    def search(self, query: str, cat: str = "news", display: int = 5):
        if not self.enabled or not query:
            return []
        try:
            url = f"https://openapi.naver.com/v1/search/{cat}.json"
            headers = {"X-Naver-Client-Id": self.cid, "X-Naver-Client-Secret": self.csec}
            params = {"query": query, "display": display, "sort": "sim", "start": 1}
            r = requests.get(url, headers=headers, params=params, timeout=6)
            r.raise_for_status()
            return r.json().get("items", []) or []
        except Exception:
            return []


naver = NaverSearchService()


# =========================
# 7) Supabase (ë¡œê·¸/íˆìŠ¤í† ë¦¬)
# =========================
class DatabaseService:
    def __init__(self):
        self.client = None
        s = st.secrets.get("supabase", {})
        self.url = s.get("SUPABASE_URL")
        self.key = s.get("SUPABASE_KEY")
        if create_client and self.url and self.key:
            try:
                self.client = create_client(self.url, self.key)
            except Exception:
                self.client = None

    def enabled(self) -> bool:
        return bool(self.client)

    def insert_run(self, row: dict) -> Tuple[bool, str, Optional[str]]:
        """runs í…Œì´ë¸” insert, run_id ë¦¬í„´(ê°€ëŠ¥í•˜ë©´)"""
        if not self.client:
            return False, "DB ë¯¸ì—°ê²°", None
        try:
            safe_row = json.loads(safe_json_dump(row))
            resp = self.client.table("runs").insert(safe_row).execute()
            run_id = None
            try:
                data = getattr(resp, "data", None)
                if data and isinstance(data, list) and data:
                    run_id = data[0].get("run_id") or data[0].get("id")
            except Exception:
                run_id = None
            return True, "ì €ì¥ ì„±ê³µ", run_id
        except Exception as e:
            return False, f"ì €ì¥ ì‹¤íŒ¨: {e}", None

    def insert_step(self, row: dict) -> None:
        if not self.client:
            return
        try:
            safe_row = json.loads(safe_json_dump(row))
            self.client.table("run_steps").insert(safe_row).execute()
        except Exception:
            return

    def insert_artifact(self, row: dict) -> None:
        if not self.client:
            return
        try:
            safe_row = json.loads(safe_json_dump(row))
            self.client.table("artifacts").insert(safe_row).execute()
        except Exception:
            return

    def list_runs(self, user_key: str, limit: int = 20):
        """ê°„ë‹¨ ìœ ì €í‚¤ ê¸°ë°˜ íˆìŠ¤í† ë¦¬(ì§„ì§œ Auth ëŒ€ì‹ )"""
        if not self.client:
            return []
        try:
            resp = (
                self.client.table("runs")
                .select("run_id, created_at, task_type, law_name, article_no, final_verdict")
                .eq("user_id", user_key)
                .order("created_at", desc=True)
                .limit(limit)
                .execute()
            )
            return getattr(resp, "data", []) or []
        except Exception:
            return []

    def load_run_detail(self, run_id: str):
        if not self.client or not run_id:
            return None
        try:
            r1 = (
                self.client.table("runs")
                .select("*")
                .eq("run_id", run_id)
                .limit(1)
                .execute()
            )
            data = getattr(r1, "data", None)
            if not data:
                return None
            run_row = data[0]

            art = (
                self.client.table("artifacts")
                .select("kind, content, created_at")
                .eq("run_id", run_id)
                .order("created_at", desc=True)
                .execute()
            )
            art_data = getattr(art, "data", []) or []
            run_row["_artifacts"] = art_data
            return run_row
        except Exception:
            return None


db = DatabaseService()


# =========================
# 8) Core Logic (Agentic-ish)
# =========================
def intake_schema(user_input: str) -> Dict[str, Any]:
    """
    ë¯¼ì› ìƒí™©ì„ 'ì‚¬ì‹¤/ìš”êµ¬/ëŒ€ìƒ/ì‹œê°„/ì¥ì†Œ/ì¦ê±°/ìŸì /í‚¤ì›Œë“œ'ë¡œ ê°•ì œ êµ¬ì¡°í™”.
    ì´ê²Œ ì •í™•ë„ í•µì‹¬(ë²•ë ¹ ì—‰ëš±í•¨ ë°©ì§€).
    """
    kw_fallback = extract_keywords_kor(user_input, max_k=10)

    prompt = f"""
ë‹¤ìŒ ë¯¼ì›/ì—…ë¬´ ì§€ì‹œë¥¼ "í–‰ì •ì‚¬ì‹¤ê´€ê³„" ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”í•´ë¼.
ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€).

{{
  "task_type": "ì£¼ê¸°ìœ„ë°˜|ë¬´ë‹¨ë°©ì¹˜|ë¶ˆë²•ì£¼ì •ì°¨|í–‰ì •ì²˜ë¶„|ì •ë³´ê³µê°œ|ê¸°íƒ€",
  "authority_scope": {{
    "my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹",
    "can_do": ["í˜„ì¥í™•ì¸","ê³„ë„","í†µì§€","ì•ˆë‚´","ì´ê´€"],
    "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬","ê°•ì œì§‘í–‰","ì••ìˆ˜ìˆ˜ìƒ‰","êµ¬ê¸ˆ"]
  }},
  "facts": {{
    "who": "ëŒ€ìƒ(ì°¨ëŸ‰/ê±´ì„¤ê¸°ê³„/ì—…ì²´/ê°œì¸ ë“±)",
    "what": "ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€(í•µì‹¬ 1~2ë¬¸ì¥)",
    "where": "ì¥ì†Œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "when": "ê¸°ê°„/ì¼ì‹œ(ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)",
    "evidence": ["ì‚¬ì§„","ì˜ìƒ","ì§„ìˆ ","ê¸°íƒ€(ì—†ìœ¼ë©´ ë¹ˆë°°ì—´)"]
  }},
  "request": {{
    "user_wants": "ë¯¼ì›ì¸ì´ ì›í•˜ëŠ” ì¡°ì¹˜",
    "constraints": "ê¸°í•œ/ì ˆì°¨/ì´ì˜ì œê¸° ë“±(ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´)"
  }},
  "issues": ["ìŸì 1","ìŸì 2"],
  "keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3","í‚¤ì›Œë“œ4"]
}}

ì…ë ¥:
\"\"\"{user_input}\"\"\"

ì£¼ì˜:
- ì†Œì„¤ ê¸ˆì§€. ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ì€ 'ì¶”ê°€ í™•ì¸ í•„ìš”'ë¡œ ì²˜ë¦¬.
- ì¥ì†Œ/ì‹œê°„ì´ ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´.
- keywordsëŠ” 'ì‚¬ì‹¤ ê¸°ë°˜' í•µì‹¬ì–´ë¡œ.
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    # ë³´ì •
    if not js:
        return {
            "task_type": "ê¸°íƒ€",
            "authority_scope": {"my_role": "ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹", "can_do": ["í˜„ì¥í™•ì¸", "ê³„ë„", "í†µì§€", "ì•ˆë‚´", "ì´ê´€"], "cannot_do": ["í˜•ì‚¬ìˆ˜ì‚¬", "ê°•ì œì§‘í–‰", "ì••ìˆ˜ìˆ˜ìƒ‰", "êµ¬ê¸ˆ"]},
            "facts": {"who": "", "what": user_input[:120], "where": "", "when": "", "evidence": []},
            "request": {"user_wants": "", "constraints": ""},
            "issues": [],
            "keywords": kw_fallback[:4],
        }

    if not isinstance(js.get("keywords"), list) or not js["keywords"]:
        js["keywords"] = kw_fallback[:4]
    js["keywords"] = [clean_text(x) for x in js["keywords"] if clean_text(x)]
    if not js["keywords"]:
        js["keywords"] = kw_fallback[:4]

    if not isinstance(js.get("issues"), list):
        js["issues"] = []
    js["issues"] = [clean_text(x) for x in js["issues"] if clean_text(x)]

    # input quality (ë£°)
    missing = []
    facts = js.get("facts") if isinstance(js.get("facts"), dict) else {}
    if not clean_text(facts.get("where")):
        missing.append("where")
    if not clean_text(facts.get("when")):
        missing.append("when")
    score = 100 - 20 * len(missing)
    js["_input_quality"] = {"score": max(score, 40), "missing_fields": missing}
    return js


def generate_law_candidates(case: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ë²•ë ¹ í›„ë³´ëŠ” 1ê°œê°€ ì•„ë‹ˆë¼ ì—¬ëŸ¬ ê°œ!
    ì—¬ê¸°ì„œ 'ì—‰ëš±í•œ ë²•ë ¹' í™•ë¥ ì´ í™• ì¤„ì–´ë“¦.
    """
    task_type = clean_text(case.get("task_type"))
    facts = case.get("facts") if isinstance(case.get("facts"), dict) else {}
    issues = case.get("issues", [])
    keywords = case.get("keywords", [])
    # rule hint (ì—…ë¬´ ë„ë©”ì¸)
    domain_hint = []
    if task_type == "ì£¼ê¸°ìœ„ë°˜":
        domain_hint += ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²• ì‹œí–‰ë ¹", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¬´ë‹¨ë°©ì¹˜":
        domain_hint += ["ìë™ì°¨ê´€ë¦¬ë²•", "ë„ë¡œêµí†µë²•"]
    if task_type == "ë¶ˆë²•ì£¼ì •ì°¨":
        domain_hint += ["ë„ë¡œêµí†µë²•", "ì£¼ì°¨ì¥ë²•"]

    prompt = f"""
ë„ˆëŠ” 'ë²•ë ¹ í›„ë³´ ìƒì„±ê¸°'ë‹¤. ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥.

{{
  "candidates": [
    {{"law_name":"ë²•ë ¹ëª…","article_hint":"ì¡°ë²ˆí˜¸(ìˆ«ìë§Œ, ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´)","reason":"ì§§ê²Œ","confidence":0.0}},
    {{"law_name":"...","article_hint":"","reason":"...","confidence":0.0}}
  ]
}}

ì…ë ¥(ì‚¬ì‹¤ìš”ì•½):
- task_type: {task_type}
- who: {facts.get("who","")}
- what: {facts.get("what","")}
- where: {facts.get("where","")}
- when: {facts.get("when","")}
- issues: {issues}
- keywords: {keywords}

ê·œì¹™:
- candidatesëŠ” 3~6ê°œ
- law_nameì€ "ê³µì‹ ë²•ë ¹ëª…" ìš°ì„ 
- í™•ì‹  ì—†ìœ¼ë©´ confidence ë‚®ê²Œ
- article_hintëŠ” ëª¨ë¥´ë©´ ë¹ˆë¬¸ìì—´
- 'ë‚´ ê¶Œí•œ(ì£¼ê¸°ìœ„ë°˜ ë‹¨ì† ë‹´ë‹¹)' ë²”ìœ„ì—ì„œ ë‹¤ë£° ê°€ëŠ¥ì„±ì´ í° ë²•ë ¹ ìš°ì„ 
"""
    js = llm.generate_json(prompt, prefer="fast", max_retry=2) or {}
    cands = js.get("candidates", []) if isinstance(js.get("candidates"), list) else []
    out = []
    # ë£° ê¸°ë°˜ ë³´ê°•
    for x in domain_hint:
        out.append({"law_name": x, "article_hint": "", "reason": "ë„ë©”ì¸ ê·œì¹™ í›„ë³´", "confidence": 0.35})
    for c in cands:
        if not isinstance(c, dict):
            continue
        ln = clean_text(c.get("law_name"))
        if not ln:
            continue
        out.append({
            "law_name": ln,
            "article_hint": clean_text(c.get("article_hint") or ""),
            "reason": clean_text(c.get("reason") or ""),
            "confidence": float(c.get("confidence") or 0.0),
        })

    # ì¤‘ë³µ ì œê±°(ë²•ë ¹ëª… ê¸°ì¤€)
    seen = set()
    uniq = []
    for c in out:
        k = c["law_name"]
        if k in seen:
            continue
        seen.add(k)
        uniq.append(c)
        if len(uniq) >= 8:
            break
    return uniq[:8]


def verifier_score(case: Dict[str, Any], law_name: str, article_title: str, article_text: str) -> Dict[str, Any]:
    """
    ì ìˆ˜í™” Verifier (0~100).
    - relevance: í‚¤ì›Œë“œ/ìŸì  vs ì¡°ë¬¸ í…ìŠ¤íŠ¸
    - scope_fit: ì£¼ê¸°ìœ„ë°˜ ë‹´ë‹¹ì ê¶Œí•œ ë²”ìœ„ì— ë§ëŠ”ì§€
    - article_match: ì œëª©/ë‚´ìš©ì´ ì§ì ‘ ì—°ê²°ë˜ëŠ”ì§€
    - hallucination_risk: ì›ë¬¸ì´ ë¹ˆì•½í•˜ê±°ë‚˜ ì¶”ì¸¡ì„±
    """
    keywords = case.get("keywords", [])
    issues = case.get("issues", [])
    facts = case.get("facts", {}) if isinstance(case.get("facts"), dict) else {}
    text = (article_title + "\n" + article_text).lower()

    # relevance (ë£°)
    hits = 0
    pool = []
    for w in keywords[:8]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in issues[:6]:
        w2 = clean_text(w)
        if w2:
            pool.append(w2)
    for w in extract_keywords_kor(clean_text(facts.get("what", "")), max_k=6):
        pool.append(w)
    pool = list(dict.fromkeys(pool))[:12]

    for w in pool:
        if w and w.lower() in text:
            hits += 1
    relevance = min(35, int((hits / max(1, len(pool))) * 35))

    # scope_fit (ë£°)
    # ê¶Œí•œ ë°– í‚¤ì›Œë“œê°€ ì¡°ë¬¸ì— ë§ìœ¼ë©´ ê°ì 
    out_of_scope = ["êµ¬ì†", "ìˆ˜ì‚¬", "ì••ìˆ˜", "ìˆ˜ìƒ‰", "ì²´í¬", "ê¸°ì†Œ", "í˜•ì‚¬", "êµ¬ê¸ˆ"]
    o_hits = sum(1 for w in out_of_scope if w in article_text)
    scope_fit = 25 - min(25, o_hits * 8)
    scope_fit = max(0, scope_fit)

    # article_match (ë£°)
    # ì œëª©ì´ ëª…í™•í•˜ë©´ ê°€ì , ì¡°ë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ê°ì 
    match = 10
    if len(article_text) >= 200:
        match += 10
    if any(k.lower() in (article_title.lower() if article_title else "") for k in keywords[:4] if k):
        match += 5
    article_match = min(25, match)

    # hallucination_risk (ë£°)
    risk = 0
    if not article_text or len(article_text) < 80:
        risk += 10
    if "ì¶”ê°€ í™•ì¸ í•„ìš”" in article_text:
        risk += 2
    # display í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹¨ì ¸ ìˆìœ¼ë©´
    if "||" in article_text or ">>" in article_text:
        risk += 5
    risk = min(15, risk)

    total = relevance + scope_fit + article_match + (15 - risk)
    if total >= 75:
        verdict = "CONFIRMED"
    elif total >= 50:
        verdict = "WEAK"
    else:
        verdict = "FAIL"

    return {
        "score_total": int(total),
        "score_breakdown": {
            "relevance": int(relevance),
            "scope_fit": int(scope_fit),
            "article_match": int(article_match),
            "hallucination_risk": int(risk),
        },
        "verdict": verdict,
        "reasons": [
            f"í‚¤ì›Œë“œ ë§¤ì¹­ {hits}/{max(1,len(pool))}",
            f"ì›ë¬¸ ê¸¸ì´ {len(article_text)}ì",
        ],
    }


def draft_strategy(case: Dict[str, Any], law_pack: Dict[str, Any], evidence_text: str) -> str:
    prefer = "strict" if law_pack.get("verdict") != "CONFIRMED" else "fast"
    prompt = f"""
[ì—…ë¬´ìœ í˜•] {case.get("task_type")}
[ì‚¬ì‹¤(ìš”ì•½)]
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
[ë¯¼ì› ìš”êµ¬] {case.get("request",{}).get("user_wants","")}
[ìŸì ] {case.get("issues",[])}

[ë²•ì ê·¼ê±°(ì„ íƒ)]
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸(ìš”ì•½): {truncate_text(law_pack.get("article_text",""), 900)}

[ì°¸ê³ (ë„¤ì´ë²„)]
{truncate_text(evidence_text, 700)}

ì•„ë˜ í˜•ì‹(ë§ˆí¬ë‹¤ìš´)ë§Œ ì¶œë ¥:
1) ì²˜ë¦¬ ë°©í–¥(í˜„ì‹¤ì ì¸ í–‰ì • í”„ë¡œì„¸ìŠ¤ ì¤‘ì‹¬, 5~8ì¤„)
2) ì²´í¬ë¦¬ìŠ¤íŠ¸(ë¶ˆë¦¿ 8~12ê°œ, "í™•ì¸/ê¸°ë¡/í†µì§€/ê¸°í•œ" í¬í•¨)
3) ê¶Œí•œë²”ìœ„(ë‚´ê°€ í•  ìˆ˜ ìˆëŠ” ê²ƒ/ì—†ëŠ” ê²ƒ ê° 3~5ê°œ)
4) ë¯¼ì›ì¸ ì„¤ëª… í¬ì¸íŠ¸(ì˜¤í•´ ì¤„ì´ëŠ” ë¬¸ì¥ 3~5ê°œ)
"""
    return llm.generate_text(prompt, prefer=prefer, temp=0.1)


def draft_document_json(dept: str, officer: str, case: Dict[str, Any], law_pack: Dict[str, Any], strategy_md: str) -> Dict[str, Any]:
    today_str = datetime.now().strftime("%Y. %m. %d.")
    doc_num = f"í–‰ì •-{datetime.now().strftime('%Y')}-{int(time.time()) % 10000:04d}í˜¸"

    prompt = f"""
ì•„ë˜ ìŠ¤í‚¤ë§ˆë¡œë§Œ JSON ì¶œë ¥(í‚¤ ì¶”ê°€ ê¸ˆì§€):
{{
  "title": "ë¬¸ì„œ ì œëª©",
  "receiver": "ìˆ˜ì‹ ",
  "body_paragraphs": ["ë¬¸ë‹¨1","ë¬¸ë‹¨2","ë¬¸ë‹¨3","ë¬¸ë‹¨4"],
  "department_head": "ë°œì‹  ëª…ì˜"
}}

ì‘ì„± ì •ë³´:
- ë¶€ì„œ: {dept}
- ë‹´ë‹¹ì: {officer}
- ì‹œí–‰ì¼: {today_str}
- ë¬¸ì„œë²ˆí˜¸: {doc_num}

ì‚¬ì‹¤ê´€ê³„(í™•ì •ëœ ë²”ìœ„):
- who: {case.get("facts",{}).get("who","")}
- what: {case.get("facts",{}).get("what","")}
- where: {case.get("facts",{}).get("where","")}
- when: {case.get("facts",{}).get("when","")}
- ë¯¼ì›ìš”êµ¬: {case.get("request",{}).get("user_wants","")}
- ì œì•½/ê¸°í•œ: {case.get("request",{}).get("constraints","")}

ë²•ì  ê·¼ê±°(ì„ íƒ/í™•ë³´ëœ ë²”ìœ„):
- ë²•ë ¹: {law_pack.get("law_name","")}
- ì¡°ë¬¸: {law_pack.get("article_title","")}
- ì›ë¬¸: {truncate_text(law_pack.get("article_text",""), 1200)}

ì²˜ë¦¬ ì „ëµ(ìš”ì•½):
{truncate_text(strategy_md, 900)}

ì‘ì„± ì›ì¹™:
- ë¬¸ì„œ í†¤: ê±´ì¡°/ì •ì¤‘, ì¶”ì¸¡ ê¸ˆì§€
- êµ¬ì¡°: [ê²½ìœ„]â†’[ë²•ì  ê·¼ê±°]â†’[ì¡°ì¹˜/ì•ˆë‚´]â†’[ê¶Œë¦¬êµ¬ì œ/ë¬¸ì˜]
- ê°œì¸ì •ë³´ëŠ” OOOë¡œ ë§ˆìŠ¤í‚¹
- ë²•ë ¹ ì›ë¬¸ì´ ì•½í•˜ë©´ "ì¶”ê°€ í™•ì¸ í•„ìš”" ë¬¸êµ¬ í¬í•¨
"""
    js = llm.generate_json(prompt, prefer="strict", max_retry=3)
    out = ensure_doc_shape(js)
    out["_meta"] = {"doc_num": doc_num, "today": today_str}
    return out


def qa_guardrails(doc: Dict[str, Any], law_pack: Dict[str, Any]) -> Dict[str, Any]:
    """í•„ìˆ˜ìš”ì†Œ/ê¸ˆì§€ìš”ì†Œ ê°„ë‹¨ ê²€ì‚¬ í›„ ë³´ì • íŒíŠ¸"""
    issues = []
    if not doc.get("title"):
        issues.append("title_missing")
    if not doc.get("receiver"):
        issues.append("receiver_missing")
    if not isinstance(doc.get("body_paragraphs"), list) or len(doc.get("body_paragraphs")) < 2:
        issues.append("body_weak")

    # 'ë‹¨ì •/ì¶”ì¸¡' ì™„í™”: ë„ˆë¬´ ê³µê²©ì /ì¶”ì¸¡ì  ë¬¸êµ¬ ì œê±°ëŠ” LLM ì¬ì‘ì„±ê¹Œì§€ëŠ” ì•ˆí•˜ê³  ê²½ê³ ë§Œ
    forbidden = ["í™•ì‹¤íˆ", "ë°˜ë“œì‹œ", "100%", "ë¬´ì¡°ê±´", "ë¬´ì°¨ë³„"]
    body = "\n".join(doc.get("body_paragraphs", []))
    if any(x in body for x in forbidden):
        issues.append("overconfident_language")

    # ë²•ë ¹ì´ FAILì¸ë° ë²•ë ¹ ë‹¨ì •í•˜ë©´ ë¬¸ì œ
    if law_pack.get("verdict") == "FAIL" and ("ë²•ë ¹" in body or "ì œ" in body):
        issues.append("law_claim_without_confidence")

    doc["_qa"] = {"issues": issues}
    return doc


def run_workflow(user_input: str, dept: str, officer: str, user_key: str):
    log_area = st.empty()
    logs = []

    def add_log(msg: str, style: str = "sys"):
        logs.append(f"<div class='agent-log log-{style}'>{safe_html(msg)}</div>")
        log_area.markdown("".join(logs), unsafe_allow_html=True)
        time.sleep(0.03)

    started = datetime.now().isoformat()

    # STEP: INTAKE
    add_log("ğŸ§¾ [INTAKE] ë¯¼ì›/ì—…ë¬´ ë‚´ìš©ì„ ì‚¬ì‹¤ê´€ê³„ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì¡°í™”â€¦ (FAST)", "sys")
    t0 = time.time()
    case = intake_schema(user_input)
    db_step_payload = {"case": case}
    # STEP LOG
    if db.enabled():
        db.insert_step({
            "run_id": None,  # run_idëŠ” ë‚˜ì¤‘ì— insert í›„ ì—…ë°ì´íŠ¸ê°€ ì´ìƒì ì´ì§€ë§Œ, ë‹¨ìˆœí™”
            "step_name": "INTAKE",
            "model_used": llm.model_fast,
            "tokens": 0,
            "cost": 0,
            "payload_json": db_step_payload
        })
    add_log(f"âœ… [INTAKE] ì™„ë£Œ (quality={case.get('_input_quality',{}).get('score','?')})", "sys")

    # STEP: LAW CANDIDATES
    add_log("ğŸ§© [LAW-CAND] ë²•ë ¹ í›„ë³´ 3~6ê°œ ìƒì„±â€¦ (FAST)", "legal")
    candidates = generate_law_candidates(case)
    if not candidates:
        candidates = [{"law_name": k, "article_hint": "", "reason": "fallback", "confidence": 0.2} for k in case.get("keywords", [])[:3]]
    add_log(f"ğŸ“Œ í›„ë³´: " + ", ".join([c['law_name'] for c in candidates[:6]]), "legal")

    # STEP: LAW FETCH + VERIFY LOOP
    add_log("ğŸ“š [LAW] DRFë¡œ ì›ë¬¸ í™•ë³´ + ê²€ì¦ ì ìˆ˜í™”â€¦", "legal")
    best_pack = {
        "law_name": "",
        "mst": "",
        "article_title": "",
        "article_text": "",
        "verdict": "FAIL",
        "score": 0,
        "debug": {}
    }

    loop_debug = []
    for i, cand in enumerate(candidates[:6], start=1):
        q = cand.get("law_name", "")
        art_hint = cand.get("article_hint", "")
        add_log(f"  - ({i}) {q} ê²€ìƒ‰ â†’ ì›ë¬¸ í™•ì¸", "legal")

        # 1) search
        laws = law_api.search_law(q, display=10)
        if not laws:
            loop_debug.append({"cand": cand, "search": "no_result"})
            continue

        chosen = laws[0]
        mst = clean_text(chosen.get("MST"))
        law_name = clean_text(chosen.get("lawNm"))
        link = clean_text(chosen.get("link"))

        # 2) fetch (ì¡°ë¬¸ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ ì¡°ë¬¸, ì—†ìœ¼ë©´ 1ì¡°ë¼ë„)
        pack = law_api.get_article_by_mst(mst, article_no=art_hint if art_hint else None)
        article_title = clean_text(pack.get("article_title", ""))
        article_text = clean_text(pack.get("article_text", ""))
        if not article_text:
            loop_debug.append({"cand": cand, "mst": mst, "fetch": "empty"})
            continue

        # 3) verify score
        v = verifier_score(case, law_name, article_title, article_text)
        score = v["score_total"]
        verdict = v["verdict"]

        loop_debug.append({
            "cand": cand,
            "selected": {"law_name": law_name, "mst": mst, "link": link, "article_title": article_title},
            "verify": v
        })

        if score > best_pack["score"]:
            best_pack = {
                "law_name": law_name,
                "mst": mst,
                "link": link,
                "article_title": article_title,
                "article_text": article_text,
                "verdict": verdict,
                "score": score,
                "verify": v,
                "debug": {"cand": cand, "selected": chosen, "loop": loop_debug[-1]}
            }

        # í™•ì •ì´ë©´ ë°”ë¡œ ì¢…ë£Œ(ì„±ëŠ¥â†‘)
        if verdict == "CONFIRMED":
            break

    add_log(f"âœ… [LAW] ì„ íƒ: {best_pack.get('law_name','(ì—†ìŒ)')} / {best_pack.get('article_title','')} (score={best_pack.get('score',0)}, {best_pack.get('verdict')})", "legal")

    # STEP: NAVER EVIDENCE
    add_log("ğŸŒ [EVIDENCE] ë„¤ì´ë²„ ì°¸ê³ ìë£Œ(ì„ íƒ) ìˆ˜ì§‘â€¦", "search")
    ev_items = []
    ev_text = ""
    kw = case.get("keywords", [])
    if kw:
        q = " ".join(kw[:2]) + " í–‰ì •ì²˜ë¶„"
        raw = naver.search(q, cat="news", display=5)
        for item in raw:
            title = clean_text(item.get("title"))
            desc = clean_text(item.get("description"))
            link = clean_text(item.get("link"))
            ev_items.append({"title": title, "desc": desc, "link": link})
            ev_text += f"- {title}: {desc}\n"
    add_log(f"âœ… [EVIDENCE] {len(ev_items)}ê±´", "search")

    # STEP: STRATEGY
    add_log("ğŸ§  [STRATEGY] ì²˜ë¦¬ ì „ëµ ìš”ì•½â€¦ (FAST/STRICT ìë™)", "strat")
    strategy = draft_strategy(case, best_pack, ev_text)

    # STEP: DRAFT
    add_log("âœï¸ [DRAFT] ê³µë¬¸ JSON ìƒì„±â€¦ (STRICT)", "draft")
    doc = draft_document_json(dept, officer, case, best_pack, strategy)
    doc = qa_guardrails(doc, best_pack)

    # A4 HTML ìƒì„±
    meta = doc.get("_meta", {})
    doc_num = meta.get("doc_num", "")
    today = meta.get("today", "")

    # STEP: SAVE
    add_log("ğŸ’¾ [SAVE] ì´ë ¥ ì €ì¥â€¦", "sys")
    run_id = None
    db_msg = "DB ë¯¸ì—°ê²°"
    if db.enabled():
        ok, msg, rid = db.insert_run({
            "user_id": user_key,               # ê°„ì´ user_key (ì‹¤ì œ Auth ëŒ€ì‹ )
            "created_at": started,
            "task_type": clean_text(case.get("task_type","")),
            "input_text": user_input,
            "input_quality_score": int(case.get("_input_quality",{}).get("score", 0)),
            "final_verdict": best_pack.get("verdict"),
            "law_name": best_pack.get("law_name"),
            "law_mst": best_pack.get("mst"),
            "article_no": best_pack.get("verify",{}).get("score_breakdown",{}),  # í…Œì´ë¸” ì„¤ê³„ì— ë§ì¶° ìˆ˜ì • ê°€ëŠ¥
            "total_tokens": int(st.session_state.get("metrics",{}).get("tokens_total",0)),
            "total_cost": 0,
            "status": "DONE"
        })
        db_msg = msg
        run_id = rid

        # artifacts ì €ì¥(ì„ íƒ)
        if run_id:
            db.insert_artifact({"run_id": run_id, "kind": "case_json", "content": safe_json_dump(case)})
            db.insert_artifact({"run_id": run_id, "kind": "law_pack_json", "content": safe_json_dump(best_pack)})
            db.insert_artifact({"run_id": run_id, "kind": "strategy_md", "content": strategy})
            db.insert_artifact({"run_id": run_id, "kind": "draft_json", "content": safe_json_dump(doc)})
            # A4 htmlë„ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´:
            # db.insert_artifact({"run_id": run_id, "kind": "draft_html", "content": "..."})

    add_log(f"âœ… ì™„ë£Œ ({db_msg})", "sys")
    time.sleep(0.25)
    log_area.empty()

    # ë°˜í™˜
    return {
        "case": case,
        "law": best_pack,
        "strategy": strategy,
        "doc": ensure_doc_shape(doc),
        "doc_meta": {"doc_num": doc_num, "today": today, "dept": dept, "officer": officer},
        "ev_items": ev_items,
        "loop_debug": loop_debug,
        "db_msg": db_msg,
        "run_id": run_id
    }


# =========================
# 9) UI
# =========================
def render_a4(doc: Dict[str, Any], meta: Dict[str, str]):
    body_html = "".join(
        [f"<p style='margin:0 0 14px 0;'>{safe_html(p)}</p>" for p in doc.get("body_paragraphs", [])]
    )
    html = f"""
<div class="paper-sheet">
  <div class="stamp">ì§ì¸ìƒëµ</div>
  <div class="doc-header">{safe_html(doc.get('title',''))}</div>
  <div class="doc-info">
    <span>ë¬¸ì„œë²ˆí˜¸: {safe_html(meta.get('doc_num',''))}</span>
    <span>ì‹œí–‰ì¼ì: {safe_html(meta.get('today',''))}</span>
    <span>ìˆ˜ì‹ : {safe_html(doc.get('receiver',''))}</span>
  </div>
  <div class="doc-body">
    {body_html}
  </div>
  <div class="doc-footer">{safe_html(doc.get('department_head',''))}</div>
</div>
"""
    components.html(html, height=900, scrolling=True)


def render_law(law_pack: Dict[str, Any]):
    law_name = law_pack.get("law_name", "")
    article_title = law_pack.get("article_title", "")
    verdict = law_pack.get("verdict", "")
    score = law_pack.get("score", 0)
    link = law_pack.get("link", "")

    st.markdown(f"**ì„ íƒ ë²•ë ¹:** {law_name}  \n**ì¡°ë¬¸:** {article_title}  \n**ê²€ì¦:** {verdict} / score={score}")
    if link:
        st.markdown(f"- ìƒì„¸ ë§í¬: {link}")

    txt = law_pack.get("article_text", "") or ""
    txt = normalize_whitespace(txt)
    txt = strip_hanja_for_display(txt)

    if not txt:
        st.warning("ì¡°ë¬¸ ì›ë¬¸ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤(ë¹ˆ í…ìŠ¤íŠ¸). í›„ë³´ë¥¼ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.")
        return

    # ë³´ê¸° ì¢‹ì€ í˜•íƒœ: ì œëª© + ì¡°ë¬¸ì„ ì½”ë“œë¸”ë¡/í”„ë¦¬í…ìŠ¤íŠ¸ë¡œ
    st.markdown("### ì¡°ë¬¸ ì›ë¬¸(ì •ë¦¬ë³¸)")
    st.code(txt, language="text")

    v = law_pack.get("verify") or {}
    if v:
        st.markdown("### Verifier ì ìˆ˜")
        st.json(v)


def main():
    # ê°„ì´ ì‚¬ìš©ì í‚¤(ë¡œê·¸ì¸ ëŒ€ì‹ ): ì¡°ì§/ì‚¬ìš©ì êµ¬ë¶„ìš©
    st.session_state.setdefault("user_key", "local_user")

    st.session_state.setdefault("dept", "OOì‹œì²­ OOê³¼")
    st.session_state.setdefault("officer", "ê¹€ì£¼ë¬´ê´€")

    col_l, col_r = st.columns([1, 1.2], gap="large")

    with col_l:
        st.title("AI í–‰ì •ê´€ Pro")
        st.caption("Dual Router v6.0 â€” FAST(qwen/qwen3-32b) + STRICT(llama-3.3-70b) + Law Verifier Loop")
        st.markdown("---")

        with st.expander("ğŸ§© ì‚¬ìš©ì/ë¶€ì„œ ì„¤ì •", expanded=False):
            st.text_input("ë¶€ì„œëª…", key="dept")
            st.text_input("ë‹´ë‹¹ì", key="officer")
            st.text_input("ì‚¬ìš©ì í‚¤(íˆìŠ¤í† ë¦¬ êµ¬ë¶„ìš©, ì„ì˜)", key="user_key")
            st.caption("â€» Supabase Authë¥¼ ë¶™ì´ë ¤ë©´ ì—¬ê¸° user_key ëŒ€ì‹  auth.uid()ë¥¼ ë„£ëŠ” êµ¬ì¡°ë¡œ í™•ì¥í•˜ì„¸ìš”.")

        user_input = st.text_area(
            "ì—…ë¬´ ì§€ì‹œ ì‚¬í•­(ë¯¼ì› ìƒí™© í¬í•¨)",
            height=220,
            placeholder="ì˜ˆ: ê±´ì„¤ê¸°ê³„ê°€ ì°¨ê³ ì§€ ì™¸ ì¥ê¸°ê°„ ì£¼ì°¨(ì£¼ê¸°ìœ„ë°˜) ì‹ ê³ ê°€ ë“¤ì–´ì™”ê³ , í˜„ì¥ í™•ì¸í–ˆë”ë‹ˆ ì´ë™í•œ ìƒíƒœ. ë¯¼ì›ì¸ì€ ìƒì‹œ ë‹¨ì†ì„ ìš”êµ¬. ë‹´ë‹¹ìê°€ í•  ìˆ˜ ìˆëŠ” ì¡°ì¹˜ì™€ ë‹µë³€ ê³µë¬¸ ì‘ì„±.",
        )

        if st.button("ğŸš€ ë¬¸ì„œ ìƒì„± ì‹¤í–‰", type="primary", use_container_width=True):
            if not user_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("ì—ì´ì „íŠ¸(êµ¬ì¡°í™”â†’ë²•ë ¹í›„ë³´â†’ì›ë¬¸í™•ë³´â†’ê²€ì¦â†’ê³µë¬¸ì‘ì„±) ì‹¤í–‰ ì¤‘..."):
                    try:
                        res = run_workflow(
                            user_input.strip(),
                            st.session_state["dept"],
                            st.session_state["officer"],
                            st.session_state["user_key"],
                        )
                        st.session_state["result"] = res
                    except Exception as e:
                        st.error(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

        # Metrics
        st.markdown("---")
        st.subheader("ğŸ“Š ì„¸ì…˜ ì‚¬ìš©ëŸ‰")
        m = st.session_state.get("metrics", {})
        calls = m.get("calls", {})
        tokens_total = m.get("tokens_total", 0)
        if calls:
            for k, v in sorted(calls.items(), key=lambda x: (-x[1], x[0])):
                st.write(f"- **{k}**: {v}íšŒ")
            st.caption(f"ì´ í† í°(ê°€ëŠ¥í•œ ê²½ìš°): {tokens_total}")
        else:
            st.info("ëŒ€ê¸° ì¤‘...")

        st.markdown("<div class='small-muted'>í•µì‹¬: ë²•ë ¹ì€ 1ë²ˆ ì°ì§€ ì•Šê³ , í›„ë³´â†’ì›ë¬¸â†’ê²€ì¦ì ìˆ˜ ë£¨í”„ë¥¼ ëŒë ¤ì„œ ì—‰ëš±í•œ ë²•ë ¹ì„ ì¤„ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)

        # History (ì˜µì…˜)
        if db.enabled():
            st.markdown("---")
            st.subheader("ğŸ•˜ íˆìŠ¤í† ë¦¬(ìµœê·¼)")
            runs = db.list_runs(st.session_state["user_key"], limit=15)
            if runs:
                opts = [f"{r.get('created_at','')} | {r.get('task_type','')} | {r.get('final_verdict','')}" for r in runs]
                idx = st.selectbox("ë¶ˆëŸ¬ì˜¬ ì‹¤í–‰ ê¸°ë¡ ì„ íƒ", range(len(opts)), format_func=lambda i: opts[i])
                if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True):
                    rid = runs[idx].get("run_id")
                    detail = db.load_run_detail(rid)
                    if detail:
                        st.session_state["history_detail"] = detail
            else:
                st.caption("runs í…Œì´ë¸”ì— ì €ì¥ëœ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤(í…Œì´ë¸”/ê¶Œí•œ í™•ì¸).")

    with col_r:
        tab_main, tab_debug, tab_history = st.tabs(["ğŸ“„ ê³µë¬¸ì„œ(A4)", "ğŸ” ê·¼ê±°/ì „ëµ", "ğŸ§¾ íˆìŠ¤í† ë¦¬ ìƒì„¸"])

        with tab_main:
            res = st.session_state.get("result")
            if not res:
                st.markdown(
                    """
<div style='text-align:center; padding:120px 20px; color:#9ca3af; border:2px dashed #e5e7eb; border-radius:14px; background:#fff;'>
  <h3 style='margin-bottom:8px;'>ğŸ“„ A4 ë¯¸ë¦¬ë³´ê¸°</h3>
  <p>ì™¼ìª½ì—ì„œ ë¯¼ì› ìƒí™©ì„ ì…ë ¥í•˜ê³  ì‹¤í–‰ì„ ëˆ„ë¥´ì„¸ìš”.<br>ìë™ìœ¼ë¡œ ë²•ë ¹ì„ í™•ë³´/ê²€ì¦ í›„ ê³µë¬¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.</p>
</div>
""",
                    unsafe_allow_html=True,
                )
            else:
                render_a4(res["doc"], res["doc_meta"])

        with tab_debug:
            res = st.session_state.get("result")
            if not res:
                st.info("ê²°ê³¼ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"DB ì €ì¥: {res.get('db_msg','')}")
                st.markdown("## 1) êµ¬ì¡°í™”ëœ ë¯¼ì›(ì‚¬ì‹¤ê´€ê³„)")
                st.json(res.get("case", {}))

                st.markdown("## 2) ë²•ì  ê·¼ê±°(ì •ë¦¬ë³¸)")
                render_law(res.get("law", {}))

                st.markdown("## 3) ì²˜ë¦¬ ì „ëµ")
                st.markdown(res.get("strategy", ""))

                st.markdown("## 4) ë„¤ì´ë²„ ì°¸ê³ (ì˜µì…˜)")
                ev = res.get("ev_items", [])
                if not ev:
                    st.caption("ì°¸ê³ ìë£Œ ì—†ìŒ(í‚¤/ìš”ì²­ ì œí•œ/ë„¤ì´ë²„ API ë¯¸ì„¤ì • ê°€ëŠ¥).")
                for item in ev:
                    title = clean_text(item.get("title"))
                    desc = clean_text(item.get("desc"))
                    link = clean_text(item.get("link"))
                    if link:
                        st.markdown(
                            f"<div class='ev-card'><div class='ev-title'><a href='{link}' target='_blank'>{escape(title)}</a></div><div class='ev-desc'>{escape(desc)}</div></div>",
                            unsafe_allow_html=True
                        )
                    else:
                        st.markdown(
                            f"<div class='ev-card'><div class='ev-title'>{escape(title)}</div><div class='ev-desc'>{escape(desc)}</div></div>",
                            unsafe_allow_html=True
                        )

                with st.expander("ğŸ› ï¸ ë²•ë ¹ í›„ë³´ ë£¨í”„ ë””ë²„ê·¸", expanded=False):
                    st.json(res.get("loop_debug", []))

        with tab_history:
            if not db.enabled():
                st.info("Supabase ë¯¸ì—°ê²°ì…ë‹ˆë‹¤(secrets.toml í™•ì¸).")
            else:
                detail = st.session_state.get("history_detail")
                if not detail:
                    st.caption("ì™¼ìª½ íˆìŠ¤í† ë¦¬ì—ì„œ ì‹¤í–‰ ê¸°ë¡ì„ ì„ íƒ í›„ 'ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
                else:
                    st.markdown("### runs row")
                    st.json(detail)

                    arts = detail.get("_artifacts", [])
                    st.markdown("### artifacts")
                    if not arts:
                        st.caption("artifacts ì—†ìŒ")
                    else:
                        # kindë³„ ë³´ê¸°
                        kinds = list(dict.fromkeys([a.get("kind") for a in arts if a.get("kind")]))
                        ksel = st.selectbox("artifact kind", kinds)
                        for a in arts:
                            if a.get("kind") == ksel:
                                st.code(a.get("content", "")[:12000], language="text")


if __name__ == "__main__":
    main()
